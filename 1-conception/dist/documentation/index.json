[
{
	"uri": "http://localhost:1313/documentation/",
	"title": "Accueil",
	"tags": [],
	"description": "",
	"content": "Documentation de la nouvelle PSL Accueil Professionnellement, j\u0026rsquo;ai découvert le SI de la Plateforme de Service en Ligne créé par la DILA.\nA titre personnel, j\u0026rsquo;ai tenté de repenser les besoins et reconcevoir les solutions à partir de mes connaissances et une dizaine d\u0026rsquo;année plus tard.\nAvec l\u0026rsquo;idée en tête de créer un système extrêmement paramétrable, j\u0026rsquo;ai tenté de constuire un prototype de \u0026ldquo;moteur\u0026rdquo; Angular capable d\u0026rsquo;afficher une saisie de formulaire. Le prototype m\u0026rsquo;a plu et j\u0026rsquo;ai continué, des années durant, le soir et le weekend, à reconstuire ce SI.\nEn voici le résultat.\nDocumentation Ce site documentaire contient et référence toute la documentation fonctionnelle et technique de ma nouvelle PSL : 1. Conception générale 2. Conception détaillée 3. Développement 4. Ops 5. Avancement 6. Glossaire "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/",
	"title": "1. Conception générale",
	"tags": [],
	"description": "",
	"content": "Chapitre 1 Conception générale Ce chapitre se veut être une documentation simple mais exhaustive.\nIl décrit rapidement le SI avec 1.1 Objectifs 1.2 Architecture 1.3 Les applicatifs "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.1objectifs/",
	"title": "1.1 Objectifs",
	"tags": [],
	"description": "",
	"content": "Chapitre 1.1 Les objectifs de cette nouvelle PSL Les pages ci-dessous ont pour objectif de lister exhaustivement tous les objectifs de ma version de la PSL.\nA partir de ces objectifs, la conception pourra commencer.\n1.1.1 Objectifs fonctionnels 1.1.2 Objectifs techniques 1.1.3 Objectifs de disponibilité 1.1.4 Objectifs d\u0026#39;homogénéité "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.1objectifs/1.1.1objectifsfonctionnels/",
	"title": "1.1.1 Objectifs fonctionnels",
	"tags": [],
	"description": "",
	"content": "Selon moi, l\u0026rsquo;objectif initial et primaire de la Plateforme de Service en Ligne (PSL) est\nde permettre aux usagers de saisir leurs demandes dans des formulaires les guidant le plus possible jusqu\u0026rsquo;au remplissage des documents à envoyer au service instructeur. Ce guidage est\n\u0026ldquo;fonctionnel\u0026rdquo; : les données à renseigner sont affichées/masquées en fonction des saisies précédentes pour que les demandes soient cohérentes et simples à saisir. \u0026ldquo;qualitatif\u0026rdquo; : les données saisies sont bonnes puisque les usagers disposent de saisies avec auto-complétion et de validations de champ. \u0026ldquo;accessible\u0026rdquo; : les applications WEB respectent le RGAA et permettent donc au plus grand nombre de réaliser une demande. Une fois les données saisies par l\u0026rsquo;usager, ce dernier n\u0026rsquo;a pas à s\u0026rsquo;occuper d\u0026rsquo;envoyer manuellement sa demande au service concerné. En effet, la PSL s\u0026rsquo;occupe de la mise à disposition des documents générés au service concerné.\nCette PSL permet principalement la saisie de données :\nles types de données saisissables ne sont pas nombreux : chaine de caractères, date, nombre, pièce jointe\u0026hellip; des validations de ces données sont souvent utilisées : donnée obligatoire, date dans le passé/futur, format de saisie\u0026hellip; des référentiels sont interrogeables (sur le moment ou quotidiennement) pour valider des données plus complexes comme les communes, les numéros RNA, les adresses françaises, les pays étrangers\u0026hellip; des groupes de données cohérents se retrouvent très régulièrement comme une adresse française, une adresse étrangère, une identité de personne (physique ou morale), une commune, une filiation\u0026hellip; "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.1objectifs/1.1.2objectifstechniques/",
	"title": "1.1.2 Objectifs techniques",
	"tags": [],
	"description": "",
	"content": "L\u0026rsquo;objectif technique de ma version du SI est de constuire une solution basée sur des technologies récentes pour en faciliter l\u0026rsquo;installation dans le cloud :\nse baser sur des technologies récentes et pérennes : SpringBoot / Angular permettre une forte évolutivité : architecture micro-services maintenir un haut niveau de sécurité : du fait des technologies modernes (et donc maintenues) et de l\u0026rsquo;architecture (peu d\u0026rsquo;API recevant des données) être \u0026ldquo;cloud ready\u0026rdquo; nativement : usage des fonctionnalités de l\u0026rsquo;écosystème Spring simplifier la configuration et l\u0026rsquo;administration : réduction des configurations sous forme de clef/valeur mais des configurations structurées en Document (au sens NoSQL du terme) disposer d\u0026rsquo;un SI hautement disponible (sans parler de l\u0026rsquo;aspect scalabilité traité par le cloud) "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.1objectifs/1.1.3objectifsdisponibilite/",
	"title": "1.1.3 Objectifs de disponibilité",
	"tags": [],
	"description": "",
	"content": "Les applications fontales doivent être hautement disponibles. Leur disponibilité ne doit pas dépendre des applicatifs présents en aval dans la chaîne de traitement de l\u0026rsquo;information.\nAutrement dit, si un des applicatifs en aval est indisponible, aucune fonctionnalité de ma PSL ne doit être impactée.\nLa solution est simple (en tout cas le principe) : à la soumission d\u0026rsquo;un télé-dossier, ma PSL ne fait que stocker les pièces jointes fournies par l\u0026rsquo;usager et les documents générés. C\u0026rsquo;est au système traitant le routage de venir chercher les documents.\n"
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.1objectifs/1.1.4objectifhomogeneite/",
	"title": "1.1.4 Objectifs d&#39;homogénéité",
	"tags": [],
	"description": "",
	"content": "Enfin, parmi les attendus de la PSL, restent\nl\u0026rsquo;homogénéité des écrans leur respect du Référentiel Général d\u0026rsquo;Amélioration de l\u0026rsquo;Accessibilité leur respect de la charte DesignSytem de l\u0026rsquo;état Dans cet objectif, presque toutes les démarches sont construites de la même manière :\nun fil d\u0026rsquo;Ariane permettant de se repérer dans les différentes étapes de la saisie chaque étape est un ensemble de pages chaque page contient un formulaire le formulaire est constitué de blocs chaque bloc peut commencer par un titre et regroupe des champs de saisie et des paragraphes de texte "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.2architecture/",
	"title": "1.2 Architecture",
	"tags": [],
	"description": "",
	"content": "Chapitre 1.2 L\u0026rsquo;architecture de ma PSL 1.2.1 Conception de l\u0026#39;architecture 1.2.2 Schéma d\u0026#39;architecture générale 1.2.3 Principes généraux "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.2architecture/1.2.1conceptionarchitecture/",
	"title": "1.2.1 Conception de l&#39;architecture",
	"tags": [],
	"description": "",
	"content": "L\u0026rsquo;architecture de cette PSL est basée sur des Single Page Application (SPA) et des micro-services (wikipedia)\nLe découpage des fonctionnalités de ma PSL en livrables applicatifs WEB est naturel :\nune application publique par démarche (au sens applicatif du terme) une application interne par typologie d\u0026rsquo;utilisateurs (un éditeur pour les concepteurs, une administration pour les exploitants\u0026hellip;) Côté BACK, le principe des micro-services prévaut. Ainsi, le découpage des fonctionnalités est piloté par la séparation des données dans des bases différentes de par\nleur nature qui impose une technologie différente pour leur persistence : les données relationnelles sont stockées dans une base de données relationnelle (si le besoin s\u0026rsquo;en fait sentir un jour) les fichiers de moins de 16Mo sont stockés dans une base de données MongoDB (brouillons et paramètres d\u0026rsquo;une application de démarche) les fichiers de plus de 16Mo sont stockés dans une base de données MongoDB+GridFS (documents générés par le back ou pièces jointes) les données de référentiel sychronisés quotidiennement depuis des sources disponibles sur Internet sont stockées en mémoire dans le micro-service concerné (43,5Mo) leur usage visibilité/sécurité : le paramétrage du visuel d\u0026rsquo;une application de démarche est chargé dans le navigateur de l\u0026rsquo;utilisateur alors que le paramétrage des documents générés et du routage de ces derniers vers les partenaires/destinataires ne doivent pas être visibles des usagers. cache : les données de référentiel, les paramètres publics d\u0026rsquo;une application de démarche et les paramètres internes ne sont modifiables que depuis les applicatifs de la zone d\u0026rsquo;administration et leur lecture se fait à travers un cache "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.2architecture/1.2.2schemageneral/",
	"title": "1.2.2 Schéma d&#39;architecture générale",
	"tags": [],
	"description": "",
	"content": "A partir des principes énoncés au chapitre précédent, on peut imaginer une architecture avec :\nGuide de lecture :\nChaque zone colorée est une zone réseau particulière dont les flux entrants sont spécifiques. En bout de flèche, le \u0026ldquo;R\u0026rdquo; et/ou le \u0026ldquo;W\u0026rdquo; spécifie que l\u0026rsquo;accès est en \u0026ldquo;Lecture\u0026rdquo; ou \u0026ldquo;Ecriture\u0026rdquo;. Par défaut, tous les accès sont \u0026ldquo;Lecture seule\u0026rdquo;. "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.2architecture/1.2.3principesgeneraux/",
	"title": "1.2.3 Principes généraux",
	"tags": [],
	"description": "",
	"content": "\r1.2.3.1 - Hébergement des applicatifs 1.2.3.2 - Haute disponibilité 1.2.3.3 - Scalabilité 1.2.3.4 - Zone réseau 1.2.3.5 - Sécurisation des appels à PSL 1.2.3.1 - Hébergement des applicatifs Les applicatifs WEB se présentent sous forme de sites statiques. Leur hébergement peut donc se faire via un service cloud dédié ou un serveur WEB classique (HTTPd ou Nginx).\nLes applicatifs Java sont autonomes (Tomcat est embarqué via SpringBoot). Ces applicatifs peuvent être déployés sur tout type de VM et automatisés/gérés automatiquement.\n1.2.3.2 - Haute disponibilité Tous les noeuds (applicatif Java et éventuellement serveur WEB classique) sont redondés et disposent de répartition de charge en amont. Le composant Transfert est également redondé (deux instances peuvent travailler en parallele) mais aucune API n\u0026rsquo;est exposée. Le composant Notification est, lui aussi, redondé mais il n\u0026rsquo;expose pas d\u0026rsquo;API publique (accessible via Internet)\n1.2.3.3 - Scalabilité La scalabilité sera à mettre en place en fonction des possibilités offertes par le fournisseur de cloud.\n1.2.3.4 - Zone réseau Les données sont, dans le schéma du chapitre précédent, séparées dans une zone spécifique (nommée DATA). Cette segmentation en zone est très palpable dans les hébergements tradionnels (répondant au pattern défense en profondeur). Dans le CLOUD, cet isolement se matérialise par l\u0026rsquo;usage d\u0026rsquo;un service managé (SAAS). La protection réseau n\u0026rsquo;est donc pas certaine et dépend (encore) du fournisseur de cloud.\nL\u0026rsquo;applicatif Transfert est séparé des autres dans une zone dédiée (nommée BATCH) car les fonctionnalités portées par cet applicatif sont sensibles et qu\u0026rsquo;il n\u0026rsquo;a pas besoin d\u0026rsquo;être exposés à Internet.\nSur le même principe, Les applicatifs Securite et Admin sont séparés dans une zone dédiée (nommée ADMIN) car leur usage est réservé aux personnes ayant des accès bien particuliers, à travers le PROXY ENTRANT ADMIN.\nLes applicatifs de la zone APP sont\ndestinés à exposer des services (et donc des données) aux usagers via Internet nécessaires au bon fonctionnement des services exposés (comme Notification) 1.2.3.5 - Sécurisation des appels à PSL Les APIs publiques exposées par les applicatifs de la zone APP sont sécurisées.\nSi l\u0026rsquo;utilisateur est connecté avec un fournisseur d\u0026rsquo;identité public, cette identification est suffisante pour sécuriser et identifier l\u0026rsquo;utilisateur lors de tous ces appels. A défaut d\u0026rsquo;authentification externe, l\u0026rsquo;utilisateur est néanmoins associé à une identité anonyme via la création d\u0026rsquo;un token JWT par les APIs afin de fournir un identifiant unique à l\u0026rsquo;utilisateur à travers toutes les APIs (pour retrouver dans les logs les appels successifs réalisés par un même utilisateur : chargement d\u0026rsquo;une configuration, téléversement d\u0026rsquo;un document, sauvegarde/chargement d\u0026rsquo;un brouillon, soumission d\u0026rsquo;un télé-dossier, \u0026hellip;). Les APIs internes sont aussi exposées par les applicatifs de la zone APP mais ne sont pas accessibles directement depuis Internet. Mais le token de sécurité à utiliser est le même que celui utilisé pour appeler l\u0026rsquo;applicatif exposé à Internet.\nLes APIs d\u0026rsquo;administration nécessite un token d\u0026rsquo;administration basé sur une identité fournie par l\u0026rsquo;applicatif Securite (LDAP).\n"
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.3lesapplicatifs/",
	"title": "1.3 Les applicatifs",
	"tags": [],
	"description": "",
	"content": "Chapitre 1.3 Les applicatifs de ma PSL (point de vu fonctionnel) 1.3.1 Les applications WEB de démarche 1.3.2 Le socle 1.3.3 Les outils 1.3.4 Rétro-ingénierie "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.3lesapplicatifs/1.3.1demarche/",
	"title": "1.3.1 Les applications WEB de démarche",
	"tags": [],
	"description": "",
	"content": "\r1.3.1.1 - Introduction 1.3.1.2 - Paramétrabilité des applications de démarche 1.3.1.3 - Le moteur paramétrable 1.3.1.4 - Un schéma 1.3.1.1 - Introduction Chaque application WEB de démarche est unique :\nun public d\u0026rsquo;usagers (trés général ou très précis) un ou plusieurs partenaires et services instructeurs une liste précise de données à obtenir de l\u0026rsquo;usager (dont souvent des pièces jointes justificatives) une liste de documents à générer Chaque démarche est donc une application spécifique\ndisposant de son propre code pour réaliser des traitements spécifiques comme des appels à des services externes construire des mécaniques visuelles spécifiques embarquant/basée sur une solution logicielle commune (pour ne pas tout réécrire) paramétrable au maximum 1.3.1.2 - Paramétrabilité des applications de démarche Le coeur de ma version de PSL est basé sur la possibilité de créer/modifier des applications à partir d\u0026rsquo;un moteur extrêmement paramétrable. Ce moteur paramétrable\naffiche une application avec sa charte graphique DSFR permet la navigation dans les écrans dont la liste des champs est définie dans la configuration autorise la modification de tous les libellés des pages dans plusieurs langues différentes se base, pour chaque champ, sur la clef unique associée à la donnée (exemple : demandeur.nom ou dateDebut) le type de données : case à cocher, radio, sélection dans une liste finie, sélection par autocomplétion, saisie de texte monoligne, saisie de texte multiligne, pièce jointe (avec son code unique), \u0026hellip; les libellés du champ : son nom et l\u0026rsquo;aide à la saisie la valeur par défaut la condition d\u0026rsquo;affichage : basée sur l\u0026rsquo;évaluation (EVAL de javascript) des autres données saisies par l\u0026rsquo;usager (exemple : demande.nom !== \u0026lsquo;\u0026rsquo;) les validations associées (les validations disponibles sont celles proposées par le framework exclusivement) propose des composants riches permettant la saisie d\u0026rsquo;un ensemble cohérent d\u0026rsquo;information comme la saisie d\u0026rsquo;adresse postale qui gère les adresses en france et à l\u0026rsquo;étranger la saisie d\u0026rsquo;adresse BAN la saisie d\u0026rsquo;IBAN la saisie de blocs multiples de données \u0026hellip; Ce moteur propose aussi d\u0026rsquo;intégrer, dans le déroulé des pages d\u0026rsquo;une démarche, une ou plusieurs pages spécifiques (codée dans la démarche) s\u0026rsquo;exécutant en dehors du moteur paramétrable.\n1.3.1.3 - Le moteur paramétrable Le moteur paramétrable se nomme framework. Il prend la forme d\u0026rsquo;une librairie Angular embarquée dans chaque application. Elle contient\nles composants simples (un composant simple par composant DSFR), les composants riches (permettant la saisie d\u0026rsquo;un ensemble fonctionnellement cohérent de données comme une identité, une adresse, \u0026hellip;) les traitements standards les appels aux APIs PSL la validation de donnée (obligatoire, date, date future, date passée, nombre entier, nombre décimal, min, max, siret, siren, email, expression régulière\u0026hellip;) la conservation de données dans un contexte un rendu graphique standard Chaque version d\u0026rsquo;application embarque (littéralement) une version du framework. Toute modification du framework doit donc entraîner un build et une livraison de toutes les démarches.\n1.3.1.4 - Un schéma Une application de démarche se base donc totalement sur le framework par défaut. Elle ne contient aucun contenu en propre (cas 1 du schéma ci-dessous). Le seul composant (au sens Angular) de cette application est App qui hérite d\u0026rsquo;une classe du framework. Un bon exemple de ce cas de figure est EtatCivil.\nDans le cas d\u0026rsquo;une démarche dont une page contient des composants graphiques non présents dans le framework ou dont la complexité des conditions d\u0026rsquo;affichage est extrême, il est possible de développer spécifiquement la dite page dans le projet de la démarche (cas n°2 du schéma ci-dessus).\nEnfin, une démarche trop complexe ou \u0026lsquo;hors norme\u0026rsquo; peut contenir plusieurs (voire toutes) pages codées spécifiquement (cas n°3 du schéma).\nPour visualiser les réels composants applicatifs, voir :\nla documentation technique de la démarche générique la documentation technique de la démarche spécifique la documentation technique du framework "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.3lesapplicatifs/1.3.2socle/",
	"title": "1.3.2 Le socle",
	"tags": [],
	"description": "",
	"content": "\r1.3.2.1 - Introduction 1.3.2.2 - Les paramètres du socle 1.3.2.3 - Les paramètres publics des applications de démarche 1.3.2.4 - Référentiels 1.3.2.5 - Gestion des documents 1.3.2.5.1 - Stockage des documents 1.3.2.5.2 - Antivirus 1.3.2.6 - Brouillon 1.3.2.7 - Transfert 1.3.2.8 - Notification 1.3.2.7 - Admin 1.3.2.7.1 - LDAP 1.3.2.1 - Introduction Les démarches ne sont que des applications WEB s\u0026rsquo;exécutant dans le navigateur des usagers. Tout le reste constitue le socle applicatif :\nles données de référence les données et documents stockés, lus et mis à jour les traitements et services intelligents dont la soumission des télé-dossiers la validation des données qui revérifie toutes les données envoyées par l\u0026rsquo;application WEB de la démarche en se basant sur les paramètres de cette dernière (base de données CONFIGURATION) la génération des documents se basant sur la configuration propre à chaque type de démarche (configuration présente dans la base de données CONFIGURATION) les envois de mails et de notifications les appels aux APIs externes (IGN, BAN, INSEE, \u0026hellip;) 1.3.2.2 - Les paramètres du socle Les paramètres du socle sont tous les éléments administrables nécessaires aux fonctionnalités :\nparamètres d\u0026rsquo;appel aux APIs externes règles communes de génération de document (encoding des fichiers, \u0026hellip;) 1.3.2.3 - Les paramètres publics des applications de démarche Les paramètres d\u0026rsquo;une telle application prennent la forme d\u0026rsquo;un fichier JSON :\nson contenu est détaillé dans le chapitre 1.3.1.1 Paramétrabilité des démarches son format est validé vis-à-vis d\u0026rsquo;un schéma à chaque modification via l\u0026rsquo;application d\u0026rsquo;administration chaque version est conservée pour disposer d\u0026rsquo;un historique des modifications (permettant l\u0026rsquo;analyse à posteriori des télé-dossiers générés) permettre de modifier la configuration en pleine journée : le socle vérifie les données envoyées par l\u0026rsquo;application WEB vis-à-vis du paramétrage chargé par l\u0026rsquo;utilisateur au début de sa démarche (à partir du numéro de version) 1.3.2.4 - Référentiels La gestion des référentiels est répartie dans deux applicatifs selon qu\u0026rsquo;il est\nà télécharger/intégrer chaque jour : référentiel des communes INSEE, codes postaux, codes INSEE des mairies, \u0026hellip; interrogé systématiquement : BAN, IGN, \u0026hellip; 1.3.2.5 - Gestion des documents Les documents sont de plusieurs natures :\nles pièces jointes fournies par l\u0026rsquo;usager durant sa saisie leur format peut être très divers (paramétrable par pièce jointe) leur poids peut varier énormément le fichier de méta-données est un petit fichier textuel (JSON, CSV, XML ou simplement texte) contenant toutes les informations saisies par l\u0026rsquo;usager et interprétable pas le SI d\u0026rsquo;un partenaire les documents générés sont des documents générés par le Socle et associés au télé-dossier (PDF, XML, CSV, \u0026hellip;) 1.3.2.5.1 - Stockage des documents La base de données contenant ces documents doit conserver, pour chacun, les informations suivantes :\nle contenu du document le nom du document original fourni par l\u0026rsquo;usager (pour les pièces jointes) le code unique de la pièce jointe ou du document généré correspondant au paramétrage de la démarche l\u0026rsquo;identifiant unique du document dans la base de données la date/heure d\u0026rsquo;upload du document par l\u0026rsquo;usager (la date de création dans la base de données) le poids du document (en méta-données pour ne pas le recalculer systématiquement alors qu\u0026rsquo;il est fixe) 1.3.2.5.2 - Antivirus Un antivirus doit être utilisé à chaque upload de document pour valider les documents uploadé par un usager. TODO: à concevoir et développé\n1.3.2.6 - Brouillon Fonctionnellement, un brouillon est la sauvegarde d\u0026rsquo;un état de saisie dans une démarche. Cette sauvegarde peut avoir lieu dès la première page et jusqu\u0026rsquo;à la soumission des informations saisies. Si l\u0026rsquo;utilisateur est connecté via un fournisseur d\u0026rsquo;identité, le lien de reprise de son brouillon est présent dans son fil d\u0026rsquo;actualité. Sinon, l\u0026rsquo;utilisateur doit fournir une adresse email et un mot de passe. Il reçoit alors un email contenant le lien de reprise de sa démarche. Seule la personne à l\u0026rsquo;origine de la sauvegarde du brouillon peut le reprendre en l\u0026rsquo;état (connexion ou par un couple \u0026ldquo;email et mot de passe\u0026rdquo;). Le brouillon contient :\nla référence unique de l\u0026rsquo;utilisateur la version du paramétrage utilisé lors de la sauvegarde si, au chargement d\u0026rsquo;un brouillon, la version de la configuration de la démarche est identique à celle au moment de la sauvegarde du brouillon, l\u0026rsquo;utilisateur reprend sa navigation à la page à laquelle il s\u0026rsquo;est arrêté si la version est différente, l\u0026rsquo;utilisateur reprend sa navigation au début de sa saisie et un algorithme supprime les données précédemment saisies qui n\u0026rsquo;ont plus à l\u0026rsquo;être la référence aux pièces jointes fournies par l\u0026rsquo;usager (nom d\u0026rsquo;origine, identifiant unique en base de données, date\u0026amp;heure de l\u0026rsquo;upload) 1.3.2.7 - Transfert L\u0026rsquo;applicatif transfert est responsable de la transmission de chaque télé-dossier vers le (ou les) partenaire(s) configurés.\n1.3.2.8 - Notification L\u0026rsquo;applicatif notification est responsable de l\u0026rsquo;envoi de mails et de notifications quand les applicatifs brouillon et soumission le nécessite.\n1.3.2.7 - Admin L\u0026rsquo;application d\u0026rsquo;administration permet :\ngérer la liste des démarches gérer les utilisateurs gérer les référentiels de données stockées gérer les configurations publiques et internes suivre, surveiller et gérer les transferts vers les partenaires 1.3.2.7.1 - LDAP Un service LDAP stocke les données des utilisateurs pouvant accéder à l\u0026rsquo;application d\u0026rsquo;administration.\n"
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.3lesapplicatifs/1.3.3outils/",
	"title": "1.3.3 Les outils",
	"tags": [],
	"description": "",
	"content": "En plus de la partie applicative (FRONT et BACK) et de la présente documentation, un ensemble d\u0026rsquo;outils existent pour faciliter la construction de ce SI :\nl\u0026rsquo;outil de rétro-ingénierie permettant d\u0026rsquo;initialiser une configuration publique de démarche à partir d\u0026rsquo;une démarche existante de l\u0026rsquo;ancienne PSL l\u0026rsquo;éditeur de configuration publique est accessible comme tout autre application WEB de démarche est uniquement installée sur un environnement hors production permet de passer d\u0026rsquo;étape en étape dans la navigateur ajoute, dans la toute première étape de la saisie, de modifier la configuration de tester cette configuration immédiatement et de recommencer infiniment les outils techniques sont des exécutables Java à utiliser depuis Eclipse et présents des projets du Socle : La classe OutilRecuperationTemplateDeDocumentEtape1 permet, à partir d\u0026rsquo;un code de démarche, de lister les templates de document présents dans les sources de l\u0026rsquo;ancienne PSL, d\u0026rsquo;en extraire les clefs et d\u0026rsquo;initier un fichier de mapping avec toutes les clefs que la démarche publique devra couvrir. La classe OutilRecuperationTemplateDeDocumentEtape2 permet, à partir d\u0026rsquo;un code de démarche, de copier les templates existants dans l\u0026rsquo;ancienne PSL et d\u0026rsquo;en modifier les clefs à partir du fichier de mapping complété. Ces templates sont ensuite disponibles dans les sources du projet socle-dbconfiguration afin d\u0026rsquo;en initialiser le jeu de données (à la demande). La classe OutilModificationTemplateDeDocumentPdf permet de modifier les clefs d\u0026rsquo;un fichier PDF précis. les tests de la classe GenerationServiceDepuisSourcesFrontTest permettent de simuler la génération des documents à partir des éléments présents dans l\u0026rsquo;ensemble des sources : une configuration interne et des templates présents dans socle-dbconfiguration une configuration publique présente dans les sources de la démarche (fichier de bouchon d\u0026rsquo;une application Angular) des données présentes dans un brouillon présent dans les sources de la démarche (fichier de bouchon d\u0026rsquo;une application Angular) "
},
{
	"uri": "http://localhost:1313/documentation/1conceptiongenerale/1.3lesapplicatifs/1.3.4retroingenierie/",
	"title": "1.3.4 Rétro-ingénierie",
	"tags": [],
	"description": "",
	"content": "Pour initialiser une configuration publique de démarche, est disponible un outil\nbasé sur la librairie de test d\u0026rsquo;application WEB Cypress (semblable à Protractor ou Selenium) capable de naviguer dans une application existante (déployée en local) à partir d\u0026rsquo;une URL de brouillon extrayant la substance de l\u0026rsquo;application pour créer une première version de la configuration (pages, libellés, champs, validations, composants\u0026hellip;) générant un brouillon dans la nouvelle PSL avec les mêmes données Pour initialiser les templates de la démarche, sont disponibles, dans le projet socle-dbconfiguration, deux outils :\nLe premier outil, nommé OutilRecuperationTemplateDeDocumentEtape1, permet de lister les templates disponibles dans le code des démarches existantes et d\u0026rsquo;en extraire toutes les clefs dans un fichier socle/socle-dbconfiguration/src/main/resources/db/${codeDemarche}-mappingDesClefsDeTemplate.properties A ce moment, est nécessaire un travail de fourmi pour définir, dans le fichier de mapping, pour chaque clef existante dans un vieux template, une clef issue de la configuration publique de la démarche (il est possible de s\u0026rsquo;aider d\u0026rsquo;un brouillon). Enfin, une fois le fichier de mapping complété, le second outil, nommé OutilRecuperationTemplateDeDocumentEtape2, copie les vieux templates, remplace les clefs et les stockent dans les ressources du projet socle-dbconfiguration Ne reste plus qu\u0026rsquo;à modifier la configuration interne de la démarche pour référencer les templates. "
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/",
	"title": "2. Conception détaillée",
	"tags": [],
	"description": "",
	"content": "Chapitre 2 Conception détaillée Ce chapitre décrit quels principes de conception que j\u0026rsquo;ai retenus :\nsegmentation fonctionnelle \u0026amp; technique architecture micro-service et en couche configurations Maven, Spring et applicatives principes, objectifs, règles et outils de tests \u0026hellip; La description de la mise en œuvre de ces principes dans les technologies choisies est dans le chapitre suivant.\nLes chapitres suivants sont 2.1 Introduction 2.2 Principes de conception du BACK 2.3 Principes de conception du FRONT 2.4 Principes de conception communs 2.5 Principes de rédaction documentaire 2.6 Fonctionnalités 2.7 Fonctionnalités Cloud 2.8 Sécurité 2.9 Liens documentaires 2.10 Documentation utilisateur "
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/2.1introduction/",
	"title": "2.1 Introduction",
	"tags": [],
	"description": "",
	"content": "\r2.1.1 - Objectifs de la documentation détaillée 2.1.2 - Les grands ensembles dans le code 2.1.1 - Objectifs de la documentation détaillée La conception détaillée a pour objectif de fournir des informations précises sur les fonctionnalités du système et sur la répartition de ces fonctionnalités dans les applicatifs, leurs couches et leurs composants.\nOr la meilleure documentation détaillée est celle présente dans le code.\nDonc une bonne partie de ce chapitre s\u0026rsquo;appuie sur la documentation générée depuis le code (définition de javadoc et JXR). Le chapitre 2.9 liens documentaires rassemble les liens documentaires.\n2.1.2 - Les grands ensembles dans le code Le dépôt de code de la solution est séparé en plusieurs grands ensembles :\nle répertoire 1-conception contient la documentation de l\u0026rsquo;ensemble de la solution. Cela comprend des éléments d\u0026rsquo;architecture, fonctionnels, techniques et des guides pour l\u0026rsquo;équipe. Cette documentation se fera au plus près du code au point d\u0026rsquo;être versionnée avec le code. Ainsi, chaque partie d\u0026rsquo;une fonctionnalité de la solution sera relue, de sa documentation à ses tests automatisés. le répertoire 2-code/socle contient le code du BACK, le socle applicatif Java portant les fonctionnalités du stockage des données jusqu\u0026rsquo;aux APIs exposant des services. le répertoire 2-code/front contient le code du FRONT, le framework et les applications WEB de démarche (sommaire description au chapitre 1.3.1). le répertoire 2-code/ias contient le code du projet Ansible permettant d\u0026rsquo;installer, déployer et démarrer l\u0026rsquo;ensemble des applicatifs. "
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/2.2principesconceptionduback/",
	"title": "2.2 Principes de conception du BACK",
	"tags": [],
	"description": "",
	"content": "\r2.2.1 - Découpage en micro-service 2.2.2 - Gestion commune des dépendances 2.2.3 - Design pattern en couches 2.2.4 - Gestion de la configuration 2.2.5 - Séparation de l\u0026rsquo;application et de ses tests 2.2.6 - le \u0026ldquo;10mn buld\u0026rdquo; 2.2.7 - les logs Ce chapitre liste les principaux principes de conception du Back.\n2.2.1 - Découpage en micro-service Le code du BACK est construit sous forme de micro-services. Un micro-service est un applicatif\nautonome : Capable de démarrer seul et proposant des fonctionnalités sous forme de service (exemple : à défaut d\u0026rsquo;une base de données démarrée, un applicatif autonome peut renvoyer une réponse contenant un message d\u0026rsquo;erreur). cohérent : Les services qu\u0026rsquo;il fournit sont fonctionnellement liés entre eux et forment un tout qui a du sens (contre-exemple : il ne fait pas le lit en fournissant le café et nettoyant la mousse sur les tuiles du toit de la maison). faiblement couplé : L\u0026rsquo;applicatif n\u0026rsquo;a pas besoin d\u0026rsquo;interroger tout un ensemble d\u0026rsquo;autres applicatifs pour fournir ses services. de bonne granularité : Il fournit plus d\u0026rsquo;un service mais pas des centaines non plus. La granularité est un autre point de vue sur la dualité cohérence/couplage. Sur ce projet (comme souvent), la bonne granularité est définie via les données traitées/stockées. Ainsi chaque micro-service du socle traite de données différentes sans couplage fort entre elles (une référence par un identifiant est autorisée mais pas de contraintes structurelles ou métiers comme le ferait une ForeignKey SQL). 2.2.2 - Gestion commune des dépendances Malgré la multiplication des applicatifs, il est important qu\u0026rsquo;une homogénéité soit conservée dans la gestion des dépendances tant pour faciliter le maintien en conditions opérationnelles du SI que dans son maintien en conditions de sécurité (simplification de la veille sécuritaire).\n2.2.3 - Design pattern en couches Les composants applicatifs Java des micro-services sont répartis selon le design pattern en couches (explications Oreilly). L\u0026rsquo;idée est que chaque composant applicatif, en fonction de ce qu\u0026rsquo;il fait, est placé dans une couche applicative. Une couche, dans le code, se matérialise par un package précis et des suffixes de nom de classe. La dernière contrainte apportée par ce pattern est la communication entre les composants : un composant ne peut appeler que un composant de la couche inférieur et ne peut être appelé que par un composant de la couche supérieur (et sans saut de couche). Les dites couches sont :\ncontrôleur (package controlleur et suffixe Controleur) : cette couche contient des composants exposant des méthodes JAVA sous forme d\u0026rsquo;API REST avec Spring MVC service (package service et suffixe Service) : ces composants contiennent toute l\u0026rsquo;intelligence et l\u0026rsquo;algorithmie des applicatifs. Les transactions débutent à l\u0026rsquo;entrée d\u0026rsquo;un service et se terminent à la sortie du dit service. A défaut de transaction, le service doit prévoir des mécaniques de compensation (transaction \u0026amp; Spring). dao (package dao et suffixe Dao) : ces composant traite du stockage ([S]CRUD) de données quelque soit le conteneur (base de données SQL ou noSQL. dto (package dto et suffixe Dto) et/ou objets métiers (package entity) sont les deux couches qui n\u0026rsquo;en sont pas. Ces deux ensembles contiennent les classes décrivant les données gérées par l\u0026rsquo;application. Ces éléments traversent les couches. Ces deux couches sont donc transverses. Attention, 3 concepts différents sont en jeu ici : un DTO est un objet de transport (Data Transport Object). Son objectif est de décrire des données dont la structure est utilisée dans un contexte précis (exemple : pour afficher le nombre et la moyenne d\u0026rsquo;âge des clients regroupés par la première lettre de leur prénom, il nous faut une liste d\u0026rsquo;objet contenant les 3 attributs premiereLettrePrenomClient, ageMoyen et nombreDeClients). un objet métier est une classe décrivant une structure de données ayant un sens réel pour l\u0026rsquo;utilisateur (exemple : un système de facturation contiendra des objets métiers comment Facture, LigneDeFacture, LigneComptable, \u0026hellip;) et contenant du code intelligent. Ainsi, un service métier peut appeler du code intelligent présent dans un objet métier (exemple : Facture.calculerSommeDesLignesDeFacture voir même Facture.genererFactureEnPdf) une entité persisté (alias entity) est une classe décrivant une structure de données de stockage. Existent des débats sur le fait d\u0026rsquo;exposer des entités persistées en sortie des contrôleurs (exposition de la structure de la base de données) ou sur le fait de ne pas distinguer entités persistées et objets métiers (je n\u0026rsquo;ai pas de bon argument pour cette distinction). Les choix de ce projet sont : Il ne faut pas faire de distinction entre une entité persistée et un objet métier. Il est légitime de développer une méthode intelligente dans une classe mappée avec Hibernate si cela a du sens. un objet métier peut être renvoyé en sortie d\u0026rsquo;une API. D\u0026rsquo;autres noms réservés de package et d\u0026rsquo;autres règles de nommage existent. Elles sont décrites dans le chapitre 3.21.2 Règles de nommage\n2.2.4 - Gestion de la configuration La configuration des applications (bien que fortement basée sur les paramètres par défaut offerts par Spring) fait l\u0026rsquo;objet de choix assez particuliers :\nLe projet socle-commun contient tous les fichiers de configuration nécessaires pour faire fonctionner un applicatif métier du socle dans le répertoire src/main/resources (pour être embarqués et disponibles pour les artefacts dépendants de ce projet). Chaque fonctionnalité/librairie fait l\u0026rsquo;objet d\u0026rsquo;un fichier de configuration différent afin d\u0026rsquo;en facilité la documentation et la maintenance (log, swagger, jwt, serviceregistry et administration par exemple). 2.2.5 - Séparation de l\u0026rsquo;application et de ses tests La séparation des sources applicatives et sources de test est induite par l\u0026rsquo;utilisation de Maven (documentation officielle). Le principe est double :\nséparer l\u0026rsquo;applicatif dans src/main/ des tests dans src/test/ séparer le code dans src/xxx/java/ des ressources dans src/xxx/resources 2.2.6 - le \u0026ldquo;10mn buld\u0026rdquo; La pratique 10mn build (documentation) a pour objectif que la compilation de la solution doit être la plus rapide possible pour que soit le plus court possible le temps entre le push du développeur et la fin de la vérification de la qualité de son code (merci à la PIC\n2.2.7 - les logs Les micro-services pouvant s\u0026rsquo;appeler entre eux, il n\u0026rsquo;est pas pertinent de tracer les appels HTTP au niveau de la Gateway (surtout que le faire avec Netty est pénible). Les accessLog sont donc générés au niveau de chacun des micro-services via le fichier de configuration application-accesslog.properties présent dans le projet socle-commun.\n"
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/2.3principesconceptiondufront/",
	"title": "2.3 Principes de conception du FRONT",
	"tags": [],
	"description": "",
	"content": "\r2.3.1 - Gestion commune des principales dépendances (via le workspace Angular) 2.3.2 - Segmentation du code 2.3.3 - conception du framework 2.3.4 - tests automatisés 2.3.1 - Gestion commune des principales dépendances (via le workspace Angular) L\u0026rsquo;ensemble du code du FRONT est rassemblé dans un workspace Angular. Ce workspace permet que tous les applicatifs FRONT puissent\nêtre dépendants les uns des autres (sans publier de version dans un repository NPM/YARN) ; partager les mêmes dépendances (pour ne pas avoir une version d\u0026rsquo;Angular différente d\u0026rsquo;une démarche à une autre). 2.3.2 - Segmentation du code L\u0026rsquo;ensemble du code du FRONT se segmente, assez logiquement, en différents applicatifs (moins nombreux que le socle) : Le code du FRONT est construit dans un workspace Angular. Les différents projets existants sont :\nLe framework est une librairie contenant toute l\u0026rsquo;intelligence d\u0026rsquo;une application frontale PSL dont le moteur se basant sur les fichiers de configuration d\u0026rsquo;une application de démarche. La partie CYPRESS du framework contient les classes d\u0026rsquo;exécution des tests E2E. L\u0026rsquo;application Edition permet de construire et tester une configuration publique d\u0026rsquo;application de démarche. Chaque type de démarche donnant lieu à une application Angular distincte. 2.3.3 - conception du framework Le framework de ma PSL est un ensemble de classes et de composants codés en Typescript soutenant le fonctionnement de toutes les démarches de la nouvelle PSL. Ce framework n\u0026rsquo;est pas exécutable en l\u0026rsquo;état car il n\u0026rsquo;est qu\u0026rsquo;une librairie présente dans l\u0026rsquo;espace de travail Angular (cf. noeud /projects/framework/projectType dans le fichier 2-code/front/angular.json. Il doit être utilisé depuis une application. Mais le framework est conçu pour que le volume de code et de configuration de chaque application de démarche soit le plus réduit et le plus simple possible.\nEn lui-même, le framework se divise en deux parties :\nle code applicatif dans le répertoire 2-code/front/projects/framework/src/lib le code utilitaire pour Cypress dans le répertoire 2-code/front/projects/framework/cypress Côté applicatif, existent\ndes classes de modèle (des DTO) fournissant une structure correspondant aux données manipulées : la structure d\u0026rsquo;un brouillon de démarche la structure de la configuration de démarche (en deux fichiers TS) les données liées à la sécurité OIDC la structure des messages affichables à l\u0026rsquo;usager des composants de service contenant l\u0026rsquo;intelligence et toutes les fonctionnalités subtiles : le service statefull contenant toutes les données saisies page après page (uniquement les données validées au clic sur le bouton SUIVANT) le service statefull contenant les BehaviorSubject permettant aux composants d\u0026rsquo;interagir entre eux sur des évènements globaux les services stateless de gestion des bouchons (statut courant et jeux de données), des brouillons (sauvegarde et chargement), configuration (chargement et prise en compte), pièces jointes (upload), document (liste et download post-soumission), formulaire (création à partir de la configuration), sécurité OIDC, appels au référentiels, sécurité (plus golobalement que l\u0026rsquo;OIDC), appel au service de soumission et validation des données saisies. des composants WEB structurant de l\u0026rsquo;application :entête, pied de page, fil d\u0026rsquo;Ariane, page des composants paramétrables spécifiques correspondant à chaque besoin : paragraphe, saisie de texte, saisie de date, saisie d\u0026rsquo;adresse, \u0026hellip; des classes utilitaires Les services les plus complexes à appréhender sont ceux se basant sur des fonctionnalités riches d\u0026rsquo;Angular (pas les appels à une API du socle) :\ncontexte.service.ts est basé sur un principe simple : tout évènement important (connexion réussie, changement de page, affichage d\u0026rsquo;un message à l\u0026rsquo;usager, chargement de la configuration, soumission, \u0026hellip;) est notifié dans un BehaviorSubject à travers une methode ayant un véritable sens fonctionnel. De plus, ce composant de contexte retient/conserve les données dont la durée de vie est le déroulement de la démarche par l\u0026rsquo;usager (on perd tout si on recharge la page). Enfin, ce composant expose des méthodes public obtenirUnObservableSurxxx(): Observable permettant à tout composant de l\u0026rsquo;application de déclencher du code suite à la publication d\u0026rsquo;un évènement. formulaire.service.ts est le gros algorithme utilisant, à fond, les fonctionnalités de formulaire \u0026ldquo;reactive\u0026rdquo; d\u0026rsquo;Angular. En quelques lignes, à travers les APIs TS d\u0026rsquo;Angular, est créée une instance de FormGroup représentant l\u0026rsquo;ensemble du formulaire de la page et un FormControl pour chaque champ de saisie de la dite page. La configuration/manipulation/lecture/miseAjour/\u0026hellip; de ces champs se fait alors exclusivement dans le code TS. L\u0026rsquo;objectif est là de déplacer la compléxitée de la configuration de chaque champ de la page HTML (modèle des fomulaire template-driven) vers le code TS. Ainsi, le code de chaque type de composant (liste déroulante, radio, checkbox, \u0026hellip;) reste simple car la compléxité est traitée de manière centrale dans le service formulaire.service.ts. 2.3.4 - tests automatisés Les tests automatisés des écrans ne sont pas développé spécifiquement pour chaque démarche (sauf pour les parties de code codées en spécifique). Ces tests se basent, eux aussi, sur la configuration de la démarche et une partie du code du framework dédiée (tout le contenu du répertoire 2-code/front/projects/framework/cypress).\nCes tests automatisés se basent sur l\u0026rsquo;outil Cypress (framework de test encouragé par Angular en remplacement de Protractor). Chaque projet de démarche contient donc une configuration Cypress et un fichier 2-code/front/projects/codedemarche/cypress/e2e/codedemarche.cy.ts démarrant les tests :\nchargement de la ressource statique de configuration bouchonnée (URL fournie depuis codedemarche.cy.ts) chargement de la ressource statique du brouillon bouchonné (URL fournie depuis codedemarche.cy.ts) calcul de tous les scénarios possibles selon les différents points d\u0026rsquo;entrée (toutes les combinaisons de paramètre d\u0026rsquo;entrée) démarrage de tous les scénarios en chargeant l\u0026rsquo;application à partir de l\u0026rsquo;URL (sans usage du brouillon) navigation de page en page en renseignant les champs avec les données du brouillon vérification des libellés, de la présence/activation des pages/bloc/champs selon les conditions paramétrées /!\\ L\u0026rsquo;exécution des tests E2E ne peut se faire que si l\u0026rsquo;ensemble des bouchons sont actifs dans l\u0026rsquo;application Angular (pour disposer d\u0026rsquo;un jeu de donnée fixe et ne pas avoir de redirection sur un site externe pour l\u0026rsquo;authentification).\n"
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/2.4principesconceptionfrontetback/",
	"title": "2.4 Principes de conception communs",
	"tags": [],
	"description": "",
	"content": "\r2.4.1 - Conception depuis le besoin 2.4.2 - Format d\u0026rsquo;échange JSON 2.4.3 - Sémantique REST 2.4.4 - Sécurisation des APIs REST Les éléments de conception communs au Front et au Back se situent tous au niveau de la conception des APIs.\n2.4.1 - Conception depuis le besoin Les APIs exposées aux démarches comme aux autre micro-services (et donc les services qui sont derrière) se conçoivent à partir du besoin (et de la faisabilité bien-sûr). Ceci comprend le choix des paramètres (et de leur type) et les données retournées.\n2.4.2 - Format d\u0026rsquo;échange JSON Toute donnée issue d\u0026rsquo;une API du socle doit être au format JSON. Même si cette donnée n\u0026rsquo;est qu\u0026rsquo;une simple chaîne de caractères (comme un identifiant dans BrouillonControlleur).\n2.4.3 - Sémantique REST Tous les services métiers développés dans les micro-services du socle ont pour objectif d\u0026rsquo;être utilisés depuis une application FRONT Angular ou depuis un autre micro-service. Ceci passe donc par une API REST. Ces APIs doivent respecter les règles de base de la sémantique REST (pas forcément l\u0026rsquo;ensemble de cette sémantique) :\nUne URL doit désigner une ressource précise (à un instant donné en tout cas). Tout service appelé via une API doit être stateless (plus généralement, tout service métier du socle doit être stateless). Les méthodes HTTP doivent être correctement : POST pour créer une donnée ou exécuter une recherche multi-critère GET pour lire une ou plusieurs données PUT pour mettre à jour tous les attributs d\u0026rsquo;une donnée existante PATCH pour mettre à jour un ou plusieurs (pas tous) attributs d\u0026rsquo;une donnée existante DELETE pour supprimer une donnée Les types de média utilisables sur ce projet sont limités : application/json pour tout échange de données (notamment pour les réponses retournant des données structurées) ; multipart/formdata pour les télé-versements bruts de pièce jointe ; tous les types de média associés au téléchargement d\u0026rsquo;un document comme application/pdf ou image/png, \u0026hellip; 2.4.4 - Sécurisation des APIs REST Toutes ces APIs (sauf certaines du projet socle-securite) sont protégées par des filtres vérifiant que la requête contient un jeton d\u0026rsquo;autorisation.\nCe jeton, dans le cas du socle, est un token JWT. Ce dernier est créé via un appel aux APIs du projet socle-securite (c\u0026rsquo;est pour ça que ces APIs ne sont pas toutes sécurisées) et il contiendra toutes les données de l\u0026rsquo;utilisateur connecté.\nFonctionnement, même dans le cas d\u0026rsquo;un usager d\u0026rsquo;une démarche non-connectée, un token sera créé. Ceci permet de limiter l\u0026rsquo;usage frauduleux des APIs (comme les APIs de référentiel) mais aussi de faire un suivi assez fin des appels via les access.log.\nInformation utile : le site jwt.io permet de lire la partie publique d\u0026rsquo;un token JWT.\n"
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/2.5principeconceptiondocumentaire/",
	"title": "2.5 Principes de rédaction documentaire",
	"tags": [],
	"description": "",
	"content": "\r2.5.1 - Accessibilité (au sens compréhension et pas RGAA) 2.5.2 - Chapitrage 2.5.3 - Mise en forme 2.5.4 - Automatisation Le présent chapitre n\u0026rsquo;est pas exclusivement à destination des développeurs. D\u0026rsquo;où sa présence ici. Mais un minimum d\u0026rsquo;outils sont nécessaires pour modifier la documentation (cf. §3.31)\n2.5.1 - Accessibilité (au sens compréhension et pas RGAA) La documentation doit être lisible et accessible à tous. En conséquence, il ne faut pas hésiter à ajouter des liens vers des documents/ressources externes permettant ainsi d\u0026rsquo;utiliser une notion sans la détailler complètement.\n2.5.2 - Chapitrage Le chapitrage sert un objectif d\u0026rsquo;abstraction et vulgarisation :\nLe premier chapitre Conception générale s\u0026rsquo;adresse à des personnes ne maîtrisant pas les technologies employées dans la solution. Le second chapitre Conception détaillée s\u0026rsquo;adresse aux personnes maîtrisant ces technologies mais ne développant pas sur le projet. Le troisième (Guide du développeur) et le quatrième chapitre (Ops) sont dédiés aux développeurs. 2.5.3 - Mise en forme D\u0026rsquo;un point de vue mise en forme :\nLes mots ou expression en gras sont des mots clefs permettant de rechercher visuellement un sujet dans la page (entre deux doubles étoiles). Les mots clefs ou anglicisme sont en italique (entre deux underscores). La numérotation des chapitres et le paramètre weight de chaque page doivent être cohérents entre eux. Le titre d\u0026rsquo;une page et le nom du fichier associés doivent être identiques. 2.5.4 - Automatisation La date de mise à jour est un hook paramétré sur le checkout du dépôt (cf. §3.2).\n"
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/2.6fonctionnalites/",
	"title": "2.6 Fonctionnalités",
	"tags": [],
	"description": "",
	"content": "\r2.6.1 - Index des fonctionnalités et règles de gestion 2.6.1.1 - Fonctionnalités paramétrables dans la configuration publique 2.6.1.2 - Fonctionnalités paramétrables dans la configuration interne 2.6.1.3 - Fonctionnalités de sécurité 2.6.1.4 - Fonctionnalités de type cloud 2.6.1.5 - Fonctionnalités métier 2.6.2 - Fonctionnalités techniques 2.6.2.1 - Les bases de données 2.6.2.2 - La centralisation/gestion des micro-services du Back 2.6.2.3 - Les logs 2.6.2.5 - Détails sur l\u0026rsquo;intégration des référentiels sur Internet pour créer les référentiels PSL 2.6.3 - Fonctionnalités FRONT \u0026amp; BACK 2.6.4 - Fonctionnalités de l\u0026rsquo;EDITEUR 2.6.5 - Fonctionnalités des tests E2E Comme cela est décrit sommairement dans le chapitre 1.3, la solution est constituée\nd\u0026rsquo;une application WEB pour chaque type de démarche mis à disposition des usagers, d\u0026rsquo;un moteur paramétrable constituant 50 à 99% du code d\u0026rsquo;une application WEB de démarche, d\u0026rsquo;un ensemble de micro-services exposant des fonctionnalités utilisables depuis les applications WEB, de services transverses de gestion/administration/paramétrage de l\u0026rsquo;ensemble L\u0026rsquo;ensemble de ces fonctionnalités sont décrites ci-dessous.\n2.6.1 - Index des fonctionnalités et règles de gestion 2.6.1.1 - Fonctionnalités paramétrables dans la configuration publique FP01 Configuration publique - Identification unique d\u0026rsquo;une démarche et de ses configurations publiques :\nFP01-R01 Une démarche est identifiée par son code unique (attention aux majuscules et minuscules) FP01-R02 Une configuration publique de démarche est identifiée par le code de la démarche associée et par sa version. FP01-R03 Le titre présent dans la configuration publique est le titre affiché dans l\u0026rsquo;onglet du navigateur de l\u0026rsquo;usager. FP01-R04 A l\u0026rsquo;arrivée d\u0026rsquo;un usager sur la page WEB d\u0026rsquo;une démarche, est toujours chargée la dernière configuration publique active et disponible. FP02 Configuration publique - Gestion des points d\u0026rsquo;entrée :\nFP02-R01 Un point d\u0026rsquo;entrée est une configuration permettant de fixer des règles d\u0026rsquo;accès à la démarche en fonction de l\u0026rsquo;état OIDC de l\u0026rsquo;usager (usager connecté avec SP, usager connecté avec FC ou usager non connecté) et/ou de paramètres dans l\u0026rsquo;URL (souvent utilisé pour choisir un parcours). FP02-R02 Le paramètre brouillon n\u0026rsquo;est pas utilisable dans le cas des points d\u0026rsquo;entrée car il est utilisé dans le cas du chargement d\u0026rsquo;un brouillon préalablement sauvegardé. FP02-R03 Dans une configuration publique de démarche, si aucun point d\u0026rsquo;entrée n\u0026rsquo;est paramétré, l\u0026rsquo;accès à la démarche peut se faire sans paramètre et aucune identification de l\u0026rsquo;usager n\u0026rsquo;est exigée. FP02-R04 Dans une configuration publique de démarche, il est possible d\u0026rsquo;utiliser un paramètre de l\u0026rsquo;URL pour pré-initialiser une valeur et donc choisir un scénario de la démarche (modèle des démarches etatCivil et arnaqueInternet par exemple) FP02-R03 Dans une configuration publique de démarche, il est possible de définir plusieurs scénarii de démarche différents exigeant des identifications différentes (anonyme, SP ou FC). FP02-R04 Une démarche dont la configuration publique définit exclusivement un ou plusieurs points d\u0026rsquo;entrée connecté est qualifiée de démarche connectée FP02-R05 Une démarche dont la configuration publique ne définit aucun point d\u0026rsquo;entrée ou définit exclusivement un ou plusieurs points d\u0026rsquo;entrée non-connecté est qualifiée de démarche non-connectée FP02-R06 Une démarche dont la configuration publique définit au moins un point d\u0026rsquo;entrée non-connecté et un point d\u0026rsquo;entrée connecté est qualifiée de démarche hybride FP03 Configuration publique - Fonctionnalités configurables :\nFP03-R01 Il est possible d\u0026rsquo;activer la sauvegarde de brouillon depuis la configuration d\u0026rsquo;une démarche \u0026ldquo;fonctionnalites\u0026rdquo;:{\u0026ldquo;brouillon\u0026rdquo;:true}. Ainsi la démarche affiche le bouton Reprendre plus tard. Le détails des possibilités liées au brouillon font l\u0026rsquo;objet d\u0026rsquo;un chapitre dans cette page. FP03-R02 Deux modes de saisie sont possibles. Dans le premier (par défaut), tous les champs sont optionnels et les champs obligatoires ont leur libellé précédé d\u0026rsquo;une étoile rouge. Dans le second mode (activable depuis la configuration de la démarche avec \u0026ldquo;fonctionnalites\u0026rdquo;: {\u0026ldquo;modeObligatoireParDefaut\u0026rdquo;: true}), le libellé des champs optionnels est suivi par la mention [facultatif]. FP03-R03 Le deuil est aussi activable via la configuration de la démarche : \u0026ldquo;fonctionnalites\u0026rdquo;: {\u0026ldquo;deuil\u0026rdquo;: true}. FP04 Gestion des brouillons :\nFP04-R01 Si une démarche, à son chargement, a un paramètre brouillon dans l\u0026rsquo;URL, les données d\u0026rsquo;un brouillon dont l\u0026rsquo;ID est égale à la valeur du paramètre est chargé. FP04-R02 Si aucun brouillon n\u0026rsquo;existe avec cet identifiant, un message d\u0026rsquo;erreur s\u0026rsquo;affiche mais la démarche est réalisable (sans aucune donnée initialisée). FP04-R03 Au clic sur le bouton Reprendre plus tard par l\u0026rsquo;usager, dans une démarche hybride avec un usager connecté ou une démarche connectée (cf. FP02), l\u0026rsquo;API de sauvegarde d\u0026rsquo;un brouillon est appelée. dans une démarche hybride avecun un usager non connecté ou une démarche non-connectée (cf. FP02), un formulaire demandant la saisie d\u0026rsquo;un email et d\u0026rsquo;un mot de passe apparaît. A la validation de ce formulaire, l\u0026rsquo;API de sauvegarde d\u0026rsquo;un brouillon est appelée. FP04-R04 A l\u0026rsquo;appel de l\u0026rsquo;API de sauvegarde d\u0026rsquo;un brouillon, toutes les informations saisies par l\u0026rsquo;usager ainsi que ces informations personnelles éventuellement obtenues via SP ou FC sont envoyées à l\u0026rsquo;API et sont sauvegardées. FP04-R05 Après la création d\u0026rsquo;un brouillon, le code de l\u0026rsquo;API, dans le cas d\u0026rsquo;une démarche hybride avec un usager connecté ou une démarche connectée (cf. FP02), crée une notification dans le fil d\u0026rsquo;actualité du compte Service-Public.fr de l\u0026rsquo;usager. Le contenu de la notification est paramétrable. dans le cas d\u0026rsquo;une démarche hybride avec un un usager non connecté ou une démarche non-connectée (cf. FP02), envoie un email (à l\u0026rsquo;adresse saisie dans le formulaire). Le contenu de l\u0026rsquo;email est paramétrable. FP04-R06 [TODO] Au chargement d\u0026rsquo;un brouillon, si la version de configuration publique chargée est différente de la version de la configuration chargée au moment de la sauvegarde du brouillon, l\u0026rsquo;usager est positionné sur la première étape de la démarche (et ses données sont toujours pré-saisies dans les champs) FP05 Configuration publique - la liste des pages, des blocs et des contenus\nFP05-R01 La description détaillée d\u0026rsquo;une démarche se compose de pages : une page est définie par un titre, obligatoire, affiché en haut de l\u0026rsquo;écran de l\u0026rsquo;usager, sous le fil d\u0026rsquo;Ariane un titreAriane, optionnel, utilisé dans le fil d\u0026rsquo;Ariane exclusivement (par défaut, le titre est utilisé) un drapeau optionnel exclueDuFilDariane permettant que la page ne soit ni visible ni accessible depuis le fil d\u0026rsquo;Ariane. Si ce drapeau a la valeur true, alors l\u0026rsquo;étape visiblement active dans le fil d\u0026rsquo;Ariane sera celle de la précédente page dont le drapeau exclueDuFilDariane est absent ou false. un drapeau optionnel specifiqueAlaDemarche définissant que cette page n\u0026rsquo;est pas décrite dans la configuration mais développée spécifiquement dans la démarche. une conditionVisibilite, optionnelle, permettant de rendre dynamique l\u0026rsquo;affichage de la page et de ses blocs (cf. R04) une liste de blocs (cf. ci-dessous) de blocs : un bloc est défini par un titre, optionnel, affiché en haut du bloc une conditionVisibilite, optionnelle, permettant de rendre dynamique l\u0026rsquo;affichage du bloc et de ses contenus (cf. R04) une liste de contenus (cf. ci-dessous) de contenus : un contenu est défini par un type, obligatoire, définissant le type de saisie possible une clef rendant unique le contenu dans sa page (la clef est obligatoire pour les champs de saisie uniquement) un titre, optionnel, définissant un libellé aux champs de saisie une aide, optionnelle, affichée au clic sur une icône et guidant l\u0026rsquo;usager sur l\u0026rsquo;objet de la saisie une conditionVisibilite, optionnelle, permettant de rendre dynamique l\u0026rsquo;affichage du contenu (cf. R04) une conditionDesactivation, optionnelle, permettant de rendre inerte/désactivé le contenu de saisie (cf. R04) d\u0026rsquo;autres champs selon le type de contenu (par exemple : validationsSimples, validationsComplexes, valeurs, api, attributReponseApiPourLibelle, \u0026hellip;) FP05-R02 Les blocs peuvent être simples (comme décrit dans R01) ou dynamiques. Si le bloc contient l\u0026rsquo;attribut \u0026ldquo;dynamique\u0026rdquo;:\u0026ldquo;true\u0026rdquo; alors apparaissent des boutons pour ajouter, supprimer ou modifier des occurences de ce bloc. L\u0026rsquo;attribut maxOccurences permet de limiter le nombre d\u0026rsquo;occurences. Tous les contenus d\u0026rsquo;un bloc dynamique doivent contenir les caratères @@ qui seront remplacés par le numéro de l\u0026rsquo;occurence du bloc. FP05-R03 Les types de contenus possibles sont : adresseFrOuEtr : saisie d\u0026rsquo;une adresse française ou étrangère. autocompletion : auto-complétion à partir des données exposées par une API. case : case à cocher. contactPersonnel : saisie des informations personnelles d\u0026rsquo;un usager permettant de le contacter. date : saisie d\u0026rsquo;une date (sans heure) finDemarcheConnecte : formulaire à afficher en fin de démarche pour confirmer la validation identite : saisie des informations personnelles d\u0026rsquo;un usager permettant de le définir complètement. listeFinie : liste déroulante de choix. paragraphe : simple texte pur ou HTML. radio : choix à sélectionner via un RADIO. recapitulatif : récapitulatif des données saisies par l\u0026rsquo;usager. saisie : saisie de texte. saisieLongue : saisie de texte multi-lignes. documents : description et lien de téléchargement d\u0026rsquo;un document mis à la disposition de l\u0026rsquo;usager. uploadDocument : sélection d\u0026rsquo;un fichier à télé-verser depuis l\u0026rsquo;ordinateur de l\u0026rsquo;usager. usagerConnecte : composant d\u0026rsquo;affichage des informations personnelles de l\u0026rsquo;usager connecté. FP05-R04 Les conditions peuvent être utilisées pour afficher/masquer une page, un bloc, un contenu ou une option dans une liste de choix (par exemple prejudicePaiements@@OptionDevise===\u0026lsquo;true\u0026rsquo;). Ces conditions sont des expressions JS s\u0026rsquo;exécutant dans le navigateur (dynamiquement) et dans le code Java (au début de la soumission) devant renvoyer une valeur true ou false disposant de toutes les variables saisies par l\u0026rsquo;usager et tous les paramètres déclarés dans le point d\u0026rsquo;entrée. FP05-R05 Les validations permettent de contrôler la valeur saisie par un usager. Elles sont paramétrables dans la définition d\u0026rsquo;un contenu et peuvent être : required : la saisie est obligatoire email : la saisie est un email valide selon la spécification officielle (cf. documentation Angular Validators.email) url : la saisie est une adresse de site WEB selon l\u0026rsquo;expression régulière suivante telephoneFR : la saisie est un numéro de téléphone valide selon l\u0026rsquo;expression régulière suivante secu : la saisie est un numéro de sécurité social valide selon l\u0026rsquo;expression régulière suivante et le contrôle réaliser dans la méthode (ValidationService.creerValidationsSynchrones)[/documentationgeneree/framework/compodoc/injectables/ValidationService.html#creerValidationsSynchrones]. datePassee : la saisie est une date passée dateFuture : la saisie est une date autocompletionPrecise : la saisie est une des valeurs proposées et pas une saisie de l\u0026rsquo;usager regex : la saisie correspond à l\u0026rsquo;expression régulière présente à la fin de cette validation, comme par exemple regex-^[A-Z]{6}$ (une chaine de caractères de 6 majuscules) FP06 Configuration publique - les pièces jointes\nFP06-R01 Dans la liste des pages, des blocs de chaque page et des contenus de chaque bloc (cf. FP05) peuvent être définis des contenus permettant de télé-verser des pièces jointes. Pour chaque clef de contenus de ce type, doit exister la description d\u0026rsquo;une pièce jointe associée. FP06-R02 La description d\u0026rsquo;une pièce jointe associée comprend le code de la pièce jointe associée devant être égale à la clef de chaque contenu (potentiellement plusieurs) permettant son télé-versement. la liste des types de documents autorisés (une vérification est faite côté serveur pour ne pas se fier aux extension présente dans le nom du fichier). une taille maximale autorisée en Mo (Méga-octets) FP06-R03 Si le type de document ou la taille maximale autorisée n\u0026rsquo;est pas respecté par l\u0026rsquo;usager, un message d\u0026rsquo;erreur est affiché. FP06-R04 Si le document sélectionné par l\u0026rsquo;usager fait moins de 1Mo, le document est uploadé en une unique requête. [TODO] plus de 1Mo, le document est uploadé en plusieurs requêtes (chunk) FP07 Configuration publique - l\u0026rsquo;internationalisation\nFP07-R01 Dans la configuration publique, tout attribut titre, titreAriane, aide, texte, \u0026rsquo;libelle\u0026rsquo; peut être répété avec un suffixe de langue (par exemple EN, DE, \u0026hellip;) pour définir des libellés différents pour chaque langue. FP07-R02 Un sélecteur de langue, affiché dans l\u0026rsquo;entête, permet à l\u0026rsquo;usager de choisir la langue. FP07-R03 Ce sélecteur de langue est alimenté à partir de la liste des langues disponibles pour le titre de la démarche. FP07-R04 Ce sélecteur de langue est préinitialisé avec la première langue commune à la liste des langues disponibles et la liste des langues du navigateur. FP07-R05 Une partie des libellés vient de l\u0026rsquo;applicatif (messages informatifs durant le chargement de l\u0026rsquo;application, message d\u0026rsquo;erreur, \u0026hellip;). La langue de ces libellés est celle du navigateur si elle est disponible ou, à défaut, le Français. 2.6.1.2 - Fonctionnalités paramétrables dans la configuration interne FI01 Configuration interne - Identification unique d\u0026rsquo;une démarche et de ses configurations internes :\nFI01-R01 Une démarche est identifiée par son code unique (attention aux majuscules et minuscules) FI01-R02 Une configuration interne de démarche est identifiée par le code de la démarche associée et par sa version. FI01-R03 A la soumission, est toujours utilisée la dernière configuration interne active et disponible. FI02 Configuration interne - les templates de notification :\nFI02-R01 Une notification est envoyée à l\u0026rsquo;usager dans le cas d\u0026rsquo;un brouillon, d\u0026rsquo;une soumission ou d\u0026rsquo;un changement de statut du télé-dossier dans le HUBEE. FI02-R02 Une notification peut être un email ou une notification dans le fil d\u0026rsquo;actualité du portail Service-Public.fr de l\u0026rsquo;usager : dans le cas d\u0026rsquo;un email, une notification est paramétrée avec : l\u0026rsquo;attribut type contenant la valeur email. l\u0026rsquo;attribut templateObjet contenant l\u0026rsquo;objet de l\u0026rsquo;email l\u0026rsquo;attribut templateDestinataires contenant la liste des destinataires l\u0026rsquo;attribut contenuHtml contenant la valeur true ou false pour définir si le corps de l\u0026rsquo;email est en HTML ou en pur texte. l\u0026rsquo;attribut templateContenu contenant le corps du mail dans le cas d\u0026rsquo;une notification SP, une notification est paramétrée avec : l\u0026rsquo;attribut type contenant la valeur notificationSP. l\u0026rsquo;attribut templateContenu contenant le corps de la notification l\u0026rsquo;attribut templateLienReprise contenant un lien utilisé au clique sur le bouton \u0026ldquo;REPRENDRE\u0026rdquo; dans la notification SP l\u0026rsquo;attribut nombreJoursAvantExpiration contenant la durée de vie de la notification (suppression automatique par SP au bout du délai) FI02-R03 Les attributs template* d\u0026rsquo;une notification sont tous traités par Velocity. Ainsi il est possible d\u0026rsquo;y utiliser les données disponibles dans la démarche ainsi que les structures de contrôle de Velocity (cf. §3.16). FI02-R04 Si le contenu d\u0026rsquo;une notification (de type email ou notificationSP) est vide, la notification n\u0026rsquo;est pas envoyée. Ainsi il est possible de paramétrer des notifications de différents types mais de n\u0026rsquo;en envoyer qu\u0026rsquo;une via les structures de contrôle de Velocity (#if par exemple) FI03 Configuration interne - les templates de documents générés\nFI03-R01 L\u0026rsquo;objectif premier de la PSL est de générer des documents à partir des données saisies et soumises par l\u0026rsquo;usager puis de les envoyer à un ou plusieurs destinataires. FI03-R02 Chaque document à générer dans être décrit dans la configuration interne d\u0026rsquo;une démarche avec les attributs code : un code unique à la démarche lié au document. La valeur TRANSFERT est réservé pour un usage interne de la PSL libelle : un libellé explicite du document. conditionGeneration : une condition rédigée en JS, basée sur les données soumises, permettant de définir si le document doit être généré. documentPresenteAuTelechargementEnFinDeDemarche : un drapeau false ou true indiquant si le document généré doit être présenté à l\u0026rsquo;usager, après la soumission, et ainsi être disponible au téléchargement. typeDeGeneration : une des valeurs templateHtmlToPdf, templatePdf ou templateTextuel indiquant le type de génération de document à utiliser. nomFinalDuDocument : le nom final du document généré, potentiellement téléchargeable par l\u0026rsquo;usager et potentiellement transféré à un destinataire. contentType : le type MIME du document généré (référentiel publique disponible ici) template : le template à proprement parlé transformé en base 64 ou, dans les sources de l\u0026rsquo;application, le nom du fichier de template préfixé et suffixé par \u0026mdash;- FI03-R03 Si le template à générer est de type templateTextuel, le contenu du template est traité par Velocity avec les données saisies par l\u0026rsquo;usager pour générer un fichier textuel (texte, CSV, XML, JSON, \u0026hellip;) FI03-R04 Si le template à générer est de type templateHtmlToPdf, le contenu du template est traité par Velocity avec les données saisies par l\u0026rsquo;usager puis transformer d\u0026rsquo;un format HTML à un fichier PDF. Le template doit donc impérativement générer un document HTML valide. FI03-R05 Si le template à générer est de type templatePdf, le contenu du template doit être un fichier PDF paramétré dont le clef de chaque champs correspond à une donnée saisie par l\u0026rsquo;usager. Le document en sortie sera toujours un PDF. FI04 Configuration interne - la description du transfert du télé-dossier vers son (ses) destinataire(s)\nFI04-R01 L\u0026rsquo;objectif premier de la PSL est de générer des documents à partir des données saisies et soumises par l\u0026rsquo;usager puis de les envoyer à un ou plusieurs destinataires. FI04-R02 La description interne d\u0026rsquo;un transfert est très proche de la structure des données HUBEE car cette plateforme est la seule supportée actuellement. FI04-R03 Un document de transfert se caractérise par : un attribut obligatoire codeDemarche égale au code de la démarche. un attribut obligatoire numeroTeledossier contenant le numéro de télédossier (logiquement toujours avec la valeur $json.numeroTeledossier car cette clef est fixe). un attribut optionnel idBrouillon contenant l\u0026rsquo;identifiant du brouillon ((logiquement toujours avec la valeur $json.idBrouillon car cette clef est fixe). un attribut optionnel nomUsager contenant le nom de l\u0026rsquo;usager à partir des données saisies (ou de connexion OIDC). un attribut optionnel prenomUsager contenant le prénom de l\u0026rsquo;usager à partir des données saisies (ou de connexion OIDC). un attribut optionnel emailUsager contenant l\u0026rsquo;email de l\u0026rsquo;usager à partir des données saisies (ou de connexion OIDC). un attribut optionnel uuidEspace contenant l\u0026rsquo;idenfiant unique de l\u0026rsquo;espace ServicePublic sélectionné par l\u0026rsquo;usager. un tableau obligatoire documents listant les documents à envoyer aux destinataires, sans doublon, ni distinction entre les destinataires. un tableau obligatoire destinataires listant les destinataires de ce transfert et les documents à envoyer à chacun. FI04-R04 Un tableau d\u0026rsquo;objets document dans le document de transfert se caractérise par : un attribut obligatoire estPieceJointe égale à false ou true définissant si le document à transférer est une pièce jointe ou un document généré. un attribut obligatoire codeFichierAenvoyer qui ne peut être que le code d\u0026rsquo;une pièce jointe décrite dans la configuration publique ou le code d\u0026rsquo;un document généré décrit dans la configuration interne. un attribut obligatoire idFichierStocke égale à l\u0026rsquo;identifiant du document dans la base documentaire. Cette valeur doit toujours être $json.JSON001_id avec JSON001 le code du document (pièce jointe ou document généré). un attribut obligatoire mimeType contenant le type MIME du document. Cette valeur devrait toujours être $json.JSON001_type. un attribut obligatoire nomFichier contenant le nom du document. Cette valeur devrait toujours être $json.JSON001_nom. un attribut obligatoire taille contenant le nom du document. Cette valeur devrait toujours être $json.JSON001_longueur. FI04-R05 Un tableau d\u0026rsquo;objets destinataire dans le document de transfert se caractérise par : un attribut obligatoire siret contenant le SIRET du destinataire ou une variable contenant cette donnée. un attribut obligatoire guichet contenant le code GUICHET du destinataire ou une variable contenant cette donnée. un attribut obligatoire type contenant le type d\u0026rsquo;abonnement du destinataire ou une variable contenant cette donnée. un attribut obligatoire codeDesDocuments contenant une liste de code de document à envoyer à ce destinataire précis FI05 Configuration interne - Spécificités dans l\u0026rsquo;usage de Velocity\nFI05-R01 Toute les données saisies par l\u0026rsquo;usager, dans un contexte Veolocity sont disponibles sous 3 formes différentes brute avec la clef ${clefDonnee} éventuellement traitée (échapé) pour un contexte de document JSON avec la clef ${json.clefDonnee} éventuellement traitée (échapé) pour un contexte de document XML avec la clef ${xml.clefDonnee} 2.6.1.3 - Fonctionnalités de sécurité FS01 Sécurité - TLS\nFS01-R01 Tout appel HTTP utilise le TLS et donc le protocol HTTPs FS01-R02 Toute API exposée par un micro-service ou un service Cloud est exposée avec TLS. FS02 Sécurité - OIDC\nFS02-R01 Comme évoqué dans la règle Configuration publique - Gestion des points d\u0026rsquo;entrée, il est possible de forcer ou d\u0026rsquo;utiliser la connexion d\u0026rsquo;un usager au portail ServicePublic.fr avec le mode d\u0026rsquo;authentification ServicePublic ou FranceConnect. FS02-R02 Deux modes d\u0026rsquo;authentification existent : la simple connexion avec un compte sur le portail ServicePublic.fr ou la connexion au portail ServicePublic via le service FranceConnect. Ces deux modes sont gérés par SP. Les modes d\u0026rsquo;authentification autorisés sont envoyés dans les paramètres de la connexion OIDC par la PSL. FS02-R03 Le scénario d\u0026rsquo;échanges de requêtes/réponses/redirection prévu par l\u0026rsquo;OIDC est, dans la PSL, un peu modifié : si la connexion est obligatoire (démarche purement connectée) et que l\u0026rsquo;usager n\u0026rsquo;est pas connecté, il est redirigé vers le portail ServicePublic.fr (dans cette URL, est envoyé le paramètre déterminant le mode de connexion SP ou FC). une fois l\u0026rsquo;usager connecté sur le portail SP, il est redirigé vers la PSL. puis une requête est envoyée, par l\u0026rsquo;application WEB (depuis le navigateur), vers l\u0026rsquo;API de création d\u0026rsquo;un token OIDC. A ce moment, le flow standard OIDC n\u0026rsquo;est plus respecté car cette requête nécessite de disposer des paramètres clientId et clientSecret et le token n\u0026rsquo;a pas a être disponible en clair dans l\u0026rsquo;application WEB. donc l\u0026rsquo;API appelée pour générer un token est une API PSL (et non celle de génération d\u0026rsquo;un token de SP) qui, elle-même, appelle l\u0026rsquo;API SP, obtient un token SP, crée un token PSL avec quelques informations en clair (cf. construction d\u0026rsquo;un token JWT) et le token SP chiffré. ainsi le token SP est utilisable à tout moment depuis les APIs PSL sans être exposé dans l\u0026rsquo;application WEB. FS02-R04 Si la démarche n\u0026rsquo;est pas purement connectée (anonyme ou hybride), l\u0026rsquo;usager utilisera un token JWT anonyme. Ceci est un token JWT généré aléatoirement. FS02-R05 La première nécessité d\u0026rsquo;une démarche est le chargement de sa configuration publique. Pour ce faire un token JWT est nécessaire. Donc, le premier appel réalisé par une démarche est l\u0026rsquo;appel à l\u0026rsquo;API de création d\u0026rsquo;un token JWT anonyme puis au chargement de la configuration publique. FS02-06 Dans le cas du chargement d\u0026rsquo;un brouillon, le choix du mode d\u0026rsquo;authentification ne se base pas sur la configuration publique (versus les paramètres potentiels dans l\u0026rsquo;URL). Il faut, pour charger un brouillon, réutiliser le même mode d\u0026rsquo;authentification que celui utilisé à la sauvegarde. Donc, si un identifiant de brouillon est présent dans l\u0026rsquo;URL de chargement de l\u0026rsquo;application WEB, un appel est fait au micro-service socle-dbbrouillon pour obtenir le mode d\u0026rsquo;authentification à partir de l\u0026rsquo;identifiant du brouillon. Puis la bonne mécanique d\u0026rsquo;authentification démarre. FS03 Sécurité - appels d\u0026rsquo;API externe\nFS03-R01 Tout appel d\u0026rsquo;API externe est basé sur le client de base des appels HTTP présent dans le projet socle-commun. FS03-R02 Ce client prévoit la gestion d\u0026rsquo;un proxy sortant (si un proxy est paramétré mais que l\u0026rsquo;appel échoue, l\u0026rsquo;appel est retenté sans le proxy). FS03-R03 Ce client permet de réaliser des appels sans authentification, avec une authentification simple ou OIDC (en fonction du contenu de l\u0026rsquo;entête authorization) FS03-R04 Ce client permet d\u0026rsquo;obtenir des données binaires, des chaines de caractères ou des structure Java issues de JSON. FS04 Sécurité - exposition et sécurisation des APIs\nFS04-R01 Seules les APIs utilisées dans l\u0026rsquo;application WEB (nommées publiques) sont exposées sur Internet. FS04-R02 Les APIs internes (appelées par un autre micro-service) ou admin (appelées depuis une console d\u0026rsquo;administration) ne sont pas exposées sur Internet FS04-R03 Les APIs admin sont sécurisées par un certificat client personnel et nominatif FS04-R04 Les APIs interne sont appelées dans le cadre d\u0026rsquo;un appel d\u0026rsquo;API publique et donc sécurisées par un token JWT PSL comme les APIs publiques. 2.6.1.4 - Fonctionnalités de type cloud FC01 Cloud - exposition des APIs sur Internet FC01-R01 Seules les APIs publiques sont exposées sur Internet (pas les internes ni les admin). FC01-R02 L\u0026rsquo;exposition des contrats d\u0026rsquo;interface (Swagger/SpringFox) est paramétrable (à toujours désactiver en environnement de production). FC01-R03 Les règles de sécurité CORS sont toujours actives (même sur le poste de développement) et demandent aux navigateurs de bloquer les requêtes inter-sites. FC01-R04 Les méthodes HTTP autorisées sont limitées FC01-R05 Les entêtes HTTP autorisés sont limités FC01-R06 Une mécanique de quota d\u0026rsquo;appels HTTP est présente pour bloquer les IP générant un trop grand nombre de requêtes dans un temps donné FC01-R07 La taille maximale d\u0026rsquo;un corps de requête HTTP est paramétrable FC02 Cloud - configuration des micro-services FC02-R01 La configuration de tous les micro-services est centralisée, modifiable et disponible dans un seul et même outil. FC02-R02 La configuration de chaque fonctionnalité transverse est indépendante des autres (log, oidc, connexion au registre, \u0026hellip;) FC02-R03 La configuration spécifique de chaque micro-service est indépendante des autres (referentiel, referentiel-externe, soumission, document, configuration, \u0026hellip;) FC02-R04 Aucune URL ou paramètre de connexion n\u0026rsquo;est présent en dur dans le code applicatif FC02-R05 La configuration se base sur des fichiers de propriétés (.properties) stocké dans un endroit unique et lisible par le service-configuration. Ce lieu de stockage est sécurisé et assure une traçabilité des modifications. FC02-R06 La valeur des clefs sensibles est chiffrée dans le stockage (déchifrable par service-configuration) FC04 Cloud - monitoring des instances FC04-R01 Un applicatif (service-admin) permet de lister les instances de micro-services et de services démarrées. FC04-R02 Pour tout micro-service ou service, l\u0026rsquo;application permet de consulter les données de santée (mémoire, cpu, \u0026hellip;) et les paramètres de démarrage FC04-R03 service-admin ne permet pas de consulter les configurations (portées par service-configuration et chiffrées) mais elle permet de déclencher le raffraîchissement du contexte Spring et donc le rechargement de la configuration depuis le service centralisé exposant les configurations. FC04-R04 _service-admin permet de modifier les niveaux de log de chaque logger déjà paramétré et de consulter les logs FC05 Cloud - documentation des APIs FC05-R01 Toute API (publique, interne et admin) est documentée à travers Swagger et SpringFox. Son contrat de service est exposé par le micro-service. FC05-R02 Via paramétrage (désactivé en production), il est possible d\u0026rsquo;accéder à une interface de test des APIs (SwaggerUI) rassemblant toutes les APIs du SI. 2.6.1.5 - Fonctionnalités métier FM01 Fonctionnalité métier - referentiel FM01-R01 Le micro-service referentiel, à son démarrage, charge depuis Internet, l\u0026rsquo;ensemble des données de références disponibles pour initialiser un cache unique (détails au chapitre 2.6.2.5). FM01-R02 Les types de données chargés sont : le référentiel COG chargé depuis https://www.insee.fr/fr/statistiques/fichier/6051727/cog_ensemble_2022_csv.zip le référentiel COP est enrichi des codes postaux depuis https://www.data.gouv.fr/fr/datasets/base-officielle-des-codes-postaux/ le référentiel COP est enrichi des protections des communes depuis https://www.data.gouv.fr/fr/datasets/competence-territoriale-gendarmerie-et-police-nationales/ le référentiel COP est enrichi des adresses des gendarmeries depuis https://www.data.gouv.fr/fr/datasets/liste-des-unites-de-gendarmerie-accueillant-du-public-comprenant-leur-geolocalisation-et-leurs-horaires-douverture/ le référentiel COP est enrichi des SIRET des communes depuis https://www.data.gouv.fr/fr/datasets/base-sirene-des-entreprises-et-de-leurs-etablissements-siren-siret/ le référentiel COP est enrichi des abonnés HUBEE depuis https://xxx.hubee.xxx/referential/v1/subscriptions la liste des commune de naissance depuis https://xxx.insee.fr/referentiel/v1/service-public/lieu-naissance/commune?nombre=42000 la liste des commune UGLE depuis https://xxx.insee.fr/referentiel/v1/service-public/ugles la liste des pays de naissance depuis https://xxx.insee.fr/referentiel/v1/service-public/lieu-naissance/pays?nombre=350 la liste des autres nationnalités/pays/capitables depuis https://www.business-plan-excel.fr/wp-content/uploads/2021/06/Liste-Excel-des-pays-du-monde-gratuit-capitales-continent-nationalites.xlsx FM02 Fonctionnalité métier - referentielexterne FM02-R01 Le micro-service referentilExterne ne fait qu\u0026rsquo;appeler des APIs disponibles sur Internet (sécurisée ou pas) sans conserver de cache de données. FM02-R02 Les services externes disponibles sont : la banque nationnale des adresses (BAN) FM03 Fonctionnalité métier - dbnotification FM04 Fonctionnalité métier - dbconfiguration FM04-R01 Ce micro-service permet le stockage et le téléchargement des configurations publiques de démarche FM04-R02 Ce micro-service permet le stockage et le téléchargement des configurations internes de démarche FM05 Fonctionnalité métier - dbdocument FM05-R01 Ce micro-service permet le stockage, la sauvegarde et le téléchargement des pièces jointes d\u0026rsquo;un brouillon et/ou d\u0026rsquo;un télé-dossier. FM05-R02 Ce micro-service permet le stockage, la sauvegarde et le téléchargement des documents générés d\u0026rsquo;un télé-dossier. FM06 Fonctionnalité métier - dbbrouillon FM06-R01 Ce micro-service permet le stockage, la sauvegarde et le téléchargement d\u0026rsquo;un brouillon. FM06-R02 Un brouillon est identifié de manière unique par son identifiant technique généré par la base de données MongoDB. FM06-R03 Un brouillon référence le code de démarche associé la version de la configuration publique chargé au moment de sa sauvegarde l\u0026rsquo;ensemble des données saisies par l\u0026rsquo;usager sous forme d\u0026rsquo;une liste de clef/valeur. La clef dans la liste est la clef du contenu de la configuration publique. La valeur dans la liste est la valeur saisie dans le champs correspondant ou l\u0026rsquo;identifiant de la pièce jointe téléversée. l\u0026rsquo;index de la page à laquelle l\u0026rsquo;usager a sauvegardé son brouillon FM06-R04 Au chargement d\u0026rsquo;un brouillon, si la version de la configuration publique chargée est différente de la version de la configuration publique définie dans le brouillon, l\u0026rsquo;usager est renvoyé à la première page de la démarche. FM06-R05 [TODO] A chaque changement de page, après que l\u0026rsquo;usager ait cliqué sur le bouton de sauvegarde d\u0026rsquo;un brouillon, le brouillon est mis à jour. FM06-R06 [TODO] Toutes les 60 secondes après que l\u0026rsquo;usager ait cliqué sur le bouton de sauvegarde d\u0026rsquo;un brouillon, le brouillon est mis à jour. FM07 Fonctionnalité métier - soumission FM07-R01 Le micro-service soumission expose des APIs permettant d\u0026rsquo;utiliser un Captcha (fournisseur : AIFE) dans la dernière page de soumission d\u0026rsquo;une démarche dans le cas où l\u0026rsquo;usager n\u0026rsquo;est pas connecté. Le code HTML du captcha est demandé par le code TS du navigateur au micro-service soumission qui appelle les services AIFE puis modifie la réponse HTML pour que les ressources passent elles-aussi par le micro-service. Chaque ressource (image, son et javascript) et la validation de la valeur saisie passent, elles aussi, par le micro-service soumission. Le captcha peut être désactivé via une clef de configuration. A ce moment, l\u0026rsquo;image est remplacée par un message et la valeur à saisir devient une valeur fixe, identique pour tous. FM07-R02 XXXXXXXXXXXXX FM08 Fonctionnalité métier - securite FM08-R01 Ce micro-service permet la création d\u0026rsquo;un token JWT anonyme. FM08-R02 Ce micro-service permet la création d\u0026rsquo;un token JWT issu d\u0026rsquo;un échange OIDC avec ServicePublic.fr sans exposer le token généré dans l\u0026rsquo;application WEB (chiffré dans un token spécifique à PSL). FM09 Fonctionnalité métier - transfert FM09-R01 XXXXXXXXXXXXX FM09-R02 XXXXXXXXXXXXX VRAC à reprendre en tout ou partie Le framework propose aussi des services réparties en deux groupes :\nstateless : les services sans état sont ceux offrant des fonctionnalités utilitaires ou appelant les APIs du socle bouchon : pour la gestion des bouchons en DEV ou durant les tests automatisés brouillon : pour le chargement et la sauvegarde des brouillons configuration : pour le chargement de la configuration et quelques pré-traitements date : pour la manipulation des dates document : pour l\u0026rsquo;appel au micro-service DOCUMENT et le téléchargement des documents générés formulaire : pour la manipulation/création des formulaires dans l\u0026rsquo;application piece jointe : pour l\u0026rsquo;appel au micro-service DOCUMENT et donc la sauvegarde des pièces jointes referentiel : pour l\u0026rsquo;appel aux micro-services REFERENTIEL et REFERENTIEL_EXTERNE securite : pour l\u0026rsquo;appel au micro-service SECURITE et la gestion des authentifications soumission : pour l\u0026rsquo;appel au micro-service SOUMISSION validation : pour la validation de surface de formulaire statefull : les services concervant la mémoire des précédents appels contexte : l\u0026rsquo;état de l\u0026rsquo;application et de la navigation de l\u0026rsquo;usager donnees : la liste des clefs/valeurs chargées et saisies par l\u0026rsquo;usager 2.6.2 - Fonctionnalités techniques 2.6.2.1 - Les bases de données Actuellement (01/2022), les micro-services du socle n\u0026rsquo;utilisent pas de base de données relationnelle (type SQL). Le principal projet pouvant en avoir besoin est le socle-referentiel. Or, vu le petit volume de données et le besoin de les indexer complètement, la plus simple solution est l\u0026rsquo;utilisation directe de Apache Lucene.\nPar contre, les micro-services socle-dbbrouillon, socle-dbconfiguration et socle-dbdocument stockent des documents JSON et/ou textuels et/ou binaires dans une base de données MongoDB.\nCette base de données MongoDB doit être installée comme un tiers sur tous les environnements sauf l\u0026rsquo;environnement de développement. En effet, sur ce dernier, une MongoDB peut être démarrée facilement avec le projet service-nosql se basant sur (de.flapdoodle.embed.mongo){https://github.com/flapdoodle-oss/de.flapdoodle.embed.mongo]. De plus, en développement, chaque micro-service peut initialiser sa collection MongoDB à partir des données des bouchons des applications FRONT Angular.\nPour découvrir ce que sont les bases de données NoSQL, voici une bonne lecture.\n2.6.2.2 - La centralisation/gestion des micro-services du Back Tous les micro-services du Back peuvent être démarrés plusieurs fois sur une même machine ou sur des machines différentes. Il est donc impossible d\u0026rsquo;appeler une instance d\u0026rsquo;un micro-service en particulier.\nPar contre, toute instance de micro-service, à son démarrage, se déclare auprès de deux services :\nl\u0026rsquo;application d\u0026rsquo;administration (service-admin) qui permet de surveiller/contrôler/paramétrer chaque instance du SI ; l\u0026rsquo;annuaire (service-registry) qui permet de lister les instances de micro-services et de fournir leur URL à tout composant du SI qui le réclame. Ainsi, une instance de micro-service peut en appeler une autre en interrogeant l\u0026rsquo;annuaire (ceci se fait automatiquement si l\u0026rsquo;appel passe par un client Feign). Mais les services exposés par une instance de micro-service ne seront accessibles depuis l\u0026rsquo;extérieur du SI que si le portail (la gateway) expose ses URLs (la gateway se base aussi sur l\u0026rsquo;annuaire pour trouver une instance de micro-service disponible).\n2.6.2.3 - Les logs Sur le poste de développement, le répertoire 2-code/socle/.log contient, pour chaqueinstance de micro-service, :\nles logs applicatives dans un fichier log_xxx-xxxx.log (format défini dans le fichier application-log.properties) ; les logs d\u0026rsquo;accès dans un fichier log_access_xxx-xxxx.log (format défini dans le fichier application-accesslog.properties) ; l\u0026rsquo;identifiant du processus dans un fichier pid_xxx-xxxx.pid. Le format des logs applicatives est un peu particulier car il comprend les données fournies le framework Sleuth (documentation, introduction).\nLe principe est d\u0026rsquo;ajouter, à chaque ligne de log, trois données supplémentaires :\ntraceId est l\u0026rsquo;identifiant unique de la requête HTTP à travers toutes les instance de micro-service (cette donnée est propagée de proche en proche) ; spanId est l\u0026rsquo;identifiant du traitement de cette requête par une instance de micro-services (différent dans chaque micro-service pour une même requête HTTP) parentSpanId est l\u0026rsquo;identifiant du traitement amont. Voici un exemple de logs (venant de plusieurs fichiers mais dans l\u0026rsquo;ordre chronologique) :\nlog_access_socle-soumission.log : [03/04/2022:10:03:41 +0200] 127.0.0.1 [31ae87b1dc2ef9c9,31ae87b1dc2ef9c9,2be8b1b8a905926a] POST /socle/soumission/soumettre HTTP/1.1 200 (20 b - 3650 ms) log_socle-soumission.log : [03/04/2022:10:03:37 +0200] 5396 [31ae87b1dc2ef9c9,2be8b1b8a905926a] INFO f.g.d.p.s.s.s.SoumissionServiceImpl : Soumission d\u0026#39;un télédossier. [03/04/2022:10:03:37 +0200] 5396 [31ae87b1dc2ef9c9,2be8b1b8a905926a] TRACE f.g.d.p.s.s.s.SoumissionServiceImpl : Données soumises : DonneesDeSoumissionDto [codeDemarche=etatcivil, versionConfiguration=1.0.0, donnees={action=MARIAGE, communeConcerne_code=80001, communeConcerne_codePostal=80000, communeConcerne_libelle=Amiens, communeConcerne_libelleLong=Amiens (80000), motif=Mariage, natureActe=COPIE-INTEGRALE, nombreExemplaire=1, qualiteDemandeur=PersonneConcernee, dateMariage=2018-08-08, identite1_civilite=MME, identite1_nomFamille=DURANT, identite1_nomUsage=DUPONT, identite1_prenoms=Annie, identite1_dateNaissance=2001-01-01, identite1_nationnalite_id=1, identite1_nationnalite_libelle=Française, identite1_paysNaissance_id=1, identite1_paysNaissance_libelle=France, identite1_communeNaissanceFR_codePostal=80400, identite1_communeNaissanceFR_code=80401, identite1_communeNaissanceFR_libelle=Ham, identite1_communeNaissanceFR_libelleLong=Ham (80000), filiation1_mere_filiationInconnue=false, filiation1_mere_nom=NomMere1, filiation1_mere_prenoms=PrenomsMere1, filiation1_pere_filiationInconnue=false, filiation1_pere_nom=NomPere1, filiation1_pere_prenoms=PrenomsPere1, identite2_civilite=M, identite2_nomFamille=DURANT, identite2_nomUsage=null, identite2_prenoms=Arnaud, identite2_dateNaissance=2002-02-02, identite2_nationnalite_id=1, identite2_nationnalite_libelle=Française, identite2_paysNaissance_id=1, identite2_paysNaissance_libelle=France, identite2_communeNaissanceFR_code=18801, identite2_communeNaissanceFR_libelle=Baugy, identite2_communeNaissanceFR_libelleLong=Baugy, filiation2_mere_filiationInconnue=false, filiation2_mere_nom=NomMere2, filiation2_mere_prenoms=PrenomsMere2, filiation2_pere_filiationInconnue=false, filiation2_pere_nom=NomPere2, filiation2_pere_prenoms=PrenomsPere2, adresse_estFrance=true, adresse_etage=Etage 1, adresse_immeuble=Immeuble 1, adresse_voie=1 rue XXX, adresse_boitePostale=BP 123, contact_email=monemail@test.com, contact_telephone=0612345678}] [03/04/2022:10:03:37 +0200] 5396 [31ae87b1dc2ef9c9,2be8b1b8a905926a] TRACE .p.s.s.s.ValidationSoumissionServiceImpl : Structure validée des données soumises [03/04/2022:10:03:37 +0200] 5396 [31ae87b1dc2ef9c9,2be8b1b8a905926a] TRACE f.g.d.p.s.s.s.SoumissionServiceImpl : Chargement de la configuration publique de la démarche etatcivil-1.0.0 log_access_socle-dbconfiguration.log : [03/04/2022:10:03:38 +0200] 127.0.0.1 [31ae87b1dc2ef9c9,2be8b1b8a905926a,dfc08275bd4057dc] GET /socle/configuration/demarche/etatcivil/1.0.0 HTTP/1.1 200 (27757 b - 879 ms) log_socle-dbconfiguration.log : [03/04/2022:10:03:38 +0200] 21168 [31ae87b1dc2ef9c9,dfc08275bd4057dc] TRACE f.g.d.p.s.d.c.ConfigurationControleur : Lecture de la configuration publique d\u0026#39;une démarche pour \u0026#39;etatcivil-1.0.0\u0026#39; log_socle-soumission.log [03/04/2022:10:03:38 +0200] 5396 [31ae87b1dc2ef9c9,2be8b1b8a905926a] TRACE f.g.d.p.s.s.s.SoumissionServiceImpl : Configuration publique chargée : com.github.talbotgui.psl.socle.dbconfiguration.apiclient.dto.ConfigurationPubliqueDemarcheDto@2a905b03 [03/04/2022:10:03:38 +0200] 5396 [31ae87b1dc2ef9c9,2be8b1b8a905926a] DEBUG .p.s.s.s.ValidationSoumissionServiceImpl : Point d\u0026#39;entrée associé à cette soumission : PointEntreeDto[authentification=FranceConnect, parametre=action, valeurs=[MARIAGE, DECES, NAISSANCE]] [03/04/2022:10:03:41 +0200] 5396 [31ae87b1dc2ef9c9,2be8b1b8a905926a] TRACE f.g.d.p.s.s.s.SoumissionServiceImpl : Chargement de la configuration interne de la démarche etatcivil log_access_socle-dbconfiguration.log : [03/04/2022:10:03:41 +0200] 127.0.0.1 [31ae87b1dc2ef9c9,2be8b1b8a905926a,57cf719eb5df43c5] GET /socle/configuration/demarche/etatcivil/interne HTTP/1.1 200 (95 b - 51 ms) log_socle-dbconfiguration.log : [03/04/2022:10:03:41 +0200] 21168 [31ae87b1dc2ef9c9,57cf719eb5df43c5] TRACE f.g.d.p.s.d.c.ConfigurationControleur : Lecture de la dernière configuration interne disponible d\u0026#39;une démarche pour \u0026#39;etatcivil\u0026#39; log_socle-soumission.log [03/04/2022:10:03:41 +0200] 5396 [31ae87b1dc2ef9c9,2be8b1b8a905926a] TRACE f.g.d.p.s.s.s.SoumissionServiceImpl : Configuration interne chargée : ConfigurationInterneDemarcheDto[codeDemarche=etatcivil, versionConfiguration=1.0.0, documentsAgenerer=null] [03/04/2022:10:03:41 +0200] 5396 [31ae87b1dc2ef9c9,2be8b1b8a905926a] INFO f.g.d.p.s.s.s.GenerationServiceImpl : Génération des documents pour le télédossier ETA-GQTR-S8ZW-PUF4 [03/04/2022:10:03:41 +0200] 5396 [31ae87b1dc2ef9c9,2be8b1b8a905926a] WARN f.g.d.p.s.s.s.GenerationServiceImpl : Aucun document à générer pour le télédossier ETA-GQTR-S8ZW-PUF4 Dans ces logs, on voit :\nl\u0026rsquo;identifiant unique de la requête (traceId) est 31ae87b1dc2ef9c9 le traitement dans l\u0026rsquo;instance SOUMISSION (spanId) est 2be8b1b8a905926a le premier appel à l\u0026rsquo;instance CONFIGURATION (spanId) est dfc08275bd4057dc et le lien entre l\u0026rsquo;appelant et l\u0026rsquo;appelé se voit dans les logs d\u0026rsquo;accès le premier appel à l\u0026rsquo;instance CONFIGURATION (spanId) est 57cf719eb5df43c5 et le lien entre l\u0026rsquo;appelant et l\u0026rsquo;appelé se voit dans les logs d\u0026rsquo;accès 2.6.2.5 - Détails sur l\u0026rsquo;intégration des référentiels sur Internet pour créer les référentiels PSL La méthode initialiserLesIndexes initialise plusieurs référentiels :\nen amont, sont obtenus un token valide pour les APIs INSEE protégée en OIDC le référentiel des codes postaux téléchargement depuis le site data.gouv.fr du référentiel des codes postaux (fichier de données, documentation) lecture du CSV obtenu (séparateur ;) récupération de tous les couples {codeInsee,codePostal} (colonnes 0 et 2 du CSV) en faisant attention car il peut exister plusieurs codes postaux pour un même code INSEE et vice-versa. un log est généré si le code codeInsee et le codePostal ne commencent pas par les deux mêmes caractères (code du département) les communes de naissance téléchargement depuis le site insee.fr du référentiel de toutes les communes ayant jamais existées (API) sont obtenus des objets contenant un libellé, un code INSEE à chaque objet, est ajouté le tableau de codes postaux téléchargés précédemment (en faisant le lien via le code INSEE) les communes UGLE (Unité de Gestion de Liste Electorale) téléchargement depuis le site insee.fr du référentiel des communes UGLE (API) sont obtenus des objets contenant un libellé et un code INSEE les pays de naissance téléchargement depuis le site insee.fr du référentiel de tous les pays ayant jamais existé (API) sont obtenus des objets contenant un libellé et un code INSEE référentiel géographique téléchargement depuis le site insee.fr de l\u0026rsquo;archive contenant tous les éléments du référentiel géographique (fichier de données, documentation) de l\u0026rsquo;archive, sont extraits les fichiers dont le nom commence par pays_20 ou region_20 ou departement_20 ou commune_20 référentiel géographique - pays actuels du fichier CSV des pays, sont traitées les lignes dont la case 1 (pays actif) contient la valeur 1 sont extraites les colonnes codeInsee (colonne 0), le libellé (colonne 5) et le code officiel sur 2 caractères (colonne 8) référentiel géographique - régions actuelles de France du fichier CSV des régions, sont traitées les lignes contenant 6 cases dont la première case n\u0026rsquo;a pas la valeur REG (ligne d\u0026rsquo;entête) sont extraites les colonnes codeInsee (colonne 0), le libellé (colonne 5) et le code INSEE de la commune chef lieu de canton (colonne 1) référentiel géographique - départements français actuels du fichier CSV des départements, sont traitées les lignes contenant 7 cases dont la première case n\u0026rsquo;a pas la valeur DEP (ligne d\u0026rsquo;entête) sont extraites les colonnes codeInsee (colonne 0), le libellé (colonne 6), le code INSEE de la région (colonne 1) et le code INSEE de la commune chef lieu (colonne 2) référentiel géographique - communes françaises actuelles du fichier CSV des communes, sont traitées les lignes contenant au minimum 8 cases dont la première case n\u0026rsquo;a pas la valeur COM (ligne d\u0026rsquo;entête) sont extraites les colonnes codeInsee (colonne 1), le libellé (colonne 8) et le code INSEE du département (colonne 3) du fichier CSV des communes, sont aussi traitées les lignes ayant une valeur en case 11 (les communes déléguées) sont extraites les colonnes codeInsee de la commune parente (colonne 11) et le libellé (colonne 8) les communes déléguées sont insérées dans leur commune parente (via le code INSEE) les chef lieu de région sont insérés dans les régions (via le code INSEE) les chef lieu de département sont insérés dans les départements (via le code INSEE) les régions sont insérées dans les départements (via le code INSEE) les départements sont insérés dans les communes (uniquement parentes) (via le code INSEE) référentiel géographique - compléments ajoutés les codes postaux (téléchargés plus tôt) sont insérés dans les communes (via le code INSEE) téléchargement des référentiels COMEDEC (documentation) pour les mairies, les notaires et TES. intégration, dans chaque commune, de ses éléments COMEDEC téléchargement du référentiel des nationalités téléchargement du fichier depuis le site business-plan-excel.fr (fichier de données, documentation) lecture du premier onglet du fichier Excel, à partir de la ligne 5, de toutes les lignes de plus de 9 cases récupération du codeOfficielSur2caractères (case 1), codeOfficielSur3caractères (case 2), nomDuPays (case 4), nomCapitale (case 6), nomContinent (case 8) et nationalité (case 9) les nationalités sont insérées dans les pays téléchargement des protections de commune téléchargement du CSV depuis le site data.gouv.fr (fichier de données et documentation) lecture des lignes du CSV (séparateur ;), hors ligne d\u0026rsquo;entête, de plus de 7 cases, en retirant les \u0026quot; récupération du code INSEE de la commune protégée (case 0), du type de protection (PN ou GN en case 2), nom du protecteur (brigade de gendarmerie ou commissariat en case 4) et identifiant du protecteur (case 3) un log est généré si le type de protection est vide un log est généré si un code INSEE de commune est présent en double et aucune protection n\u0026rsquo;est retenue téléchargement des coordonnées et horaires des gendarmeries de France téléchargement du CSV depuis le site data.gouv.fr (fichier de données et documentation) lecture des lignes du CSV (séparateur ;), hors ligne d\u0026rsquo;entête, de plus de 3 cases, en retirant les \u0026quot; récupération de l\u0026rsquo;identifiant du protecteur (case 0), du nom du protecteur (brigade de gendarmerie ou commissariat en case 1), de l\u0026rsquo;adresse (case 2), du téléphone (case 3) récupération, si présente, du contenu de la case 14 contenant les horaires récupération, si présente, du contenu de la case 15 contenant l\u0026rsquo;adresse WEB de la gendarmerie intégration, dans chaque commune, du type de protection et du nom du protecteur (via le code INSEE de la commune) intégration, dans chaque commune, des coordonnées de la gendarmerie (via l\u0026rsquo;identifiant du protecteur) téléchargement du référentiel des SIRETs téléchargement de l\u0026rsquo;archive depuis le site data.gouv.fr (fichier de données et documentation) /!\\ Ce ZIP est énorme (plus de 1Go) extraction de l\u0026rsquo;archive et lecture du fichier CSV (séparateur ,) lecture des lignes de plus de 41 cases dont la case etablissementSiege (9) contient true, la case etatAdministratifEtablissement (40) contient A et la case enseigne1Etablissement (41) contient MAIRIE récupération du SIRET (case 2), du nom de la commune (case 17), de son code postal (case 16), de son code INSEE (case 20) intégration des SIRETs dans chaque commune via (les codes INSEE et les codes postaux) ou (les deux premiers caractères des codes postaux et les noms de communes) téléchargement de la liste des abonnés génération d\u0026rsquo;un token sur l\u0026rsquo;API HUBEE téléchargement, par page de 100 résultats, de tous les abonnés à toutes les démarches depuis le site API récupération des données subscriber.companyRegister et processCode qui sont, respectivement, le SIRET et le code de démarche intégration, dans chaque commune, de la liste des codes des démarches connectées (via le SIRET) recherche d\u0026rsquo;incohérence dans l\u0026rsquo;ensemble du référentiel géographique log, pour chaque commune, si un des champs suivant est vide : codeInsee, codeInseeDepartement, codesPostaux, departement, SIRET, typeProtection log, pour chaque commune, si un des codes postaux ne commence pas par les deux premiers caractères du codeInsee /!\\ A SAVOIR /!\\\nle référentiel des communes de naissance de l\u0026rsquo;INSEE n\u0026rsquo;est mis à jour que très rarement. Légalement, l\u0026rsquo;INSEE a jusqu\u0026rsquo;à 18 ans pour mettre à jour l\u0026rsquo;état d\u0026rsquo;une commune. Ce référentiel est donc peu utilisé. 2.6.3 - Fonctionnalités FRONT \u0026amp; BACK TODO\n2.6.4 - Fonctionnalités de l\u0026rsquo;EDITEUR TODO\n2.6.5 - Fonctionnalités des tests E2E TODO Le framework xxxxxx apporte des fonctionnalités de test \u0026ldquo;end to end\u0026rdquo; permettant, à partir de la configuration de la démarche, de tester les composants du framework :\n"
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/2.7cloud/",
	"title": "2.7 Fonctionnalités Cloud",
	"tags": [],
	"description": "",
	"content": "\r2.7.1 - Que sont les services du socle disponibles jusque sur le poste du développeur ? 2.7.2 - Pile Elastic 2.7.1 - Que sont les services du socle disponibles jusque sur le poste du développeur ? Les micro-services du socle (détaillés au chapitre précédent) ne peuvent pas démarrer, s\u0026rsquo;appeler entre eux ou être appelés depuis l\u0026rsquo;extérieur sans des services purement techniques comme :\nun registre listant les micro-services (et services) démarrés et permettant les appels entre eux ; une gateway pouvant exposer les services de toutes les multiples isntances de micro-service à l\u0026rsquo;extérieur (en s\u0026rsquo;adossant au regitre) ; un fournisseur de configuration mettant à disposition la configuration nécessaire à chaque micro-service. En plus de ces deux composants présents en amont des micro-services, sont disponibles :\nune base de données MongoDB (ou ClusterFS) permettant le stockage de toutes les collections de documents (cf. chapitre précédent) ; une application d\u0026rsquo;administration permettant de surveiller et interagir avec les micro-services démarrés. un serveur de cache REDIS permettant à la Gateway de bloquer un client si son nombre de requête est trop important Enfin une pile Elastic est disponible (cf. détails plus bas).\n2.7.2 - Pile Elastic La pile Elastic permet de centraliser les logs de tous les services et micro-services dans un même espace de stockage et de consultation.\nCette pile est construite autour de :\nFileBeat surveille les fichiers de logs sur le disque, lit/traite chaque log et l\u0026rsquo;envoie dans ElasticSearch ElasticSearch stocke les logs et la configuration de Kibana Kibana permet la consultation des logs et met à disposition des tableaux de bord Après voir suivi la procédure d\u0026rsquo;installation et de démarrage disponible au chapitre §3.35.1, Kibana sera disponible\nrechercher des logs dans Analytics \u0026gt; Discover exporter des éléments de configuration Stack Management \u0026gt; Saved objects "
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/2.8securite/",
	"title": "2.8 Sécurité",
	"tags": [],
	"description": "",
	"content": "\r2.8.1 - Introduction 2.8.2 - Séquence en détails 2.8.2.1 - Jusqu\u0026rsquo;au chargement de la configuration de la démarche 2.8.2.2 - Authentification supplémentaire éventuelle 2.8.2.3 - Par la suite 2.8.2.3 - A la soumission 2.8.3 - Sécurité \u0026amp; chiffrement 2.8.1 - Introduction L\u0026rsquo;authentification d\u0026rsquo;une démarche peut se faire, de manière paramétrables, selon deux modes d\u0026rsquo;authentification.\nLe premier mode authentification, systématiquement utilisée à l\u0026rsquo;accès par l\u0026rsquo;utilisateur à une démarche, est le mode anonyme. Ce mode anonyme consiste en la création d\u0026rsquo;un token JWT (appel au micro-service SECURITE) dès le chargement de la démarche. Avec ce token, l\u0026rsquo;application WEB peut appeler les autres API du socle (configuration/brouillon/\u0026hellip;).\nUne fois la configuration chargée, selon le contenu de cette dernière, une authentification supplémentaire peut être demandée. Celle-ci se fait via le protocole OIDC avec le fournisseur d\u0026rsquo;identité ServicePublic.fr ou FranceConnect.\nSi la démarche le nécessite, une fois les échanges OIDC réalisés et l\u0026rsquo;usager connecté, le token généré est transmis au socle pour être ajouté au token propre au socle.\n2.8.2 - Séquence en détails Selon le couple \u0026ldquo;paramètres de l\u0026rsquo;URL\u0026rdquo; et \u0026ldquo;points d\u0026rsquo;entrée de la configuration\u0026rdquo;, l\u0026rsquo;authentification anonyme suffit (passez au chapitre suivant) ou une authentification OIDC est nécessaire (lisez ce chapitre).\nCette authentification OIDC est alors réalisée exclusivement dans le navigateur WEB avec un implicit flow OIDC avec le framework angular-oauth2-oidc (documentation).\n2.8.2.1 - Jusqu\u0026rsquo;au chargement de la configuration de la démarche Pour rappel, l\u0026rsquo;application WEB d\u0026rsquo;une démarche ne sait pas faire grand chose (voire rien) avant d\u0026rsquo;avoir chargé la configuration. S\u0026rsquo;enchaînent donc :\nle chargement de l\u0026rsquo;application Angular l\u0026rsquo;appel au micro-service SECURITE pour générer un token anonyme (token JWT) l\u0026rsquo;appel au micro-service CONFIGURATION pour charger la dernière configuration disponible de la démarche les paramètres de l\u0026rsquo;URL sont analysés vis-à-vis des \u0026ldquo;points d\u0026rsquo;entrée\u0026rdquo; configurés dans la démarche (cf. chapitre 2.6.1.1) 2.8.2.2 - Authentification supplémentaire éventuelle Il est possible, dans la configuration d\u0026rsquo;une démarche, d\u0026rsquo;imposer, à l\u0026rsquo;accès à la démarche, une authentification SP et/ou FC. Cette configuration est modulable, à travers les points d\u0026rsquo;entrée, en fonction des paramètres d\u0026rsquo;accès la démarche (cf. exemple de la démarche biliothèque accessible sans authentification ou avec.\nTechniquement, l\u0026rsquo;application FRONT se charge puis elle :\ngénère un token PSL anonyme charge la configuration de la démarche analyse les points d\u0026rsquo;entrée de la configuration vis-à-vis de l\u0026rsquo;URL de la démarche Si une authentification est nécessaire, le service OidcService est appelé pour initialiser l\u0026rsquo;authentification et rediriger le navigateur vers la page de connexion SP (dans la méthode FmkApplicationAbstraitComponent.gererLaSecurite). Au retour de la page de connexion, l\u0026rsquo;application FRONT se charge puis elle recommence les étapes précédente. Mais comme l\u0026rsquo;URL contient les données nécessaires à la connexion OIDC (qui vient d\u0026rsquo;être faite), le framework OIDC appelle l\u0026rsquo;API de création du token (API exposée par le socle PSL). L\u0026rsquo;application FRONT n\u0026rsquo;a pas besoin de disposer d\u0026rsquo;un token SP. Donc, pour éviter de divulguer une information inutile, l\u0026rsquo;API de création de token exposée par le socle PSL va :\ndans le cas d\u0026rsquo;une création de token à partir des données de l\u0026rsquo;échange OIDC (grant_type=\u0026ldquo;authorization_code\u0026rdquo; + code=\u0026ldquo;valeurSpécifiqueAchaqueConnexion\u0026rdquo; + redirect_uri=\u0026ldquo;UrlDeRetourAlaDemarcheAvecTousLesParametresOriginaux\u0026rdquo; + code_verifier=\u0026ldquo;valeurSpécifiqueAchaqueConnexion\u0026rdquo;) : le socle appelle les API OIDC de SP (KeyCloack) pour générer des tokens (accessToken et refreshToken) le socle appelle les API de SP pour récupérer les informations de la personne connectée le socle génère un token PSL contenant en clair les données de la personne connectée (claims \u0026ldquo;sp\u0026rdquo; cf. OidcServiceImpl.CLAIM_DONNEES_USAGER) et les deux tokens SP chiffrés (claims \u0026ldquo;at\u0026rdquo; et \u0026ldquo;rt\u0026rdquo; cf. JwtService.CLEF_REFRESH_TOKEN_OIDC et JwtService.CLEF_ACCESS_TOKEN_OIDC). dans le cas d\u0026rsquo;un raffraichissement de token à partir du token PSL fourni en entrée (grant_type=\u0026ldquo;refresh_token\u0026rdquo;) : le socle déchiffre le refreshToken OIDC présent dans le token PSL le socle appelle l\u0026rsquo;API OIDC de SP (KeyCloack) pour regénérer un accessToken le socle vérifie la cohérence des informations personnelles présentes dans le token PSL et dans le token généré (uniquement le mail) le socle regénère un token PSL avec les nouveaux tokens OIDC 2.8.2.3 - Par la suite Une fois la démarche pleinement chargée (configuration \u0026amp; authentification), le brouillon (si un identifiant est fourni dans l\u0026rsquo;URL d\u0026rsquo;accès initial) est chargé. Si la version de la configuration de la démarche est différente entre la sauvegarde du brouillon et son chargement, l\u0026rsquo;usager redémarre à la première étape. Sinon, il reprend à l\u0026rsquo;étage à laquelle il s\u0026rsquo;est arrêté.\nL\u0026rsquo;usager peut alors avancer/reculer dans les étapes de la démarche à son rythme.\nDu fait que tout token expire (PSL, SP comme FC), une mécanique régulière (toutes les 5 minutes) appelle lance le raffraichissement du token :\nSi le token actuel est anonyme, un appel à l\u0026rsquo;API de connexion anonyme crée un nouveau token. Sinon, la mécanique de raffraichissement du token (via le framework) est appelée et ce token OIDC est envoyé à l\u0026rsquo;API SECURITE du socle (décrite plus haut) 2.8.2.3 - A la soumission A la soumission, la recherche du point d\u0026rsquo;entrée cohérent depuis la liste présente dans la configuration publique de la démarche est réalisé dans le code Java sur le même modèle que dans le code TS.\nUne fois le point d\u0026rsquo;entrée trouvé, si ce dernier demande une authentification, l\u0026rsquo;email présent dans les données soumises et comparé à celui présent dans les données soumises.\nAucune autre donnée soumise n\u0026rsquo;est contrôlée car, dans la démarche, il est tout à fait autorisé de modifier les données récupérées depuis SP.\n2.8.3 - Sécurité \u0026amp; chiffrement Le SI contient plusieurs keystore et truststore utilisés pour différents besoin de chiffrement/authentification :\nTLS/HTTPs : toutes les APIs sont exposées (par la gateway comme par les micro-services) en HTTPs. Pour cela, un certificat est présent dans 2-code/.certificatsLocaux/keystore.p12 et utilisé dans les scripts de démarrage (demarrer.sh et tous les _launch Eclipse)\nservice-configuration : toutes les données sensibles de configuration stockées par service-configuration sont chiffrées. Avant d\u0026rsquo;envoyer les informations au micro-service, le service déchiffre les données à partir de la clef présente dans keystoreconfig/service-config.jks. Ces éléments de configuration sont présents\ndans le le fichier application-specifique de _service-conf (pour la définition du chiffrement) dans les fichiers de configuration des lancements faits depuis Eclipse, application-communDansEclipse.properties et application-tests.properties, car les applicatifs démarrés dans Eclipse lisent les fichiers de configuration présents dans les sources (sans appeler le service-config) authentification mutuelle : les APIs d\u0026rsquo;administration ne sont accessibles qu\u0026rsquo;à travers un appel HTTPs contenant un certificat client valide. Les certificats CLIENT valides sont stockés dans 2-code/.certificatsLocaux/truststore.jks et utilisé dans les scripts de démarrage (demarrer.sh et tous les _launch Eclipse)\n"
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/2.9liensdocumentaires/",
	"title": "2.9 Liens documentaires",
	"tags": [],
	"description": "",
	"content": "\rLe volume de code est disponible ici.\nL\u0026rsquo;outil d\u0026rsquo;analyse de sécurité DependencyTrack est disponible ici\nLa documentation générée/technique des projets BACK est disponible ici (les liens vers les applicatifs sont ici) :\nProjetDocumentationSources service-admin javadoc sources service-gateway javadoc sources service-nosql javadoc sources service-registry javadoc sources socle-commun javadoc sources\u0026nbsp;sources-test socle-communtest javadoc sources socle-commundb javadoc sources socle-commundbtest javadoc sources socle-dbconfiguration javadoc sources\u0026nbsp;sources-test socle-dbbrouillon javadoc sources\u0026nbsp;sources-test socle-dbdocument javadoc sources\u0026nbsp;sources-test socle-referentiel javadoc sources\u0026nbsp;sources-test socle-referentielexterne javadoc sources\u0026nbsp;sources-test socle-securite javadoc sources\u0026nbsp;sources-test socle-soumission javadoc sources\u0026nbsp;sources-test Celle des projets FRONT est ici :\nframework documentation Compodoc la partie CYPRESS du framework documentation Compodoc edition documentation Compodoc analyse webpack adminpsl documentation Compodoc analyse webpack les démarches ArnaqueInternet documentation Compodoc analyse webpack Bibliotheque documentation Compodoc analyse webpack DDMariage documentation Compodoc analyse webpack EtatCivil documentation Compodoc analyse webpack JeChangeDeCoordonnees documentation Compodoc analyse webpack OperationTranquiliteVacances documentation Compodoc analyse webpack La documentation des PlayBook Ansible est disponible ici (penser à dézoomer pour consulter les schémas) :\n01_preparer 02_installer 03_deployer 04_demarrer 05_statuer 06_arreter 99_detruire "
},
{
	"uri": "http://localhost:1313/documentation/2conceptiondetaillee/2.10documentationutilisateur/",
	"title": "2.10 Documentation utilisateur",
	"tags": [],
	"description": "",
	"content": "Cette page décrit comment définir les configurations d\u0026rsquo;une démarche : 2.10.1 - Configuration interne 2.10.2 - Configuration publique 2.10.2.1 - Structure 2.10.2.2 - Les types de contenu 2.10.1 - Configuration interne Les APIs exposées aux démarches comme aux autre micro-services (et donc les services qui sont derrière) se conçoivent à partir du besoin (et de la faisabilité bien-sûr). Ceci comprend le choix des paramètres (et de leur type) et les données retournées.\n2.10.2 - Configuration publique 2.10.2.1 - Structure Une configuration publique est un fichier JSON contenant la définition des éléments suivants :\nl\u0026rsquo;identité de la configuration { [...] \u0026#34;codeDemarche\u0026#34;: \u0026#34;bibliotheque\u0026#34;, \u0026#34;versionConfiguration\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;titre\u0026#34;: \u0026#34;Démarche montrant les possiblités du moteur de la nouvelle PSL\u0026#34;, [...] les scénarii métiers et l\u0026rsquo;authentification associée { [...] \u0026#34;pointsEntree\u0026#34;: [ { \u0026#34;authentification\u0026#34;: \u0026#34;FranceConnect\u0026#34;, \u0026#34;parametres\u0026#34;: [ { \u0026#34;parametre\u0026#34;: \u0026#34;action\u0026#34;, \u0026#34;valeurs\u0026#34;: [\u0026#34;PLAINTE\u0026#34;] }, { \u0026#34;parametre\u0026#34;: \u0026#34;type\u0026#34;,\u0026#34;valeurs\u0026#34;: [\u0026#34;EAS\u0026#34;,\u0026#34;CEL\u0026#34;,\u0026#34;EASCEL\u0026#34;,\u0026#34;PMEP\u0026#34;,\u0026#34;PMEC\u0026#34;,\u0026#34;FSV\u0026#34;,\u0026#34;FA\u0026#34;,\u0026#34;FVFL\u0026#34;,\u0026#34;R\u0026#34;] } ], }, { \u0026#34;parametres\u0026#34;: [ { \u0026#34;parametre\u0026#34;: \u0026#34;action\u0026#34;,\u0026#34;valeurs\u0026#34;: [\u0026#34;SIGNALEMENT\u0026#34;] }, { \u0026#34;parametre\u0026#34;: \u0026#34;type\u0026#34;,\u0026#34;valeurs\u0026#34;: [\u0026#34;EAS\u0026#34;,\u0026#34;CEL\u0026#34;,\u0026#34;EASCEL\u0026#34;,\u0026#34;PMEP\u0026#34;,\u0026#34;PMEC\u0026#34;,\u0026#34;FSV\u0026#34;,\u0026#34;FA\u0026#34;,\u0026#34;FVFL\u0026#34;,\u0026#34;R\u0026#34;] } ] } ], [...] des valeurs de configuration { [...] \u0026#34;valeursInitiales\u0026#34;: { \u0026#34;destinatairesActifs_agirc\u0026#34;: true, \u0026#34;destinatairesActifs_ants\u0026#34;: true, \u0026#34;destinatairesActifs_caf\u0026#34;: true, \u0026#34;destinatairesActifs_camieg\u0026#34;: true } [...] les définitions des contraintes des pièces jointes { [...] \u0026#34;piecesJointesAssociees\u0026#34;: [ { \u0026#34;codePieceJointe\u0026#34;: \u0026#34;pj1\u0026#34;, \u0026#34;tailleMaximaleAutorisee\u0026#34;: 10, \u0026#34;typesDeContenuAutorises\u0026#34;: [\u0026#34;application/pdf\u0026#34;] } ], [...] l\u0026rsquo;activation/désactivation des fonctionnalités PSL { [...] \u0026#34;fonctionnalites\u0026#34;: { \u0026#34;captcha\u0026#34;: false, \u0026#34;modeObligatoireParDefaut\u0026#34;: true, \u0026#34;deuil\u0026#34;: true, \u0026#34;brouillon\u0026#34;: true }, [...] et enfin le contenu des blocs et des pages { [...] \u0026#34;pages\u0026#34;: [ { \u0026#34;titre\u0026#34;: \u0026#34;Des exemples de paragraphe\u0026#34;, \u0026#34;titreAriane\u0026#34;: \u0026#34;Paragraphes\u0026#34;, \u0026#34;blocs\u0026#34;: [ { \u0026#34;titre\u0026#34;: \u0026#34;Libellés simples\u0026#34;, \u0026#34;aide\u0026#34;: \u0026#34;Aide contextuelle du bloc\u0026#34;, \u0026#34;contenus\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;paragraphe\u0026#34;, \u0026#34;texte\u0026#34;: \u0026#34;Un simple libellé.\u0026#34; } ] }, { \u0026#34;titre\u0026#34;: \u0026#34;Libellés conditionnés\u0026#34;, \u0026#34;aideTitre\u0026#34;: \u0026#34;Tooltip du titre du bloc\u0026#34;, \u0026#34;aide\u0026#34;: \u0026#34;Une autre aide contextuelle de bloc\u0026#34;, \u0026#34;contenus\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;paragraphe\u0026#34;, \u0026#34;texte\u0026#34;: \u0026#34;Un simple libellé.\u0026#34; } ] } ] }, { \u0026#34;titre\u0026#34;: \u0026#34;Seconde page de paragraphe\u0026#34;, \u0026#34;exclueDuFilDariane\u0026#34;: true, \u0026#34;blocs\u0026#34;: [ { \u0026#34;contenus\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;paragraphe\u0026#34;, \u0026#34;texte\u0026#34;: \u0026#34;Cette page existe mais elle n\u0026#39;est pas visible spécifiquement dans le fil d\u0026#39;Ariane. Elle partage son numéro avec la page précédente\u0026#34; } ] } ] } ] [...] 2.10.2.2 - Les types de contenu Le contenu paragraphe permet d\u0026rsquo;afficher un paragraphe de texte contenant :\ntexte : une première partie (balise P) contiendra le texte (qui peut être du code HTML et/ou contenir une donnée saisie sous la forme {{codeContenu}}) style : une liste de classes CSS prédéfinies par PSL ou DSFR comme fr-callout pour créer une mise en forme DSFR sur le modèle callout fr-icon-information-line ou fr-icon-message-2-line permettent d\u0026rsquo;ajouter une icône à un callout fr-highlight pour créer une mise en forme DSFR sur le modèle highlight text-danger, text-warning et _text-info permettent de colorier le texte en rouge, orange ou bleu fr-callout\u0026ndash;green-emeraude pour changer la couleur du fond du cadre et de son texte (les couleures sont disponibles ici) aide et styleAide affichent une seconde balise P avec les mêmes possibilités que texte et style Exemple :\n{ \u0026#34;type\u0026#34;: \u0026#34;paragraphe\u0026#34;, \u0026#34;texte\u0026#34;: \u0026#34;Paragraphe en \u0026lt;a href=\\\u0026#34;https://v1-10-1--ds-gouv.netlify.app/example/component/callout/\\\u0026#34;\u0026gt;mode \u0026lt;b\u0026gt;callout\u0026lt;/b\u0026gt; de la DSFR\u0026lt;/a\u0026gt;.\u0026#34;, \u0026#34;style\u0026#34;: \u0026#34;fr-callout fr-icon-message-2-line\u0026#34;, \u0026#34;aide\u0026#34;: \u0026#34;Et son aide avec une autre icône\u0026#34;, \u0026#34;styleAide\u0026#34;: \u0026#34;fr-callout fr-icon-information-line\u0026#34; } "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/",
	"title": "3. Développement",
	"tags": [],
	"description": "",
	"content": "Chapitre 3 Guide de développemenent Le chapitre précédent décrit comment sont appliqués les principes de conception ainsi que l\u0026rsquo;usage des technologies choisies.\nIl constitue le guide du développeur.\nLes chapitres suivants sont 3.1 Liens 3.2 Installation de poste 3.3 Démarrer tout 3.11 Infos-logs 3.12 Infos-Spring 3.13 Infos-cloud 3.14 Infos-PIC 3.15 Infos-test e2e 3.16 Infos-velocity 3.21 Règles-conception 3.22 Règles-Java 3.23 Règles-Maven 3.24 Règles-test 3.25 Règles-logs 3.26 Règles-Front 3.31 Procédures-site documentaire 3.32 Procédures-règles de l\u0026#39;application Angular 3.33 Procédures-environnement Maven 3.34 Procédures-veille sécurité 3.35 Procédures-elastic 3.36 Procédures-test 3.37 Procédures-diverses 3.41 Les choses à savoir 3.99 Foire aux questions (FAQ) "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.1liens/",
	"title": "3.1 Liens",
	"tags": [],
	"description": "",
	"content": "\r3.1.1 - Liens locaux 3.1.2 - Liens de la PIC Les liens vers les documentations générées automatiquement à partir du code sont disponible ici.\n3.1.1 - Liens locaux Applicatifs WEB Front : Applicatifs WEB Front d\u0026rsquo;administration : édition de configuration de démarche PSL Admin: wsl ou local Applications WEB Back : Service Cloud Registry Eureka : lien local ou lien wsl Service Cloud Admin : lien local ou lien wsl Swagger des APIs exposés par la Gateway Documentation : liens documentaire publiée dans WSL ou en édition locale 3.1.2 - Liens de la PIC TODO: quand une PIC sera associée au projet\n"
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.2installationdeposte/",
	"title": "3.2 Installation de poste",
	"tags": [],
	"description": "",
	"content": "\r3.2.1 - Clone du dépôt 3.2.2 - Java 3.2.3 - Maven 3.2.4 - Node \u0026amp; co 3.2.4.1 - Installer Node 3.2.5 - Les IDE 3.2.5.1 - IDE - Notepad++ 3.2.5.2 - IDE - Eclipse 3.2.5.3 - IDE - VSCode 3.2.5.4 - IDE - Compass 3.2.5.5 - IDE - UseBruno 3.2.5.6 - IDE - Règle sur l\u0026rsquo;utilisation des IDEs 3.2.5.7 - OUTILS - SMTP4DEV (pas nécessaire dans un premier temps) 3.2.5.8 - OUTILS - SpringBootCli (pas nécessaire dans un premier temps) 3.2.6 - Compiler les sources 3.2.7 - Ré-activer la vérification SSL 3.2.8 - Certificats 3.2.8.1 - Créer le certificat racine et le faire accepter par Windows et Java 3.2.8.2 - Créer le certificat signé localement (TLS/HTTPs) 3.2.8.3 - Créer un certificat client d\u0026rsquo;appel aux APIs d\u0026rsquo;administration 3.2.9 - Installer les outils nécessaires au projet IAS (Infrastructure As Code) (pas nécessaire dans un premier temps) 3.2.10 - Modifier le fichier host de Windows 3.2.11 - Initialiser un fichier de cache 3.2.12 - FAQ Le premier élément primordiale du guide du développeur est l\u0026rsquo;installation du poste de développement. Si, lors de son installation de poste, un développeur a un doute ou a besoin d\u0026rsquo;une information supplémentaire, il doit capitaliser et enrichir, à son tour, la présente page.\nCette procédure ne prend pas en compte le paramétrage d\u0026rsquo;éventuel repository personnel ou de proxy.\nCette procédure peut sembler fastidieuse. Une installation de poste via la virtualisation est en effet plus rapide à exécuter pour chaque développeur. Mais, toute mise à jour de l\u0026rsquo;environnement de développement nécessite de retravailler la VM puis de la redistribuer à chacun. De plus, la virtualisation est maintenant limitée chez certaines ESN (pour des raisons de sécurité). Enfin, l\u0026rsquo;installation manuelle a l\u0026rsquo;avantage de faire comprendre à chacun le fonctionnement de chaque outil. Cela fait donc grandir chacun.\n3.2.1 - Clone du dépôt Ce dépôt contient des sub-modules GIT pour le thème GoHugo utilisé dans la documentation. La commande (documentation) pour faire un clone du dépôt est donc\ngit clone --recurse-submodules https://xxxxxxxxxxx Si le paramètre \u0026ndash;recurse-submodules n\u0026rsquo;a pas été utilisé au moment du clone, il est toujours possible de récupérer les sub-modules avec les commandes :\ngit submodule init git submodule update Un hook doit être installé pour mettre à jour la date des documents MD au moment de chaque commit. Pour cela, il faut copier le fichier aInstaller_pre-commit dans le répertoire .git/hooks en le renommant pre-commit. A chaque commit comprenant un fichier MD, un message apparaît :\nModification des dates dans les pages MD pour 1-conception/content/X.xxx/X.Xxxxxxx.md Pour plus de détails, se référer au §3.31\n3.2.2 - Java Le projet utilise Java-23.0.2. Pour le télécharger, le binaire est sur le site java.net.\nUne fois téléchargé, il suffit\nd\u0026rsquo;extraire le contenu du ZIP dans un répertoire précis (comme D:\\outils) de définir la variable d\u0026rsquo;environnement JAVA_HOME (globalement sur la machine ou localement dans la console) d\u0026rsquo;ajouter %JAVA_HOME%\\bin dans la variable d\u0026rsquo;environnement PATH 3.2.3 - Maven Le projet utilise Maven-3.9.9.\nPour installer Maven :\ntélécharger le binaire depuis le site officiel d\u0026rsquo;extraire le contenu du ZIP dans un répertoire précis (comme D:\\outils) de définir la variable d\u0026rsquo;environnement MAVEN_HOME (globalement sur la machine ou localement dans la console) de définir la variable d\u0026rsquo;environnement MAVEN_OPTS avec la valeur \u0026ndash;add-opens java.base/java.lang=ALL-UNNAMED (demandé depuis la version maven-3.9.7) d\u0026rsquo;ajouter %MAVEN_HOME%\\bin dans la variable d\u0026rsquo;environnement PATH paramétrer votre Maven : créer le répertoire du repository local (comme D:\\outils\\repositoryLocal) le renseigner dans le fichier %MAVEN_HOME%\\conf\\settings.xml si des mots de passe sont à stocker dans la configuration Maven, suivre la procédure de chiffrement des mots de passe Pour construire (builder) très rapidement les projets du socle sans déclencher les tests automatisés, il est possible d\u0026rsquo;utiliser la commande mvn clean install -DskipTests -T 1C. Ce paramètre déclenche la parallélisation en utilisant tous les coeurs du processeur.\nSi le poste de développement dispose de plusieurs version de Java. Il peut être utile de créer des raccourcis d\u0026rsquo;appel à Maven pour chaque version depuis la commande Git4Windows. Pour cela :\néditer le fichier C:\\Program Files\\Git\\etc\\profile.d\\aliases.sh ajouter, autant que nécessaire, une ligne sur le modèle alias mvn19=\u0026quot;JAVA_HOME=/d/xxxxxx/jdk-19/ \u0026amp;\u0026amp; mvn\u0026quot; en remplaçant le chemin vers le JDK par le bon ainsi que la version dans l\u0026rsquo;alias redémarrer votre (vos) ligne(s) de commande Git4Windows et/ou CMD et/ou PowerShell pour que la modification soit prise en compte. 3.2.4 - Node \u0026amp; co Le projet utilise Node-23.10.0. La compilation de tout le projet peut se faire via Maven car ce dernier télécharge un Node et un NPM pour construire le livrable des projets FRONT.\nMais, pour développer, installer Node et NPM sur son poste est nécessaire.\n3.2.4.1 - Installer Node Pour installer Node et NPM, il suffit de :\ntélécharger le ZIP depuis le site officiel d\u0026rsquo;extraire le contenu du ZIP dans un répertoire précis (comme D:\\outils) de définir la variable d\u0026rsquo;environnement NODE_HOME (globalement sur la machine ou localement dans la console) d\u0026rsquo;ajouter %NODE_HOME% dans la variable d\u0026rsquo;environnement PATH 3.2.5 - Les IDE L\u0026rsquo;idée n\u0026rsquo;est pas de multiplier les outils mais d\u0026rsquo;utiliser le bon outil pour le bon usage.\nLes informations nécessaires à l\u0026rsquo;installation des IDEs sont regroupées ici mais ceci ne préjuge pas de l\u0026rsquo;ordre d\u0026rsquo;installation des outils (et tous ne sont pas forcément nécessaires).\n3.2.5.1 - IDE - Notepad++ Notepad++ est utilisé pour l\u0026rsquo;édition de la documentation.\nPour l\u0026rsquo;installer :\nTélécharger le binaire depuis le site officiel. Installer le. Pour installer le plugin DSpellCheck dans Notepad++ :\ncliquer sur le menu Modules d\u0026rsquo;extension \u0026gt; Gestionnaire des modules d\u0026rsquo;extension filter sur le nom DSpellCheck installer le plugin une fois le plugin installé, cliquer sur le menu Modules d\u0026rsquo;extension \u0026gt; DSpellCheck \u0026gt; Change current language \u0026gt; Download more language installer le pack français 3.2.5.2 - IDE - Eclipse La version Eclipse-2025-03 est utilisée pour la partie Java.\nPour l\u0026rsquo;installer :\ntélécharger la dernière version for Java Developpers depuis le site officiel. extraire l\u0026rsquo;archive dans le répertoire de votre choix (comme D:\\outils par exemple) créer un répertoire workspacepsl dans le répertoire de votre choix (comme D:\\workspaces par exemple) télécharger l\u0026rsquo;archive disponible ici (prévue pour eclipse-java-XXXX-XX-R-win32-x86_64) en extraire le contenu dans le répertoire workspacepsl précédemment créé (un répertoire .metadata doit donc être présent dans le répertoire workspacepsl) Ce workspace prépackagé prévoit la désactivation des fonctionnalités GIT d\u0026rsquo;Eclipse (qui traite projet par projet et non globalement par dépôt). Il référence un JDK installé dans le répertoire D:\\outils\\jdk-XXXX (à changer au besoin) Il prévoit tout un ensemble d\u0026rsquo;actions automatiques à la sauvegarde d\u0026rsquo;une classe Java (alias Java save actions). Il embarque un formattage du code Java (pour que tous les membres de l\u0026rsquo;équipe partage le même formattage). créer un raccourci Windows pointant sur D:\\outils\\eclipse-java-XXXX-XX-R-win32-x86_64\\eclipse.exe -showlocation -data D:\\workspaces\\workspacepsl -vm %JAVA_HOME%\\bin Ce raccourci pointe sur l\u0026rsquo;Eclipse installé. Ce raccourci pointe sur le workspace créé (à changer sur vos postes). Ce raccourci force l\u0026rsquo;utilisation du chemin du workspace dans le nom de la fenêtre (pratique quand plusieurs Eclipse sont démarrés en même temps) Ce raccourci force l\u0026rsquo;usage d\u0026rsquo;un DJK précis (à changer sur vos postes). au démarrage d\u0026rsquo;Eclipse, si la version de Java n\u0026rsquo;est pas supportée (Eclipse refuse de démarrer les tests automatisés et affiche sa version embarquée de JRE plutôt que la version de JDK paramétrée dans le workspace), il est possible de télécharger le plugin Java XX Support for Eclipse depuis le Marketplace après le démarrage, il est nécessaire d\u0026rsquo;installer le plugin SonarLint (profile par défaut) 3.2.5.3 - IDE - VSCode VScode est utilisé pour la partie Angular. Le projet utilise la dernière version disponible.\nPour l\u0026rsquo;installer VSCode :\ntélécharger la dernière version ZIP pour Windows de VSCode depuis le site officiel (car plus simple à mettre à jour). extraire l\u0026rsquo;archive dans un répertoire contenant la version de VSCode (toujours pour simplifier la mise à jour) créer un raccourci vers l\u0026rsquo;exécutable Code.exe et ajouter, à la fin du chemin, le chemin absolu vers le répertoire front (cela évite d\u0026rsquo;avoir à sélectionner le répertoire de travail) _La couverture de code ne fonctionne plus depuis le passage en Angular-17 et le passage de webpack à ESbuild/Vite (cf. https://v17.angular.io/guide/esbuild) _\nPour consulter les classes TS présentes dans les dépendances, il faut ajouter l\u0026rsquo;extension ZipFS dans VSCode.\nPour manipuler le projet ias, il faut ajouter l\u0026rsquo;extension WSL (l\u0026rsquo;extension ansible nécessite l\u0026rsquo;exécutable installé sur Windows mais il ne fonctionne pas).\n3.2.5.4 - IDE - Compass Compass est un IDE permettant de se connecter à une base de donnée MongoDB. Le projet utilise la dernière version disponible.\nPour l\u0026rsquo;installer :\ntélécharger la dernière version disponible depuis le site officiel) (pour Windows et au format ZIP). extraire l\u0026rsquo;archive téléchargée dans un répertoire (comme D:\\outils) démarrer le programme saisir la chaine de connexion mongodb://localhost:27017/?readPreference=primary\u0026amp;appname=MongoDB%20Compass\u0026amp;directConnection=true\u0026amp;ssl=false et se connecter 3.2.5.5 - IDE - UseBruno Historiquement (avant 2024), Postman était l\u0026rsquo;IDE de prédilection pour les requêtes HTTP. Mais, en 2023, la modification de leur modèle économique et le stockage du travail de chacun sur Internet (et non sur le poste local), a poussé ses utilisateurs vers d\u0026rsquo;autres solutions. Pour rappel, d\u0026rsquo;un point de vue SECURITE, il n\u0026rsquo;est pas envisageable de stocker des requêtes, des identifiants ou des certificats sur Internet.\nL\u0026rsquo;IDE à utiliser sur le projet est donc, maintenant, UseBruno.\nLe projet utilise la dernière version disponible sur la page de téléchargement.\nUne fois téléchargé et installé, il est nécessaire\nd\u0026rsquo;ouvrir la collection présente dans le répertoire 1-conception/static/installationdeposte/bruno/NewPSL de paramétrer l\u0026rsquo;IDE via le menu Collection \u0026gt; Préférences de paramétrer le proxy en fonction des besoins dans le cas d\u0026rsquo;une mise à jour ou d\u0026rsquo;une réinstallation, il faut déclarer le certificat racine. Pour cela, se référer à l\u0026rsquo;étape ajouter le certificat racine dans UseBruno du chapitre Créer le certificat signé localement L\u0026rsquo;usage de la collecion est décrit dans le chapitre 3.24.3. La création des certificats et clefs est décrites au chapitre $3.2.8 (plus loin dans cette page).\n3.2.5.6 - IDE - Règle sur l\u0026rsquo;utilisation des IDEs La configuration des IDE doit être commune à tous les développeurs de l\u0026rsquo;équipe pour permettre de maintenir une homogénéité du code et donc une bonne traçabilité des modifications.\nIl est tout à fait autorisé de modifier l\u0026rsquo;apparence de son IDE (skin, thème, raccourcis, \u0026hellip;) mais le paramétrage influant sur le code (formatage, import, \u0026hellip;) ne doit pas être modifié.\n3.2.5.7 - OUTILS - SMTP4DEV (pas nécessaire dans un premier temps) Pour recevoir les emails envoyés par le système, il suffit d\u0026rsquo;installer smtp4dev en laissant le paramétrage par défaut et en le démarrant avec le programme Rnwood.Smtp4dev.exe.\nUne fois démarré, l\u0026rsquo;interface graphique du serveur SMTP est disponible ici.\nLa documentation de l\u0026rsquo;outil est ici.\n3.2.5.8 - OUTILS - SpringBootCli (pas nécessaire dans un premier temps) SpringBootCli est un outil en ligne de commande lié à SpringBoot. Il est principalement utilisé pour chiffrer/déchiffrer des clefs de configuration.\nPour l\u0026rsquo;installer, il faut (inspiré de la documentation officielle) :\ntélécharger la dernière version de spring-boot-cli-*-bin.zip depuis le repository officiel extraire l\u0026rsquo;archive dans le répertoire des outils créer une variable d\u0026rsquo;environnement Windows nommée SPRING_HOME contenant le chemin vers le répertoire créé ajouter SPRING_HOME/bin dans la variable d\u0026rsquo;environnement PATH 3.2.6 - Compiler les sources Pour builder le projet une première fois, il suffit de lancer la commande mvn clean install depuis une ligne de commande ouverte à la racine du dépôt (puis de patienter).\nPour compiler les sources individuellement :\ndocumentation : depuis le répertoire 1-conception, exécuter le raccourci startServer.cmd (ou startServer.sh) front, depuis le répertoire _D:\\xxx\\2-code\\front_, exécuter la commande npm ci Quand on installe son poste, il ne faut jamais utiliser la commande npm install ou yarn install. npm ci ou yarn install --frozen-lockfile installe les dépendances exactes du package-lock.json ou du yarn.lock quand install recherche des dépendances compatibles.\n3.2.7 - Ré-activer la vérification SSL Il se peut que, sur certains postes de développement professionnels, un certificat racine propre à la société soit paramétré. Ceci se vérifie dans Chrome :\nouvrir Chrome en étant connecté au réseau de l\u0026rsquo;entreprise afficher un site HTTPs dans un onglet cliquer sur le cadenas dans la barre d\u0026rsquo;adresse afficher le certificat en cliquant sur les messages la connexion est sécurisée puis certificat valide dans la fenêtre qui s\u0026rsquo;ouvre, vérifier la donnée intitulée Délivré par Si le certificat Racine du service HTTPs appelé n\u0026rsquo;est pas délivré/vérifié par une autorité de certification standard, alors le certificat racine n\u0026rsquo;est pas présent dans le CACERT du JDK (qui contient déjà les principaux certificats racines du monde).\nDeux solutions sont possibles :\ndésactiver les vérifications SSL (cf. clients.desactiverSSL dans les fichiers de configuration) ajouter, dans le CACERT du JDK, le certificat racine de l\u0026rsquo;employeur (cf. ci-dessous) Pour ajouter le certificat de votre entreprise, dans le trustore de Java (pour les tests automatisés) et dans le trustore utilisé par les micro-service, il faut :\nréafficher la fenêtre comme décrit précédemment dans la fenêtre ouverte, afficher l\u0026rsquo;onglet Détails sélectionner le certificat racine et cliquer sur le bouton exporter pour extraire le certificat dans un fichier ouvrir une ligne de commande dans le répertoire $JAVA_HOME/lib/security/ exécuter les commandes (avec XXXXX le libellé de votre choix) cp \u0026#34;$JAVA_HOME/lib/security/cacerts\u0026#34; \u0026#34;$JAVA_HOME/lib/security/cacerts-saveXXXXX\u0026#34; keytool -import -trustcacerts -file \u0026#34;/chemin/vers/le/certificat.cer\u0026#34; -alias certificatEntreprise -keystore \u0026#34;$JAVA_HOME/lib/security/cacerts\u0026#34; -storepass changeit Pour vérifier que cette modification fonctionne (ou ne sert à rien), exécuter les tests du projet socle-commun et vérifier la bonne exécution des tests de la classe AbstractClientHttpTest.\n3.2.8 - Certificats 3.2.8.1 - Créer le certificat racine et le faire accepter par Windows et Java Pour créer un certificat signé localement (source), il faut, en premier lieu, disposer d\u0026rsquo;une autorité de certification enregistrée dans Windows et dans Java. Pour cela, il faut :\n0/ !! En cas de besoin seulement !! Voici comment détruire toute la partie certificats potentiellement déjà créée dans une installation précédente : Fichiers : Supprimer le répertoire 2-code/.certificatsLocaux Certificat racine dans Windows : Ouvrir Microsoft Management Console en utilisant la combinaison Windows + R et tapant mmc avant de valider Cliquer sur Fichier \u0026gt; Ajouter/Supprimer un composant logiciel enfichable Cliquer sur Certificats and Ajouter Sélectionner Un compte d\u0026rsquo;ordinateur et cliquer sur Suivant Sélectionner Ordinateur local et cliquer sur Terminer Cliquer sur OK Double-cliquer sur Certificats (ordinateur local) Sélectionner Autorités de certification racines de confiance Cliquer droit sur Autorités de certification racines de confiance Cliquer sur Rechercher des certificats Sélectionner la valeur Autorités de certification racines de confiance dans le champs Rechercher dans Taper le mot Amiens dans le champ Contenu Cliquer sur Rechercher maintenant Cliquer droit sur l\u0026rsquo;entrée disponible Cliquer sur Supprimer puis confirmer Fermer la fenêtre sans enregistrer Certificat racine dans Java : Exécuter la commande keytool -delete -alias caRacineDevLocal -keystore \u0026#34;$JAVA_HOME/lib/security/cacerts\u0026#34; -storepass changeit Warning: use -cacerts option to access cacerts keystore 1/ Créer une clef et un certificat d\u0026rsquo;autorité ouvrir une ligne de commande dans le répertoire racine du dépôt mkdir -p 2-code/.certificatsLocaux/caRacine cd 2-code/.certificatsLocaux/caRacine openssl genrsa -des3 -out ca-clefAutoriteCertification.key -passout pass:mdpAutoriteCertification 2048 Generating RSA private key, 2048 bit long modulus (2 primes) .......................+++++ ....+++++ e is 65537 (0x010001) openssl req -x509 -new -nodes -key ca-clefAutoriteCertification.key -sha256 -days 1825 -out ca-certificatRacine.pem -passout pass:mdpAutoriteCertification -passin pass:mdpAutoriteCertification -subj \u0026#34;//C=FR/ST=Amiens/L=Amiens/O=Security/OU=general/CN=guillaumetalbot.com\u0026#34; req: Skipping unknown attribute \u0026#34;/C\u0026#34; 2/ Ajouter ce certificat racine dans Windows : Ouvrir Microsoft Management Console en utilisant la combinaison Windows + R et tapant mmc avant de valider Cliquer sur Fichier \u0026gt; Ajouter/Supprimer un composant logiciel enfichable Cliquer sur Certificats and Ajouter Sélectionner Un compte d\u0026rsquo;ordinateur et cliquer sur Suivant Sélectionner Ordinateur local et cliquer sur Terminer Cliquer sur OK Double-cliquer sur Certificats (ordinateur local) Cliquer droit sur Autorités de certification racines de confiance Sélectionner Toutes les tâches \u0026gt; Import Cliquer sur Suivant et Parcourir Sélectionner le fichier ca-certificatRacine.pem Cliquer sur Suivant Choisir de placer les certificats dans Autorités de certification racines de confiance (valeur par défaut normalement) Cliquer sur Suivant et Terminer 3/ Pour vérifier le bon ajout du certificat racine Retourner (ou rester) dans la partie Autorités de certification racines de confiance de Microsoft Management Console Cliquer droit sur Autorités de certification racines de confiance Cliquer sur Rechercher des certificats Sélectionner la valeur Autorités de certification racines de confiance dans le champs Rechercher dans Taper le mot Amiens dans le champ Contenu Cliquer sur Rechercher maintenant Vérifier qu\u0026rsquo;une entrée apparaît avec une date d\u0026rsquo;expiration à +5 ans -1 jour Fermer la fenêtre Microsoft Management Console sans enregistrer 3/ Déclarer cette autorité dans Java : Se replacer (si besoin) dans le répertoire 2-code/.certificatsLocaux/caRacine Vérifier que la variable JAVA_HOME pointe bien sur la version de Java utilisée pour le projet : echo $JAVA_HOME Dupliquer le cacert par défaut de Java (pour en faire une sauvegarde) rm -f \u0026#34;$JAVA_HOME/lib/security/cacerts-save\u0026#34; cp \u0026#34;$JAVA_HOME/lib/security/cacerts\u0026#34; \u0026#34;$JAVA_HOME/lib/security/cacerts-save\u0026#34; Importer le certificat racine en exécutant la commande suivante, depuis le répertoire 2-code.certificatsLocaux\\caRacine (répondre yes à la confirmation) keytool -import -trustcacerts -file \u0026#34;ca-certificatRacine.pem\u0026#34; -alias caRacineDevLocal -keystore \u0026#34;$JAVA_HOME/lib/security/cacerts\u0026#34; -storepass changeit Vérifier la présence du certificat racine keytool -v -list -keystore \u0026#34;$JAVA_HOME/lib/security/cacerts\u0026#34; -storepass changeit | grep \u0026#34;Alias name\u0026#34; | grep caracinedevlocal Warning: use -cacerts option to access cacerts keystore Alias name: caracinedevlocal Sont donc présents, dans le répertoire 2-code/.certificatsLocaux/caRacine, le certificat racine (extension PEM) la clef permettant de signer un certificat (extension KEY) 3.2.8.2 - Créer le certificat signé localement (TLS/HTTPs) Tous les micro-services du socle ne s\u0026rsquo;exposent exclusivement que sur une interface https. Le certificat TLS doit être signé avec l\u0026rsquo;autorité de certification créée précédemment. Pour cela, il faut :\n0/ Pour recréer les éléments de ce chapitre, rien n\u0026rsquo;est réutilisable (car le CSR n\u0026rsquo;est pas conservé). Donc il faut supprimer tous les fichiers du répertoire 2-code/.certificatsLocaux/tls s\u0026rsquo;il existe.\n1/ Créer un certificat propre à l\u0026rsquo;environnement de développement\nmkdir -p 2-code/.certificatsLocaux/tls cd 2-code/.certificatsLocaux/tls openssl req -new -sha256 -nodes -out dev-certificatDeDeveloppementNonSigne.csr -newkey rsa:2048 -keyout dev-clefDeDeveloppement.key -passout pass:mdpCertificatDeDeveloppement -subj \u0026#34;//C=FR/ST=Amiens/L=Amiens/O=Security/OU=newPSL/CN=dev-psl.guillaumetalbot.com\u0026#34; Generating a RSA private key .............................................+++++ .....................+++++ writing new private key to \u0026#39;dev-clefDeDeveloppement.key\u0026#39; ----- req: Skipping unknown attribute \u0026#34;/C\u0026#34; 2/ Signer ce certificat de développement avec l\u0026rsquo;autorité de certification echo \u0026#34;authorityKeyIdentifier=keyid,issuer\u0026#34; \u0026gt;dev-confSignature.cnf echo \u0026#34;basicConstraints=CA:FALSE\u0026#34; \u0026gt;\u0026gt;dev-confSignature.cnf echo \u0026#34;keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\u0026#34; \u0026gt;\u0026gt;dev-confSignature.cnf echo \u0026#34;subjectAltName=DNS:machineUbuntuTest,DNS:dev-psl.guillaumetalbot.com,DNS:*.dev-psl.guillaumetalbot.com,DNS:localhost,IP:127.0.0.1\u0026#34; \u0026gt;\u0026gt;dev-confSignature.cnf openssl x509 -req -in dev-certificatDeDeveloppementNonSigne.csr -passin pass:mdpAutoriteCertification -CA ../caRacine/ca-certificatRacine.pem -CAkey ../caRacine/ca-clefAutoriteCertification.key -CAcreateserial -out dev-certificatDeDeveloppementSigne.crt -days 3650 -sha256 -extfile dev-confSignature.cnf Signature ok subject=ST = Amiens, L = Amiens, O = Security, OU = newPSL, CN = dev-psl.guillaumetalbot.com Getting CA Private Key rm dev-confSignature.cnf rm dev-certificatDeDeveloppementNonSigne.csr 3/ Créer un PKCS12 (format standard remplaçant JKS) à partir du certificat signé (pour être utilisé dans Java) openssl pkcs12 -export -out keystore.p12 -inkey dev-clefDeDeveloppement.key -in dev-certificatDeDeveloppementSigne.crt -certfile ../caRacine/ca-certificatRacine.pem -password pass:changeit 4/ Paramétrer le keystore dans les micro-services 4.1/ modifier/vérifier le contenu du fichier /socle/variablesPourScripts.properties.gpg (cf. §3.37.6) cheminRelatifKeystore=\u0026#34;../.certificatsLocaux/tls/keystore.p12\u0026#34; motdepasseKeystore=\u0026#34;changeit\u0026#34; 4.2/ modifier/vérifier le contenu des configurations d\u0026rsquo;exécution Eclipse (fichier .launch) \u0026lt;stringAttribute key=\u0026#34;org.eclipse.jdt.launching.VM_ARGUMENTS\u0026#34; value=\u0026#34;-DcheminKeystore=../../.certificatsLocaux/tls/keystore.p12 -DmdpKeystore=changeit\u0026#34;/\u0026gt; 4.3/ ajouter le certificat racine dans UseBruno ouvrir UseBruno dans le menu Collection \u0026gt; Preferences, cocher la case Use custom CA Certificate et de sélectionner le fichier 2-code/.certificatsLocaux/caRacine/ca-certificatRacine.pem 3.2.8.3 - Créer un certificat client d\u0026rsquo;appel aux APIs d\u0026rsquo;administration Certains micro-services du socle exposent des APIs d\u0026rsquo;administration exclusivement accessibles si la requête contient un certificat autorisé. Pour cela, il faut :\n1/ Créer un certificat client propre à l\u0026rsquo;environnement de développement Exécuter les commandes suivantes mkdir -p 2-code/.certificatsLocaux/authAdmin cd 2-code/.certificatsLocaux/authAdmin openssl genrsa -out certificatClientAppelApiAdmin-clefPrivee.key 4096 MSYS_NO_PATHCONV=1 openssl req -new -key certificatClientAppelApiAdmin-clefPrivee.key -out certificatClientAppelApiAdmin-certifNonSigne.csr -nodes -subj \u0026#34;/CN=developeurLocal1/OU=talbotgui/O=github/C=com\u0026#34; echo \u0026#34;[SAN]\u0026#34; \u0026gt;opensslConf.txt echo \u0026#34;subjectAltName=DNS:dev-psl.guillaumetalbot.com,DNS:localhost\u0026#34; \u0026gt;\u0026gt;opensslConf.txt openssl x509 -req -days 360 -in certificatClientAppelApiAdmin-certifNonSigne.csr -passin pass:mdpAutoriteCertification -CA ../caRacine/ca-certificatRacine.pem -CAkey ../caRacine/ca-clefAutoriteCertification.key -CAcreateserial -out certificatClientAppelApiAdmin-certifSigne.crt -sha256 -extensions SAN -extfile opensslConf.txt rm opensslConf.txt openssl pkcs12 -export -out certificatClientAppelApiAdmin.p12 -inkey certificatClientAppelApiAdmin-clefPrivee.key -in certificatClientAppelApiAdmin-certifSigne.crt -password pass:changeit * _L'astuce du MSYS_NO_PATHCONV est décrite [ici](https://github.com/git-for-windows/git/issues/577#issuecomment-166118846)._ Supprimer le fichier certificatClientAppelApiAdmin-certifNonSigne.csr\nSont dont présents les fichiers\ncertificatClientAppelApiAdmin.jks utilisé dans les applicatifs Java certificatClientAppelApiAdmin.p12 utilisé dans les commandes CURL certificatClientAppelApiAdmin-certifSigne.crt et certificatClientAppelApiAdmin-clefPrivee.key utilisés dans Postman Ajouter dev-psl.guillaumetalbot.com dans les sites de confiances\ndémarrer Internet Explorer ouvrir les propriétés \u0026gt; sécurité \u0026gt; site de confiances ajouter dev-psl.guillaumetalbot.com 2/ Créer un truststore pour contenir les certificats \u0026ldquo;client\u0026rdquo; autorisés\nkeytool -import -trustcacerts -noprompt -alias certificatClientAppelApiAdmin1 -ext san=dns:dev-psl.guillaumetalbot.com,localhost,ip:127.0.0.1 -file certificatClientAppelApiAdmin-certifSigne.crt -keystore certificatClientAppelApiAdmin.jks -storepass changeit -keypass changeit 3/ Paramétrer le truststore dans les micro-services 3.1/ modifier/vérifier le contenu du fichier /socle/variablesPourScripts.properties.gpg (cf. §3.37.6) cheminRelatifTruststore=\u0026#34;../.certificatsLocaux/authAdmin/certificatClientAppelApiAdmin.jks\u0026#34; motdepasseTruststore=\u0026#34;changeit\u0026#34; 3.2/ modifier/vérifier le contenu des configurations d\u0026rsquo;exécution Eclipse (fichier .launch) \u0026lt;stringAttribute key=\u0026#34;org.eclipse.jdt.launching.VM_ARGUMENTS\u0026#34; value=\u0026#34;xxxxx -DcheminTruststore=../../.certificatsLocaux/authAdmin/certificatClientAppelApiAdmin.jks -DmdpTruststore=changeit\u0026#34;/\u0026gt; Pour tester le certificat et le trustStore, après avoir démarré l\u0026rsquo;ensemble du socle, il est possible d\u0026rsquo;exécuter les commandes suivantes (en remplaçant le port par celui du micro-service)\ncurl -vk --cert certificatClientAppelApiAdmin-certifSigne.crt --key certificatClientAppelApiAdmin-clefPrivee.key https://dev-psl.guillaumetalbot.com:65129/socle/notification/admin/statistiques curl -vk --cert-type P12 --cert certificatClientAppelApiAdmin.p12:changeit https://dev-psl.guillaumetalbot.com:65129/socle/notification/admin/statistiques PKCS12 est le format standard des keystores (à opposer à JKS qui est propre à Java). Depuis la version 8 de Java, ce dernier gère les PKCS12. (source baeldung).\n3.2.9 - Installer les outils nécessaires au projet IAS (Infrastructure As Code) (pas nécessaire dans un premier temps) Installer les machines WSL :\nPour (re)installer WSL, si c\u0026rsquo;est la première installation de WSL, depuis une ligne de commande DOS, exécuter : echo \u0026#34;activer WSL\u0026#34; wsl --install si WSL est déjà installé, depuis une ligne de commande DOS, exécuter : echo \u0026#34;lister les machines\u0026#34; wsl --list echo \u0026#34;pour chaque machine, exécuter\u0026#34; wsl --unregister XXX Pour installer WSL et des machines récentes, exécuter, depuis une ligne de commande DOS, les commandes suivantes : echo \u0026#34;créer une clef SSH pour permettre à Ansible de se connecter à la machine\u0026#34; del %USERPROFILE%\\.ssh\\wsl.key del %USERPROFILE%\\.ssh\\wsl.key.pub ssh-keygen -t rsa -b 2048 -f %USERPROFILE%/.ssh/wsl.key -N \u0026#34;\u0026#34; echo \u0026#34;mettre à jour WSL\u0026#34; wsl --update echo \u0026#34;installer la version d\u0026#39;Ubuntu par défaut\u0026#34; wsl --install -d Ubuntu Dans la fenêtre WSL, du fait du premier démarrage, il est nécessaire de saisir un compte et un mot de passe. Saisir ubuntu pour toutes les questions. Si besoin (l\u0026rsquo;installation démarre habituellement l\u0026rsquo;instance), démarrer l\u0026rsquo;instance echo \u0026#34;démarer l\u0026#39;instance\u0026#34; wsl -d Ubuntu Pour initialiser la machine Ubuntu de base du projet, exécuter une première fois la commande sudo ls /etc pour que les prochaines commandes sudo ne réclame pas de mot de passe (pour tout copier/coller) exécuter les commandes suivantes, dans WSL, echo \u0026#34;suppression des fichiers (pas dans le même bloc que leur création)\u0026#34; sudo rm -f /etc/wsl.conf sudo rm -f /etc/resolv.conf rm -rf ~/.ssh echo \u0026#34;activation de systemd sur la machine (et création du fichier)\u0026#34; echo \u0026#39;[boot]\u0026#39; | sudo tee /etc/wsl.conf echo \u0026#39;systemd=true\u0026#39; | sudo tee -a /etc/wsl.conf echo \u0026#39;[network]\u0026#39; | sudo tee -a /etc/wsl.conf echo \u0026#34;déclarer un DNS pour accéder à Internet (sans support du proxy Windows)\u0026#34; echo \u0026#39;generateResolvConf=false\u0026#39; | sudo tee -a /etc/wsl.conf echo \u0026#34;pour pouvoir manipuler le nom de la machine\u0026#34; echo \u0026#39;hostname = machineUbuntuTest\u0026#39; | sudo tee -a /etc/wsl.conf echo \u0026#39;nameserver 8.8.8.8\u0026#39; | sudo tee -a /etc/resolv.conf sudo chattr +i /etc/resolv.conf echo \u0026#34;pour forcer la connexion avec le compte ubuntu\u0026#34; echo \u0026#39;[user]\u0026#39; | sudo tee -a /etc/wsl.conf echo \u0026#39;default=ubuntu\u0026#39; | sudo tee -a /etc/wsl.conf echo \u0026#34;pour pouvoir manipuler les autorisations (chmod) depuis WSL sur des répertoires Windows\u0026#34; echo \u0026#39;[automount]\u0026#39; | sudo tee -a /etc/wsl.conf echo \u0026#39;options = \u0026#34;metadata\u0026#34;\u0026#39; | sudo tee -a /etc/wsl.conf echo \u0026#34;initialiser le fichier des clefs RSA autorisées (en remplaçant par le bon login)\u0026#34; mkdir ~/.ssh touch ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys cat /mnt/c/Users/$USERNAME/.ssh/wsl.key.pub \u0026gt;~/.ssh/authorized_keys sed -i \u0026#39;s/@.*/@localhost/g\u0026#39; ~/.ssh/authorized_keys exécuter les commandes suivantes, une à une, dans WSL, echo \u0026#34;vérifier que tout est fait (9, 1, 1)\u0026#34; wc -l /etc/wsl.conf cat /etc/resolv.conf | grep 8.8.8.8 | wc -l cat ~/.ssh/authorized_keys | grep localhost | wc -l echo \u0026#34;Activation des releases non LTS\u0026#34; sudo sed -i \u0026#39;s/=lts/=normal/g\u0026#39; /etc/update-manager/release-upgrades echo \u0026#34;Mise à jour du système (répondre yes et attendre)\u0026#34; sudo do-release-upgrade echo \u0026#34;mettre à jour la machine\u0026#34; sudo apt-get update sudo apt-get upgrade -y sudo apt-get dist-upgrade -y echo \u0026#34;Afficher la version installée\u0026#34; lsb_release -a echo \u0026#34;personnalisation du répertoire par défaut de la machine (à customiser)\u0026#34; echo \u0026#34;\u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;#répertoire par défaut à la connexion\u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;cd /mnt/d/xxx/2-code/ias\u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;sortir de la machine\u0026#34; exit Pour créer deux machines basées sur cette version d\u0026rsquo;Ubuntu, depuis une ligne de commande DOS, exécuter les commandes : echo \u0026#34;complètement arrêter WSL pour prendre en compte le paramétrage\u0026#34; wsl --shutdown echo \u0026#34;se placer dans le répertoire 2-code/ias/machinesWsl\u0026#34; cd xxxxxxxxxxxxxxxxxxxxx echo \u0026#34;supprimer les machines existantes (si présentes)\u0026#34; del ubuntu_nue.tar rmdir UbuntuAnsible rmdir UbuntuTest echo \u0026#34;création d\u0026#39;une photo de la machine\u0026#34; wsl --export Ubuntu ubuntu_nue.tar echo \u0026#34;création des nouvelles instances basées sur l\u0026#39;image\u0026#34; wsl --import UbuntuAnsible .\\UbuntuAnsible ubuntu_nue.tar wsl --import UbuntuTest .\\UbuntuTest ubuntu_nue.tar Pour démarrer les machines, depuis deux lignes de commande DOS différentes, exécuter\nwsl -d UbuntuAnsible wsl -d UbuntuTest Dans la machine UbuntuTest, exécuter les commandes :\necho \u0026#34;personnalisation du prompt\u0026#34; echo \u0026#34;\u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;# personnalisation du prompt\u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;PS1=\u0026#39;${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@test\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ \u0026#39;\u0026#34; \u0026gt;\u0026gt; ~/.bashrc . ~/.bashrc echo \u0026#34;installer openssh-server\u0026#34; sudo apt-get install openssh-server -y sudo systemctl enable ssh echo \u0026#34;installer ACL pour permettre le démarrage des applicatifs avec le compte www\u0026#34; sudo apt-get install acl echo \u0026#34;vérifier que openssh est démarré (doit s\u0026#39;afficher en vert \u0026#39;active (running)\u0026#39;)\u0026#34; sudo service ssh status echo \u0026#34;installer une librairie nécessaire à MongoDB (pour le message : libcrypto.so.1.1: cannot open shared object file: No such file or directory)\u0026#34; wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.0g-2ubuntu4_amd64.deb sudo dpkg -i libssl1.1_1.1.0g-2ubuntu4_amd64.deb rm libssl1.1_1.1.0g-2ubuntu4_amd64.deb echo \u0026#34;paramétrer le hostname (le fichier /etc/hosts est une copie du fichier C:\\Windows\\System32\\drivers\\etc\\hosts de Windows)\u0026#34; echo \u0026#39;machineUbuntuTest\u0026#39; | sudo tee /etc/hostname Pour tester la bonne connexion à la machine UbuntuTest,\nouvrir une nouvelle ligne de commande DOS exécuter ssh -i C:/Users/%username%/.ssh/wsl.key ubuntu@localhost en cas d\u0026rsquo;erreur impliquant remote host identification, supprimer la ligne commençant par localhost dans le fichier C:\\Users%username%.ssh\\known_hosts en cas d\u0026rsquo;erreur, vérifier le contenu du fichier ~/.ssh/authorized_keys dans WSL (erreur récurente) fermer la nouvelle ligne de commande DOS Dans la machine UbuntuAnsible, exécuter les commandes :\necho \u0026#34;personnalisation du prompt et ajout d\u0026#39;un chemin dans le path\u0026#34; echo \u0026#34;\u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;# personnalisation du prompt\u0026#34; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#34;PS1=\u0026#39;${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@ansible\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ \u0026#39;\u0026#34; \u0026gt;\u0026gt; ~/.bashrc . ~/.bashrc echo \u0026#34;installation d\u0026#39;Ansible (pipx est long à s\u0026#39;exécuter - cf. https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html)\u0026#34; sudo apt install pipx -y pipx install --include-deps ansible echo \u0026#39;export PATH=\u0026#34;/home/ubuntu/.local/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bashrc . ~/.bashrc echo \u0026#34;vérifier la bonne installation\u0026#34; ansible --version echo \u0026#34;correction des droits sur la clef SSH (chemin à adapter avec la variable saisie dans les scripts Ansible)\u0026#34; sudo chmod 600 /mnt/c/Users/%username%/.ssh/wsl.key echo \u0026#34;Installer les logiciels nécessaires à la documentation d\u0026#39;Ansible (pipx peut être long à s\u0026#39;exécuter)\u0026#34; sudo apt-get update sudo apt-get install graphviz -y pipx install ansible-playbook-grapher Pour réaliser une installation complète, depuis UbuntuAnsible, exécuter les commandes echo \u0026#34;première installation - commandes de préparation (avec droits SUDO)\u0026#34; ansible-playbook ansible/01_preparer.yml -i ansible/inventory/local -K --extra-vars \u0026#34;ansible_user=ubuntu\u0026#34; ansible-playbook ansible/02_installer.yml -i ansible/inventory/local ansible-playbook ansible/03_deployer.yml -i ansible/inventory/local ansible-playbook ansible/04_demarrer.yml -i ansible/inventory/local ansible-playbook ansible/05_statuer.yml -i ansible/inventory/local ansible-playbook ansible/06_arreter.yml -i ansible/inventory/local Pour valider le bon fonctionnement complet (cas uniquement d\u0026rsquo;une mise à jour de l\u0026rsquo;environnement), se référer aux étapes 4 et suppérieures du chapitre 3.36.4 3.2.10 - Modifier le fichier host de Windows Tous les applicatifs répondent sur le DNS dev-psl.guillaumetalbot.com. Mais ce DNS n\u0026rsquo;existe pas. Il faut donc le déclarer à Windows. Pour ce faire :\nouvrir le menu Démarrer de Windows recherche bloc note faire un clic droit et sélectionner Executer en tant qu\u0026rsquo;administrateur cliquer sur le menu Fichier \u0026gt; Ouvrir sélectionner le répertoire C:\\Windows\\System32\\drivers\\etc taper * dans le champs de saisie de fichier pour faire apparaître tous les fichiers sélectionner le fichier hosts ajouter les lignes suivantes (si elles n\u0026rsquo;y sont pas déjà) : # dev local ::1 dev-psl.guillaumetalbot.com admin.dev-psl.guillaumetalbot.com # Nécessaire pour que les applicatifs s\u0026#39;enregistrent auprès du service-admin quand ils sont démarrés depuis Git4Windows avec le script demarrerTout.sh 127.0.0.1 dev-psl.guillaumetalbot.com admin.dev-psl.guillaumetalbot.com # mais les appels interne à Ubuntu sont aussi résolus simplements (rappel : le hosts de Windows est copié dans WSL) 127.0.0.1 machineUbuntuTest 3.2.11 - Initialiser un fichier de cache L\u0026rsquo;applicatif socle-referentiel télécharge un fichier de plus de 1Go et le conserve, sur disque, en guise de cache. Or seule une toute petite portion du fichier est nécessaire. Pour limiter l\u0026rsquo;espace pris par ce cache, il faut :\ntélécharger le fichier de référentiel des SIRET placer ce fichier dans le répertoire 2-code/socle/.cache avec le nom referentiel-dataGouv-siret (supprimer le fichier s\u0026rsquo;il existe) exécuter la commande cd 2-code/socle/.cache unzip referentiel-dataGouv-siret rm referentiel-dataGouv-siret mv StockEtablissement_utf8.csv StockEtablissement_utf8_original.csv cat StockEtablissement_utf8_original.csv | grep A,MAIRIE \u0026gt;StockEtablissement_utf8.csv rm StockEtablissement_utf8_original.csv créer un ZIP nommé referentiel-dataGouv-siret contenant le fichier StockEtablissement_utf8.csv Si l\u0026rsquo;applicatif socle-referentiel, s\u0026rsquo;exécutant sur la machine WSL est long à démarrer, copier le fichier de cache dans le bon répertoire en exécutant les commandes :\nsudo su - www mkdir /psl/applicatifs/socle-referentiel/.cache cp /mnt/d/xxx/2-code/socle/.cache/referentiel-dataGouv-siret /psl/applicatifs/socle-referentiel/.cache/ 3.2.12 - FAQ Si Node ne veut pas fonctionner durant le npm ci, tenter la commande suivante : npm cache clean -f En cas d\u0026rsquo;erreur, dans les tests automatisés, du type Caused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target : ajouter -Djavax.net.debug=all dans la configuration du test et relancer le test.\nPour se simplifier la vie, une fois le compte www créé sur la machine UbuntuTest, il est utile de créer ces alias :\necho \u0026#34;ajouter un alias pour tout demarrer/arrêter dans le compte www\u0026#34; sudo su - www echo \u0026#34;alias demarrerTout=\u0026#39;/psl/applicatifs/service-gateway/service-gateway.sh startAndWait ; /psl/applicatifs/service-registry/service-registry.sh startAndWait ; /psl/applicatifs/service-nosql/service-nosql.sh startAndWait ; /psl/applicatifs/service-config/service-config.sh startAndWait ; /psl/applicatifs/service-admin/service-admin.sh startAndWait ; /psl/applicatifs/service-ldap/service-ldap.sh startAndWait ; /psl/applicatifs/socle-dbbrouillon/socle-dbbrouillon.sh startAndWait ; /psl/applicatifs/socle-dbconfiguration/socle-dbconfiguration.sh startAndWait ; /psl/applicatifs/socle-dbdocument/socle-dbdocument.sh startAndWait ; /psl/applicatifs/socle-dbnotification/socle-dbnotification.sh startAndWait ; /psl/applicatifs/socle-referentiel/socle-referentiel.sh startAndWait ; /psl/applicatifs/socle-referentielexterne/socle-referentielexterne.sh startAndWait ; /psl/applicatifs/socle-securite/socle-securite.sh startAndWait ; /psl/applicatifs/socle-soumission/socle-soumission.sh startAndWait ; /psl/applicatifs/socle-transfert/socle-transfert.sh startAndWait ; /psl/applicatifs/socle-admin/socle-admin.sh startAndWait\u0026#39;\u0026#34; \u0026gt;\u0026gt; .bashrc echo \u0026#34;alias arreterTout=\u0026#39;/psl/applicatifs/service-nosql/service-nosql.sh stop \u0026amp;\u0026amp; /psl/applicatifs/service-config/service-config.sh stop \u0026amp;\u0026amp; /psl/applicatifs/service-admin/service-admin.sh stop \u0026amp;\u0026amp; /psl/applicatifs/service-ldap/service-ldap.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-dbbrouillon/socle-dbbrouillon.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-dbconfiguration/socle-dbconfiguration.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-dbdocument/socle-dbdocument.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-dbnotification/socle-dbnotification.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-referentiel/socle-referentiel.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-referentielexterne/socle-referentielexterne.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-securite/socle-securite.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-soumission/socle-soumission.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-transfert/socle-transfert.sh stop \u0026amp;\u0026amp; /psl/applicatifs/service-gateway/service-gateway.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-admin/socle-admin.sh stop \u0026amp;\u0026amp; /psl/applicatifs/service-registry/service-registry.sh stop\u0026#39;\u0026#34; \u0026gt;\u0026gt; .bashrc echo \u0026#34;alias statutTout=\u0026#39;/psl/applicatifs/service-gateway/service-gateway.sh status \u0026amp;\u0026amp; /psl/applicatifs/service-registry/service-registry.sh status \u0026amp;\u0026amp; /psl/applicatifs/service-nosql/service-nosql.sh status \u0026amp;\u0026amp; /psl/applicatifs/service-config/service-config.sh status \u0026amp;\u0026amp; /psl/applicatifs/service-admin/service-admin.sh status \u0026amp;\u0026amp; /psl/applicatifs/service-ldap/service-ldap.sh stop \u0026amp;\u0026amp; /psl/applicatifs/socle-dbbrouillon/socle-dbbrouillon.sh status \u0026amp;\u0026amp; /psl/applicatifs/socle-dbconfiguration/socle-dbconfiguration.sh status \u0026amp;\u0026amp; /psl/applicatifs/socle-dbdocument/socle-dbdocument.sh status \u0026amp;\u0026amp; /psl/applicatifs/socle-dbnotification/socle-dbnotification.sh status \u0026amp;\u0026amp; /psl/applicatifs/socle-referentiel/socle-referentiel.sh status \u0026amp;\u0026amp; /psl/applicatifs/socle-referentielexterne/socle-referentielexterne.sh status \u0026amp;\u0026amp; /psl/applicatifs/socle-securite/socle-securite.sh status \u0026amp;\u0026amp; /psl/applicatifs/socle-soumission/socle-soumission.sh status \u0026amp;\u0026amp; /psl/applicatifs/socle-transfert/socle-transfert.sh status \u0026amp;\u0026amp; /psl/applicatifs/socle-admin/socle-admin.sh status\u0026#39;\u0026#34; \u0026gt;\u0026gt; .bashrc . ~/.bashrc Si plusieurs versions de Java sont présentes sur le poste de développement, il est possible de créer plusieurs aliases dans la ligne de commande GIT pour exécuter Maven avec une version de Java spécifique. Pour cela, il faut éditer le fichier C:\\Program Files\\Git\\etc\\profile.d\\aliases.sh pour y ajouter les lignes suivantes : alias mvn8=\u0026#34;JAVA_HOME=/d/xxxxxx/jdk-1.8.0.212 \u0026amp;\u0026amp; mvn\u0026#34; alias mvn11=\u0026#34;JAVA_HOME=/d/xxxxxx/jdk-11.0.20.1+1 \u0026amp;\u0026amp; mvn\u0026#34; alias mvn17=\u0026#34;JAVA_HOME=/d/xxxxxx/jdk-17.0.2 \u0026amp;\u0026amp; mvn\u0026#34; "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.3demarrertout/",
	"title": "3.3 Démarrer tout",
	"tags": [],
	"description": "",
	"content": "\r3.3.1 - Démarrer tout 3.2.2 - Ordre de démarrage des composants du socle 3.3.1 - Démarrer tout Pour démarrer l\u0026rsquo;ensemble des applications JAVA et FRONT sur un poste de développement, il faut :\nen prérequis : avoir installé son poste de développement convenablement (cf. §3.2) avoir compilé avec succès tous les projets Java avec Maven avoir installé toutes les dépendances JS avec NPM (avec la commande npm ci) démarrer les projets Java ouvrir une ligne de commande git4windows dans le répertoire 2-code\\socle exécuter la commande . ./demarrerTout.sh une fois la commande terminée, pour vérifier la liste des processus démarrés, exécuter la commande . ./outils.sh PS démarrer les projets Front ouvrir une ligne de commande git4windows dans le répertoire 2-code\\front exécuter la commande npm run all-build-prod pour compiler, en mode production, toutes les applications, dans le répertoire ./dist exécuter la commande npm run http-start pour démarrer un serveur web simpliste exposant toutes les applications consulter le chapitre §3.1 liens pour accéder aux applications 3.2.2 - Ordre de démarrage des composants du socle Voici l\u0026rsquo;ordre de démarrage des micro-services et services du socle avec la raison précise de cet ordre :\nS_REGISTRY : le service \u0026ldquo;registre\u0026rdquo; est le service auprès duquel la plus part des composants s\u0026rsquo;enregistrent (micro-services + S_CONFIG + S_GATEWAY ). Il doit donc être le premier. S_CONFIG : le service \u0026ldquo;config\u0026rdquo; expose toutes les configurations nécessaires aux micro-services. S_REDIS : le service \u0026ldquo;redis\u0026rdquo; fournit au service \u0026ldquo;gateway\u0026rdquo; le stokage des jetons de requêtes. S_GATEWAY : le service \u0026ldquo;gateway\u0026rdquo; est le point d\u0026rsquo;entrée de toute requête vers un micro-service. S_ADMIN : le service \u0026ldquo;admin\u0026rdquo; permet la surveillance de tous les micro-services et ces derniers s\u0026rsquo;enregistrent auprès de lui. les micro-services ne nécessitant pas MongoDB : REFERENTIEL, REFERENTIEL_EXTERNE, SECURITE, SOUMISSION et TRANSFERT. S_MONGODB : le service \u0026ldquo;mongoDB\u0026rdquo; fournit une base de données à quelques micro-services. les micro-services nécessitant MongoDB : BROUILLON, CONFIGURATION et DOCUMENT. "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.11infoslogs/",
	"title": "3.11 Infos-logs",
	"tags": [],
	"description": "",
	"content": "\r3.11.1 - Types de log 3.11.2 - Format des logs 3.11.2.1 - Format des logs applicatives 3.11.2.2 - Format des access logs 3.11.3 - Configuration par environnement 3.11.3.1 - Logs en local 3.11.3.2 - Logs hors local 3.11.1 - Types de log Actuellement, deux types de log existent :\nLes logs applicatives générées par les frameworks, les librairies et le code applicatif permettant de suivre l\u0026rsquo;activité des applications. Les access log généré par le serveur WEB et contenant exclusivement les traces des requêtes HTTP. 3.11.2 - Format des logs 3.11.2.1 - Format des logs applicatives La configuration du format des logs applicatives se paramètre dans un fichier de configuration SpringBoot avec la clef logging.pattern.console.\nLa configuration actuelle est très proche de la configuration par défaut de SpringBoot mais adaptée pour être similaire au format des access log : [%d{dd/MMM/yyyy:HH:mm:ss Z}] ${PID:-} [%X{traceId:-},%X{parentSpanId:-},%X{spanId:-}] %-5level %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:%wEx} avec\n[%d{dd/MMM/yyyy:HH:mm:ss Z}] : la date et l\u0026rsquo;heure formatées ${PID:-} : l\u0026rsquo;identifiant du processus [%X{traceId:-},%X{parentSpanId:-},%X{spanId:-}] : les éléments de trace Sleuth (cf. §3.12) %-5level : le niveau de log %-40.40logger{39} : la classe générant la log %m%n : le message + le retour à la ligne ${LOG_EXCEPTION_CONVERSION_WORD:%wEx} : la gestion d\u0026rsquo;exception Ceci donne des logs du type :\n[14/janv./2022:20:36:50 +0100] 15400 [,,] DEBUG f.g.d.p.s.s.a.SocleSoumissionApplication : Running with Spring Boot v2.6.1, Spring v5.3.13 3.11.2.2 - Format des access logs La configuration des access logs dépend du serveur WEB utilisé. Dans le cas des micro-services, il s\u0026rsquo;agit de Tomcat donc la configuration est server.tomcat.accesslog.pattern avec la valeur %t %a [%{X-B3-TraceId}i,%{X-B3-parentspanid}i,%{X-B3-SpanId}i] %r %s (%B b - %D ms) avec\n%t : la date et l\u0026rsquo;heure formatées %a: l\u0026rsquo;IP de l\u0026rsquo;appelant [%{X-B3-TraceId}i,%{X-B3-parentspanid}i,%{X-B3-SpanId}i] : les valeurs des entête Sleuth (cf. §2.6.2.3) %r : la première ligne de la requête comprenant la méthode HTTP, l\u0026rsquo;URI et le protocole %s : le code HTTP de la réponse %B b: le poids de la réponse %D ms : le temps de traitement de la requête Ceci donne des logs du type :\n[14/Jan/2022:20:51:53 +0100] 127.0.0.1 4zc-fbrt4-syevbq-24222443474ed475-df4ee67a6ee65a9d GET /socle/document/teledossier/eta-GQ11-3P0D-KIC0/document HTTP/1.1 200 (1724 b - 203 ms) 3.11.3 - Configuration par environnement 3.11.3.1 - Logs en local La configuration des logs en local se trouve dans les fichiers application-accesslog.properties et application-log.properties du répertoire 2-code/socle/socle-commun/src/main/resources/.\nCette configuration des access logs génère un fichier. Mais celle des logs applicatives envoie les lignes de logs vers la sortie standard. Ainsi, dans Eclipse, les logs arrivent dans la console. Et, en démarrant les micro-services depuis un script SH, les logs arrivent dans un fichier log_xxx.log.\n3.11.3.2 - Logs hors local La configuration locale des logs ne doit pas être reprise dans les autres environnements !\n"
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.12infosspring/",
	"title": "3.12 Infos-Spring",
	"tags": [],
	"description": "",
	"content": "\r3.12.1 - Liste des principales dépendances Spring et leurs usages 3.12.2 - Liste des annotations Spring (et autres) utilisées dans les projets Back Les fonctionnalités CLOUD et plus largement de Spring sont utilisées dans les projets BACK.\n3.12.1 - Liste des principales dépendances Spring et leurs usages Ces dépendances Spring sont utilisés sont dans les services de gestion/administration\nspring-boot-admin-starter-server est utilisé dans service-admin pour fournir une interface d\u0026rsquo;administration de l\u0026rsquo;ensemble du SI. A travers ces écrans, les instances de micro-services sont visibles, leurs métriques sont consultables et il est possible de modifier certains paramètres (comme les niveaux de log). spring-cloud-starter-gateway est utilisé dans le projet services-cloud\\service-gateway pour créer un point d\u0026rsquo;entrée unique à tous les micro-services. Ce portail (traduction possible de \u0026lsquo;gateway\u0026rsquo;) contient, dans sa configuration, une route pour chaque micro-service. Cette configuration fait référence au nom du micro-service (spring.application.name) et utilise un répartiteur de charge simpliste ainsi que l\u0026rsquo;annuaire. C\u0026rsquo;est le seul et unique point d\u0026rsquo;entrée du SI. Aucun micro-service ne doit être appelé depuis l\u0026rsquo;extérieur du SI sans passer par la Gateway. spring-cloud-starter-netflix-eureka-server est utilisé dans le projet services-cloud\\service-registry pour créer un annuraire des micro-services. Chaque applicatif, à son démarrage, s\u0026rsquo;enregistre auprès de l\u0026rsquo;annuaire en fournissant son nom (spring.application.name configuré dans le fichier application-specifique.properties), son IP et son port. Ainsi l\u0026rsquo;annuaire connait tous les micro-services démarrés et fournit, à tous les micro-services et à la gateway, une URL à appeler pour un nom d\u0026rsquo;application donné. Ces dépendances Spring sont utilisés dans tous les projets applicatifs de micro-service\nspring-boot-starter-web permet la création des APIs avec l’annotation @Controller spring-cloud-starter-sleuth est une librairie permettant d\u0026rsquo;ajouter, dans chaque ligne de log, un identifiant unique et de faire passer cet identifiant d\u0026rsquo;un micro-service à un autre. spring-cloud-starter-openfeign est une librairie permettant de créer, dynamiquement, un client REST pour les APIs simples (hors upload de document par exemple). C\u0026rsquo;est une alternative aux clients développés manuellement. (le code actuel comprend un client manuel ET un client OpenFeign) spring-cloud-starter-netflix-eureka-client est la dépendance par laquelle tout micro-service et la gateway appelle l\u0026rsquo;annuraire Eureka pour s\u0026rsquo;enregistrer ou obtenir l\u0026rsquo;URL d\u0026rsquo;un autre service (cf. spring-cloud-starter-netflix-eureka-server). Ces dépendances Spring permettent la réalisation de test\nspring-data-mongodb fournit un client MongoDB spring-boot-starter-test fournit les classes de Spring pour s\u0026rsquo;intégrer aux frameworks de test (démarrage/redémarrage/arrêt de contexte Spring). /!\\ Cette dépendance est en scope TEST et n\u0026rsquo;est donc pas transitive. Il est donc normal de la retrouver dans à peu près tous les projets. 3.12.2 - Liste des annotations Spring (et autres) utilisées dans les projets Back Ce chapitre ne liste pas les annotations documentaires comme celles de la Javadoc.\nLes règles de nommage associées aux composants décrits ci-dessous sont au chapitre 3.4.2\nLes annotations de base de Spring (IOC\u0026amp;DI alias inversion de contrôle et injection de dépendance)\n@Component et @Service permettent de déclarer, à Spring, que cette classe est un composant que Spring doit considérer comme un composant applicatif à instancier une (et une seule) fois, à y injecter d\u0026rsquo;autres composant et à injecter dans d\u0026rsquo;autres composant. Le @Component est à utiliser pour les composants qui ne sont pas des DAO, des services métiers ou des contrôleurs REST. @Service est à injecter dans tous les services métiers (dont le nom est suffixé par Service). @Autowired est l\u0026rsquo;annotation demandant à Spring d\u0026rsquo;injecter automatiquement un composant applicatif dans un autre (un DAO dans un service ou un service dans un contrôleur REST ou un service dans un test, \u0026hellip;) @PostConstruct est une annotation particulière permettant de faire s\u0026rsquo;exécuter une méthode d\u0026rsquo;un composant applicatif Spring juste après que le dit composant ait été instancié et que les dépendances aient été injectées. Les annotation de configuration de Spring :\n@Configuration est une annotation à placer sur toute classe définissant des éléments de configuration pour Spring (par annotation comme @PropertySource, par méthode avec @Bean). Ces classes-là doivent être suffixées par Config. @Value(\u0026quot;${la.clef:ValEurParDEFAUT}\u0026quot;) est une annotation à placer sur un attribut d\u0026rsquo;un composant Spring. Elle permet d\u0026rsquo;injecter automatiquement une valeur configurée dans un fichier PROPERTIES. @PropertySource(\u0026ldquo;classpath:unfichier.properties\u0026rdquo;) est une annotation à placer sur une classe de configuration ou d\u0026rsquo;application listant/ajoutant un fichier de configuration à charger. @Bean est une annotation placée sur une méthode de classe de configuration. Cette méthode retourne un (ou une liste de) composant(s) applicatif(s). Les annotations de base des contrôleur REST de Spring :\n@DeleteMapping, @GetMapping, @PostMapping et @PutMapping sont des annotations déclarant une méthode publique d\u0026rsquo;une classe suffixée par API que Spring devra exposer sous forme d\u0026rsquo;une API REST. @PathVariable, @RequestParam, @RequestPart, @ResponseBody et @RequestBody sont des annotations décrivant une méthode exposée sous forme d\u0026rsquo;API REST : exemples Baeldung et documentation officielle. @RestController est une annotation placée sur un contrôleur REST (cf. §3.21.2 pour les règles de nommage). @SecurityRequirements({ @SecurityRequirement(name = \u0026ldquo;bearer-jwt\u0026rdquo;) }) : Cette chaîne de caractères est utilisée pour la documentation des APIs et notamment déclarer leur mode de protection. Les annotations spécifiques à un besoin :\n@FeignClient est une annotation à placer sur une interface décrivant une API REST. Cette annotation permet que Spring, sur demande, crée un client appelant cette API. @ControllerAdvice est une annotation pour les classes traitant les exceptions et les transformant en une réponse d\u0026rsquo;API REST. @LocalServerPort permet, depuis une classe de test par exemple, de récupérer le port sur lequel répondent les APIs REST du contexte Spring démarré (les tests s\u0026rsquo;exécutent toujours avec un port dynamique). @Scheduled permet de déclencher à intervalle de temps régulier une méthode : Les annotations spécifiques à SpringBoot ou à une librairie de SpringBoot\n@SpringBootApplication est l\u0026rsquo;annotation de base de SpringBoot permettant de déclarer une classe de démarrage. @EnableAutoConfiguration est une annotation permettant d\u0026rsquo;activer/désactiver des modules SpringBoot qui démarre normalement automatiquement du moment que le JAR est présent dans le classpath (dans notre cas, elle est utilisée pour désactiver le démarrage automatique de MongoDB). @EnableFeignClients se place dans une classe d\u0026rsquo;application ou de configuration et permet de déclarer un ou plusieurs clients Feign (classes annotées avec @FeignClient). @EnableWebSecurity et @EnableGlobalMethodSecurity s\u0026rsquo;associent pour créer une classe configurant la sécurité des APIs REST exposées. @EnableScheduling permet d\u0026rsquo;autoriser l\u0026rsquo;usage de l\u0026rsquo;annotation @Scheduled. @EnableAdminServer et @EnableEurekaServer permettent respectivement d\u0026rsquo;activer une application d\u0026rsquo;administration et un annuaire Eureka (cf. §3.12.2). Les annotations de Jackson (framework réalisant la transformation JSON\u0026lt;-\u0026gt;Java).\n@JsonAnySetter permet de déclarer une méthode à utiliser si aucun setter ne correspond dans la classe (utilisé quand une partie des attributs sont dynamiques et stockés dans une Map par exemple). @JsonCreator peut annoter un constructeur et sera utilisée pour désérialiser un JSON (transformer le texte JSON en classe Java). Ceci est utile pour les classes immutables ou quand quelques lignes de logique sont nécessaires. @JsonIgnore permet de demander à Jackson de ne pas prendre en compte une méthode pour créer le JSON à partir d\u0026rsquo;une classe. @JsonIgnoreProperties(ignoreUnknown = true), placée sur une classe, permet que Jackson ne lance pas d\u0026rsquo;erreur si un message JSON contient des attributs n\u0026rsquo;existant pas dans la classe Java. @JsonProperty(\u0026ldquo;clef\u0026rdquo;) permet de personnaliser le nom d\u0026rsquo;un attribut JSON (par défaut, l\u0026rsquo;attribut JSON porte le nom de l\u0026rsquo;attribut Java). Les annotations de JUnit\n@SpringBootTest est une annotation de Spring permettant de configurer un test démarrant un contexte Spring. @Test est une annotation JUnit à placer sur chaque méthode de test JUnit. Cette méthode doit être public, ne pas prendre d\u0026rsquo;argument et renvoyer void. @AfterAll, @BeforeAll et @BeforeEach sont des annotations de JUnit permettant de faire s\u0026rsquo;exécuter une méthode avant/après chaque/tous test(s). @ExtendWith(MockitoExtension.class) permet de dire à Spring que le test doit utiliser Mockito et traiter les annotations @InjectMocks et @Mock. @TestInstance(Lifecycle.PER_CLASS) est une annotation JUnit permettant de lui préciser un cycle de vie particulier de la classe de test. En effet, par défaut, une nouvelle instance de la classe de test est créée pour chaque appel à une méthode de test. Mais, comme créer et injecter des bouchons est coûteux en temps, il est préférable de n\u0026rsquo;avoir qu\u0026rsquo;une unique instance de classe de test, de créer et injecter les bouchons une seule fois mais de réinitialiser les bouchons entre chaque test. @Mock permet de générer un bouchon sur un membre de la classe dont le type est une classe (attention, interdit sur les interfaces). @InjectMocks permet de dire à Spring d\u0026rsquo;injecter tous les bouchons générés dans la classe ainsi annotée. @TestMethodOrder(MethodOrderer.MethodName.class) permet de dire à JUnit d\u0026rsquo;exécuter les tests dans un ordre précis (par défaut, l\u0026rsquo;ordre peut varier aléatoirement). @TestPropertySource est une annotation permettant de préciser un ou plusieurs fichiers de configuration supplémentaires à utiliser pour cette classe de test particulière. "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.13infoscloud/",
	"title": "3.13 Infos-cloud",
	"tags": [],
	"description": "",
	"content": "\r3.13.1 - spring-boot-admin et service-admin 3.13.2 - spring-cloud-starter-gateway et service-gateway 3.13.3 - spring-cloud-config-server et service-config 3.13.4 - spring-cloud-starter-netflix-eureka-server et service-registry 3.13.5 - service-nosql 3.13.1 - spring-boot-admin et service-admin L\u0026rsquo;ensemble des applicatifs du socle sont prévus pour fonctionner dans le cloud et être scalables horizontalement (possibilité de démarrer plusieurs instances d\u0026rsquo;un même service et répartir la charge sur l\u0026rsquo;ensemble). Pour permettre le monitoring des instances démarrées,\nexiste l\u0026rsquo;application service-admin basée sur le projet SpringBootAdmin (https://codecentric.github.io/spring-boot-admin/current/) tout applicatif du socle se recense auprès de l\u0026rsquo;application service-admin et expose, de manière sécurisée, ses APIs de monitoring et gestion (cf. Spring Actuator) Les services du socle ne se déclare pas dans service-admin car ils peuvent, potentiellement, être remplacés par des services d\u0026rsquo;un fournisseur de cloud. 3.13.2 - spring-cloud-starter-gateway et service-gateway L\u0026rsquo;ensemble des APIs des micro-services du socle peuvent être exposés à l\u0026rsquo;extérieur du SI via la Gateway. Ce service a pour objectif de fournir un point d\u0026rsquo;entrée unique à tous les appels venant de l\u0026rsquo;extérieur.\nCe service fournit en plus :\nune limitation du nombre de requêtes par secondes (cf. documentation) une limitation de la taille maximale d\u0026rsquo;une requête (cf. documentation) 3.13.3 - spring-cloud-config-server et service-config Cet applicatif contient et expose aux micro-services toutes les configurations. Ainsi, la configuration est centralisée pour n\u0026rsquo;être exposée que de manière sécurisée. Le framework spring-cloud-config-server fournit différents connecteurs pour aller chercher la configuration.\nEn local, sur le poste du développeur, la configuration est dans le système de fichier (répertoire src/main/resources du projet socle-communtest). Ainsi\nles fichiers de configuration sont tous disponibles dans le classpath des tests automatisés ; les fichiers de configuration ne sont pas présent dans les JAR des micro-services (car la dépendance à socle-communtest est en test ; les fichiers de configuration sont accessibles à travers le système de fichier quand le service-config tente d\u0026rsquo;y accéder. 3.13.4 - spring-cloud-starter-netflix-eureka-server et service-registry Le service de registre est assimilable un annuaire. Tous les micro-services du socle et tous les services (sauf MongoDB) s\u0026rsquo;enregistre et interroge le registre. Ainsi, quelque soit le nombre et la localisation des instances, tous savent appeler les autres.\nLe message affiché sur le portail WEB du registre THE SELF PRESERVATION MODE IS TURNED OFF. THIS MAY NOT PROTECT INSTANCE EXPIRY IN CASE OF NETWORK/OTHER PROBLEMS. vient de la clef eureka.server.enable-self-preservation à false pour réduire le délai de déréférencement d\u0026rsquo;une instance arrêtée violemment (ce qui est toujours le cas sous Windows)\n3.13.5 - service-nosql Ce service ne se base pas sur une technologie de Spring Cloud mais uniquement sur du code et la librairie de.flapdoodle.embed.mongo.\n/!\\ la base MongoDB ne stocke, par défaut, que des documents jusqu\u0026rsquo;à 16Mo : https://docs.mongodb.com/manual/core/document/#document-size-limit. Si besoin de plus : https://docs.mongodb.com/manual/core/gridfs/\n"
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.14infospic/",
	"title": "3.14 Infos-PIC",
	"tags": [],
	"description": "",
	"content": "\rUne Plateforme d\u0026rsquo;Intégration Continue (PIC) est un ensemble d\u0026rsquo;outils dont l\u0026rsquo;objectif premier est de tester, en continue (d\u0026rsquo;où son nom) toutes les versions de code créées par les développeurs. Pour cela, un orchestrateur (comme Jenkins) surveille un référentiel de source (comme Gitlab) pour déclencher le build (cf. §3.33) et envoyer, si besoin, un mail prévenant que quelque chose ne va pas. En plus de cet objectif de base, la PIC peut permettre :\nd\u0026rsquo;analyse le code de publier les résultats de l\u0026rsquo;analyse de code dans un portail dédié (comme SonarQube) de publier les résultats des tests automatisés de publier les livrables dans un repository de binaires (comme Nexus ou Archiva) d\u0026rsquo;installer des composants applicatifs sur un environnement de test voire de production \u0026hellip; TODO: à compléter quand le projet disposera d\u0026rsquo;une PIC :\ndescription du référentiel de source accès WEB et clone rôles et droits de chacun pratiques du projet branches : nommage, branche par défaut et flow du projet MR : nommage, squach et destruction de la branche fusionnée liens avec d\u0026rsquo;autres outils (comme le gestionnaire de demandes) description du repository des binaires accès WEB rôles et droits de chacun liste des dépôts publiques \u0026ldquo;proxifiés\u0026rdquo; liste des dépôts privés description de l\u0026rsquo;orchestrateur accès WEB rôles et droits de chacun jobs existants, fonctionnement et usages portail de qualimétrie accès WEB rôles et droits de chacun explicitation des écarts (s\u0026rsquo;il en existe) entre le paramétrage de la qualimétrie et les règles du projet "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.15infose2e/",
	"title": "3.15 Infos-test e2e",
	"tags": [],
	"description": "",
	"content": "\r3.15.1 - Introduction 3.15.2 - Démarrage 3.15.3 - FailFast 3.15.4 - Couverture de code 3.15.5 - Dépannage 3.15.1 - Introduction Protractor n\u0026rsquo;est plus utilisé par Angular. Aucun test ni configuration de test d\u0026rsquo;écrans (E2E) n\u0026rsquo;existe plus à la création d\u0026rsquo;un projet Angular. CYPRESS est le framework nouvellement conseillé. Il fournit notamment une migration automatique depuis Protractor. Mais son premier usage est parfois pénible. Donc le fichier package.json contient des commandes install-1*cypress\nLes tests E2E permettent de valider le bon fonctionnement de l\u0026rsquo;application mais n\u0026rsquo;en sont pas les garants (malheureusement).\n3.15.2 - Démarrage Selon votre poste et la configuration du proxy présente dans les variables d\u0026rsquo;environnement, il peut être nécessire de préciser à Cypress le proxy à utiliser pour accéder à l\u0026rsquo;application :\nexport HTTP_PROXY= export HTTPS_PROXY= L\u0026rsquo;outil Cypress utilisé pour les tests E2E se démarre avec la commande npm run cypress\n3.15.3 - FailFast Quand une étape d\u0026rsquo;un test E2E échoue, la plus part du temps, le reste du test échoue ensuite car un bouton ou un champs n\u0026rsquo;a pas été trouvé/saisi/cliqué/\u0026hellip; Pour éviter de perdre du temps à exécuter des étapes perdues d\u0026rsquo;avance, est mis en place le framework cypress-fail-fast. Ce dernier arrête toute action de Cypress dès la première erreur.\n3.15.4 - Couverture de code _La couverture de code ne fonctionne plus depuis le passage en Angular-17 et le passage de webpack à ESbuild/Vite (cf. https://v17.angular.io/guide/esbuild) _\nUne grande partie de l\u0026rsquo;effort de développement de la nouvelle PSL est centrée sur la librairie Angular Framework. Les tests E2E permettent d\u0026rsquo;en tester les fonctionnalités. Mais, sans couverture de code, il n\u0026rsquo;est pas possible d\u0026rsquo;identifier les lignes de code, les classes et les fonctionnalités non couvertes par les tests. Cela est maintenant possible en :\ndémarrant la démarche en activant la couverture de code : npm run codeDemarche-startcoverage (ou yarn à la place de npm) démarrant les tests E2E (la couverture de code code est paramétrée par défaut mais ne pénalise pas l\u0026rsquo;exécution) : npm run cypress (ou yarn à la place de npm) à la fin du test, le rapport de couverture de code est disponible dans 2-code/front/coverage/lcov-report/index.html Si la démarche est démarrée avec le codeDemarche-start, le code n\u0026rsquo;est pas instrumenté. Donc la couverture de code sera à 0%.\n3.15.5 - Dépannage Il est courant que les tests E2E ne démarrent pas car le package.json, à la commande e2e, définit que le webdriver ne doit pas être mis à jour à chaque exécution (gain de temps non négligeable). Si le message d\u0026rsquo;erreur indique que la version de Chrome n\u0026rsquo;est pas compatible avec celle du webdriver, il suffit de passer la valeur du paramètre webdriverUpdate à true puis de relancer la commande e2e (attention à bien remettre la valeur à false avant le prochain commit).\nIl est courant que les tests E2E échouent :\nsi tous les bouchons ne sont pas activés dans le fichier environment.ts si les données du brouillon présentes dans assets/bouchonapi ne sont pas complètes ou ne permettent pas d\u0026rsquo;aller au bout de la démarche ou ne correspondent pas aux données présentes dans les bouchons si l\u0026rsquo;application met trop de temps à charger sur le poste (performance du poste, \u0026hellip;) si le calcul du nombre d\u0026rsquo;options des listes déroulantes échouent "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.16infovelocity/",
	"title": "3.16 Infos-velocity",
	"tags": [],
	"description": "",
	"content": "\r3.15.1 - Introduction 3.15.2 - Syntaxes à connaître 3.15.1 - Introduction Velocity est un framework de templating de texte. Il permet, à partir d\u0026rsquo;un template et de données, de générer un texte.\nPour rappel, un document JSON, XML ou même HTML est, à la base, un document texte. Et la nouvelle PSL permet de générer un PDF à partir d\u0026rsquo;une page HTML.\n3.15.2 - Syntaxes à connaître La documentation officielle est là.\nParmi les choses remarquables, sont à noter :\n## les commentaires qui commencent par 2 dièses /!\\ ils génèrent souvent des problèmes d\u0026#39;interprétation ## l\u0026#39;affectation de variable #set( $nombre = \u0026#34;2\u0026#34; ) ## les IF en multiligne /!\\ ça génère des sauts de lignes dans le document final #if( $var = \u0026#34;toto\u0026#34; ) la variable est bien toto #else la variable n\u0026#39;est pas toto #end ## le même IF en monoligne #if( $var = \u0026#34;toto\u0026#34; )la variable est bien toto#{else}la variable n\u0026#39;est pas toto#end ## les macros alias les fonctions réutilisables comme celle-ci qui permet de formatter un nombre sur deux chiffres #macro( formaterNombre $i )#if( $i\u0026lt;10 )0#{end}$i#end #set( $nombreFormatte = \u0026#34;#formaterNombre( $nombre )\u0026#34; ) "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.21reglesdeconception/",
	"title": "3.21 Règles-conception",
	"tags": [],
	"description": "",
	"content": "\r3.21.1 - Conception 3.21.1.1 - Les projets et leur catégorisation 3.21.1.2 - Configuration 3.21.1.3 - Les clients d\u0026rsquo;API 3.21.2 - Règles de nommage 3.21.1 - Conception 3.21.1.1 - Les projets et leur catégorisation Le projet socle se compose de multiples projets (notion de micro-service) mais ces projets se divisent en plusieurs catégories\nles projets fonctionnels apportant des fonctionnalités et exposant des APIs sécurisées comme socle-dbdocument traitant du stockage des documents générés et des pièces jointes ; socle-dbconfiguration stockant les configurations internes et publiques des démarches ; socle-dbbrouillon stockant les brouillons de télé-dossier ; socle-referentiel exposant des APIs permettant l\u0026rsquo;autocomplétion à partir de données indéxées et obtenues depuis des référentiels externes ; socle-referentielexterne exposant des APIs permettant l\u0026rsquo;autocomplétion à partir de directement obtenues (à chaque requête entrante) depuis des référentiels externes ; socle-soumission exposant l\u0026rsquo;API de création d\u0026rsquo;un tx²élé-dossier (validation, génération de documents\u0026hellip;) ; socle-securite exposant les APIs de gestion de l\u0026rsquo;authentification des usagers. les services standards permettant le bon fonctionnement, l\u0026rsquo;accès, l\u0026rsquo;administration ou le suivi des micro-services fonctionnels comme service-nosql proposant une base de données MongoDB utilisable sur un environnement de développement ; service-registry démarrant un annuaire des micro-services ; service-gateway démarrant un portail exposant les APIs des micro-services à l\u0026rsquo;extérieur du SI ; service-admin permettant de suivre et configurer les micro-services démarrés. les projets techniques portant des fonctionnalités communes à tous les autres : socle-commun fournit les éléments de base de la sécurité des APIs REST ; la gestion des tokens JWT ; la transformation des exceptions en message JSON ; la base des clients REST ; les éléments de configuration des applications SpringBoot (documentation, REST, sécurité, \u0026hellip;) ; les fichiers de configuration commun à tous les micro-service ; des classes utilitaires ; socle-communtest fournit la classe de base pour tous les tests automatisés avec le chargement des fichiers de configurations communs à tous ainsi qu\u0026rsquo;une classe utilitaire pour traiter les tokens JWT. socle-commundb fournit une classe abstraite permettant de démarrer un processus MongoDB ; une classe abstraite d\u0026rsquo;interrogation d\u0026rsquo;une base MongoDB ; une classe de base pour les exceptions dans les appels à MongoDB ; une classe utilitaire pour initialiser MongoDB avec un jeu de données basé sur les fichiers de bouchon des projets FRONT Angular. 3.21.1.2 - Configuration Les paramètres de chaque micro-service sont présents dans des fichier .properties. Ce choix a été fait car les fichiers YML ont un format est plus subtile, basé sur les indentations. Ceci en fait des fichiers plus sujet aux erreurs. La règle veut que chaque fichier de configuration ait un objectif et un seul. Pour conserver un équilibre cohérence/cohésion, chaque fichier de configuration est lié à une fonctionnalité majeure (les logs par exemple) ou à une librairie (le lien avec l\u0026rsquo;annuaire/registry).\nConcernant la configuration Maven :\ntoutes les versions de dépendances sont paramétrées dans le pom.xml du SOCLE PARENT et exclusivement là-bas beaucoup de dépendances sont paramétrées directement dans les projets socle-commun*. Ceci permet que les mécaniques de tous les micro-services soient homogènes. toute dépendance d\u0026rsquo;un projet à un autre doit utiliser la version ${project.version} /!\\ Certains micro-services dépendent d\u0026rsquo;un autre (socle-soumission dépendant de socle-dbdocument par exemple). Normalement, la soumission doit se faire avec le client. Mais Eclipse gère mal la notion de classifier. La dépendance est donc doublée avec un scope test pour permettre au code de fonctionner correctement dans Eclipse. 3.21.1.3 - Les clients d\u0026rsquo;API TODO Chaque projet fonctionnel expose des APIs. Pour chacune d\u0026rsquo;entre elles, doit exister une méthode dans une classe Client les DTO en fonction des besoins de appelant pas de DTO JAVA exhaustif\n3.21.2 - Règles de nommage Les annotations à utiliser sont décrites dans le chapitre 3.0.2\nles services métiers sont les composants applicatifs contenant de l\u0026rsquo;intelligence (algorithmie) à suffixer par Service pour l\u0026rsquo;interface et ServiceImpl pour l\u0026rsquo;implémentation dans un package service sans aucun constructeur (c\u0026rsquo;est un composant Spring utilisant @Autowired sur ses membres pour l\u0026rsquo;injection de dépendances) les API sont des interfaces contenant toute la déclaration d\u0026rsquo;une API (méthodes publiques avec les annotations @XxxMapping) à suffixer par API dans un pachage apiclient.api les contrôleurs REST sont les composants applicatifs exposant les services via une API REST à suffixer par Controlleur dans un package controlleur sans aucun constructeur (c\u0026rsquo;est un composant Spring utilisant @Autowired sur ses membres pour l\u0026rsquo;injection de dépendances) implémentant une API (sauf cas particulier comme l\u0026rsquo;upload de document) les objets de transport (DTO) sont les classes contenant des données mais qui ne sont pas des Objets Métiers (aucune intelligence) ni des Rntités (des objets sauvegardés en base) à suffixer par Dto dans un package dto avec un constructeur sans paramètre systématiquement les énumérations ne sont pas des DTO mais décrivent eux aussi des données. Donc elles sont au plus proche des DTO (dans le même package) à suffixer par Enum dans un package dto les applications sont les classes permettant de démarrer une application SpringBoot à suffixer par Application dans un package application avec un constructeur mais avec une méthode main les configuration SpringBoot sont des composants applicatifs permettant d\u0026rsquo;activer, désactiver, paramétrer des comportements/fonctionnalités de SpringBoot à suffixer par Config dans le package application (si un seul) ou dans le package config avec un constructeur mais avec une méthode main les clients d\u0026rsquo;API (pour les APIs du socle ou les APIs externes) sont des composants applicatifs à suffixer par Client dans le package client avec un constructeur mais avec une méthode main les classes utilitaires ne sont pas des composants applicatif. Donc aucune injection n\u0026rsquo;est possible. Ces classes exposent des méthodes statiques uniquement. à suffixer par Utils dans le package au plus proche s\u0026rsquo;il n\u0026rsquo;en existe qu\u0026rsquo;une seule dans le projet sinon dans un package utils dans le package au plus proche s\u0026rsquo;il n\u0026rsquo;en existe qu\u0026rsquo;une seule dans le projet sinon dans un package utils avec un constructeur privé uniquement n\u0026rsquo;exposant que des méthodes statiques les tests automatisés à suffixer par Test dans le répertoire src/test/java des projets exclusivement (sauf pour les classes de base des tests présentes dans le projet socle-communtest pour plus de détails, se référer au chapitre dédié les composants de génération de données de test suive le pattern ObjectMother décrit par Martin Fowler à suffixer par ObjectMother dans le répertoire src/test/java au plus près des tests automatisés tout autre type de composant doit être soigneusement décrit "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.22reglesspecificiquesjava/",
	"title": "3.22 Règles-Java",
	"tags": [],
	"description": "",
	"content": "\r3.22.1 - Java 17 3.22.2 - Spécificités associées aux record de Java 3.22.3 - Les imports 3.22.4 - Validation de données en entrée des APIs exposées par le socle 3.22.5 - L\u0026rsquo;injection de dépendance de Spring 3.22.1 - Java 17 La partie Socle de cette solution est initialement développée avec Java 17. Elle utilise donc certaines fonctionnalités intéressantes (et pour certaines relativement récentes) de Java :\nles record sont une nouvelle façon de déclarer une classe en Java. Plus succincte, elle est pratique à utiliser pour déclarer des classes sans aucune méthode spécifique (uniquement des constructeurs, des getter et des setter). En voici la documentation. les text bloc (documentation) sont autorisés (si on y trouve une utilité dans notre code). le pattern matching est une fonctionnalité visiblement utile et intéressante à utiliser documentation Par contre, certaines nouveautés ne me semble pas pertinente voire génantes. Donc ne sont pas autorisées sur le projet les fonctionnalités suivantes :\nles var documentation les switch n\u0026rsquo;ont jamais été le bien venu et leur nouvelle syntaxe ne les rend pas beaucoup plus attrayants documentation 3.22.2 - Spécificités associées aux record de Java Les record de Java ont l\u0026rsquo;avantage de ne plus nécessiter de coder les getter et setter.\nMais attention ! Un record est une structure de données dont tous les attributs sont finaux. Donc aucun setter n\u0026rsquo;est disponible !!!\nPour les besoins de notre code, il peut être utile de créer un constructeur spécifique. Ceci est possible à condition d\u0026rsquo;appeler le constructeur natif du record avec une valeur par défaut pour chaque attribut (false, new ArrayList\u0026lt;\u0026gt;(), new HashMap\u0026lt;\u0026gt;() ou null). Exemple :\n/** Constructeur vide */ public PageDto() { this(new ArrayList\u0026lt;\u0026gt;(), null, null, null, false, false); } /** Constructeur par défaut */ public PageDto(List\u0026lt;BlocDto\u0026gt; blocs, String conditionVisibilite) { this(blocs, conditionVisibilite, null, null, false, false); } Pour les besoins de SpringDataMongo, si la classe décrit une structure de données stockée dans MongoDB et qu\u0026rsquo;un constructeur est codé explicitement, il faut créer un constructeur complet pour MongoDB. Ce constructeur doit\nêtre annoté avec @PersistenceConstructor comprendre tous les membres de la classe avec le premier du constructeur natif à la fin (pour ne pas avoir la même signature que le constructeur natif. Exemple : /** * Constructeur contenant tous les attributs mais avec le premier en dernier pour fournit à SpringDataMongo un constructeur à utitiliser (les * setter n\u0026#39;existe pas dans un record). De plus, pour les mêmes raisons mais avec Jackson, il faut ajouter un @JsonCreator sur le constructeur et * un @JsonProperty sur chaque paramètre. */ @PersistenceConstructor @JsonCreator public PageDto(@JsonProperty(\u0026#34;conditionVisibilite\u0026#34;) String conditionVisibilite, @JsonProperty(\u0026#34;titre\u0026#34;) String titre, @JsonProperty(\u0026#34;titreAriane\u0026#34;) String titreAriane, @JsonProperty(\u0026#34;exclueDuFilDariane\u0026#34;) Boolean exclueDuFilDariane, @JsonProperty(\u0026#34;specifiqueAlaDemarche\u0026#34;) Boolean specifiqueAlaDemarche, @JsonProperty(\u0026#34;blocs\u0026#34;) List\u0026lt;BlocDto\u0026gt; blocs) { this(blocs, conditionVisibilite, titre, titreAriane, exclueDuFilDariane, specifiqueAlaDemarche); } 3.22.3 - Les imports Seule la classe StringUtils de Spring peut être utilisée (org.springframework.util). La méthode la plus utilisée est hasLength.\n3.22.4 - Validation de données en entrée des APIs exposées par le socle Toute donnée doit être validée en entrée de toute API exposée par le socle.\nLa validation doit être la plus précise possible. Plusieurs REGEXs sont disponibles dans la classe RegexUtils du projet socle-commun. Si de nouvelles REGEXs doivent être créées pour correspondre au plus près au format d\u0026rsquo;une donnée, elles doivent être créées.\nPour valider un paramètre unique dans une méthode publiques d\u0026rsquo;un contrôlleur REST, il faut utiliser l\u0026rsquo;annotation @Pattern:\nResponseEntity\u0026lt;byte[]\u0026gt; obtenirContenuDuCaptcha(// @Pattern(regexp = RegexUtils.ALPHABETIQUE_ETENDUE) String get, // @Pattern(regexp = RegexUtils.ALPHANUMERIQUE) String c, // @Pattern(regexp = RegexUtils.NOMBRE) String t); Pour valider un objet passer dans un corps de message, il faut demander la validation de l\u0026rsquo;objet avec l\u0026rsquo;annotation @Valid et utiliser l\u0026rsquo;annnotation @Pattern pour valider chacun des membres de cette classe :\nString soumettreUnTeledossier(@Valid @RequestBody DonneesDeSoumissionDto dto); public class DonneesDeSoumissionDto { @Pattern(regexp = RegexUtils.CODE_DEMARCHE) private String codeDemarche; private Map\u0026lt;@Pattern(regexp = RegexUtils.DONNEE_SOUMISE_CLEF) String, @Pattern(regexp = RegexUtils.DONNEE_SOUMISE_VALEUR) String\u0026gt; donnees = new HashMap\u0026lt;\u0026gt;(); @Pattern(regexp = RegexUtils.ID) private String idBrouillon; ... } Pour information, dans les écrans WEB de SwaggerUI, les contraintes sur les membres de classes soumises (en bas de page, dans la partie schéma) sont bien décrits avec leurs validations. Mais, pour les paramètres d\u0026rsquo;appels de type simple (chaîne de caractères, nombres, \u0026hellip;), les contraintes ne s\u0026rsquo;affichent pas dans la page. Néanmoins, si une donnée invalide est saisie, SwaggerUI n\u0026rsquo;exécute pas la requête car il sait que la donnée est invalide mais il affiche un message. Toutes les validations de données sont présentes dans le swagger (document JSON descriptif technique).\n3.22.5 - L\u0026rsquo;injection de dépendance de Spring L\u0026rsquo;annotation @Autowired permet d\u0026rsquo;injecter un composant dans un autre.\nDepuis des années, l\u0026rsquo;habitude / le standard est d\u0026rsquo;utiliser l\u0026rsquo;annotation @Autowired sur chaque membre d\u0026rsquo;un composant qui est un composant à injecter (tout comme pour les valeurs de configuration avec @Value).\nMais, depuis quelques mois/années est poussée une autre façon de faire : l\u0026rsquo;usage du constructeur. Sonar, depuis peu, pousse aussi cette pratique avec la règle RSPEC-4288.\nSur le principe, l\u0026rsquo;idée est bonne :\nsi le composant est instancié via un constructeur initialisant tous les membres, il est donc impossible de créer une instance du composant sans tous les composants dont il a besoin (c\u0026rsquo;est l\u0026rsquo;objectif d\u0026rsquo;un constructeur de classe) si tous les membres sont initialisé par le constructeur, les membres peuvent être finaux. Donc, une fois instancié, le composant ne peut plus être abimé. mais ce point à son équivalent négatif : dans le cas des tests automatisés, il est utile de bidouiller/abimer un composant pour injecter un bouchon ou modifier une configuration (d\u0026rsquo;où l\u0026rsquo;usage de @MockBean de Mockito avec @Autowired versus @Mock couplé à @InjectMock). La documentation de l\u0026rsquo;injection de dépendance de Spring est documentée ici.\nLes consignes sont donc :\n1/ créer un constructeur sans l\u0026rsquo;annotation @Autowired dans tous les composants applicatifs (donc dans src/main/java) avec les composants à injecter avec les configurations @Value 2/ utiliser, dans les tests automatisés, le couple @MockBean pour faire créer les bouchons par Mockito @Autowired pour les composants applicatifs dans lesquels injecter les bouchons "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.23reglesmaven/",
	"title": "3.23 Règles-Maven",
	"tags": [],
	"description": "",
	"content": "\r3.23.1 - Règles de développement liées à Maven L\u0026rsquo;ensemble des projets BACK, FRONT sont construits avec Maven. Maven apporte deux grands services :\nla gestion des dépendances se base sur l\u0026rsquo;identification unique de chaque artefact (alias livrable applicatif ) quelque soit son type (JAR, WAR ou EAR. Cette clef unique se compose du groupid, de l\u0026rsquo;artefactid et de la version. Par convention, le groupid est le package de base de la solution (donc aussi un nom DNS déclarant le propriétaire). L\u0026rsquo;artefactid peut être n\u0026rsquo;importe quoi. Et la version est une chaîne de caractères sur le modèle [0-9]+\\.[0-9]+\\.[0-9]+(-(RELEASE|SNAPSHOT))? (explication release/snapshot). permet à un artefact de déclarer qu\u0026rsquo;il dépend d\u0026rsquo;un ou plusieurs autres artefacts qui eux-mêmes peuvent dépendre d\u0026rsquo;autres artefacts (dépendance transitive), \u0026hellip; la notion de build fournit un squelette par défaut d\u0026rsquo;exécutions de plugins réalisant des tâches basiques et communes à tout projet Java comme détruire le répertoire target (qui contient le résultat de la compilation et des tests) puis compile les sources puis compile les tests puis exécute les tests puis crée l\u0026rsquo;artefact et le copie dans le repository local. est totalement configurable en ajoutant des plugins leur demandant d\u0026rsquo;exécuter une tâche précise (nommée goal) à un moment précis du cycle de vie du build (à un stage). 3.23.1 - Règles de développement liées à Maven Les modification de la configuration Maven ainsi que la création de nouveaux projets/artefact n\u0026rsquo;est pas dans les prérogatives d\u0026rsquo;un développeur. Les règles associées à Maven sont\nToutes les versions des dépendances sont définies dans la balise dependencyManagement du pom.xml racine du socle. Ces versions sont dans une propriété préfixée par version.. Aucune surcharge de version ou exclusion de dépendance transitive ne doit être mise en place sans un gros commentaire explicite. Le build du profile par défaut doit s\u0026rsquo;exécuter le plus rapidement possible mais doit quand même aboutir à la création d\u0026rsquo;un livrable complet et fiable. Cela signifie que les tests automatisés font partie du build ; que la génération de documentation ne fait pas partie du build ; que la qualimétrie ne fait pas partie du build. L\u0026rsquo;exécution du build ne doit pas nécessiter/dépendre d\u0026rsquo;outils autre qu\u0026rsquo;un JDK et de Maven. "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.24reglesdetest/",
	"title": "3.24 Règles-test",
	"tags": [],
	"description": "",
	"content": "\r3.24.1 - Comment faire fonctionner edition-tool en local 3.24.2 - Les tests automatisés dans le Back 3.24.3 - Les requêtes HTTP 3.24.4 - Les tests en cas de modification structurelle du code du socle 3.24.5 - Tests E2E 3.24.6 - Analyse de problème dans les tess E2E 3.24.1 - Comment faire fonctionner edition-tool en local L\u0026rsquo;outil de reverse engineering générant une configuration et un brouillon de démarche à partir d\u0026rsquo;une application déployée est aussi limité que l\u0026rsquo;outil CYPRESS sur lequel il est basé. En effet, CYPRESS ne permet pas de réaliser un test (son objectif premier) dans lequel le navigateur change de domaine. Donc il n\u0026rsquo;est pas possible d\u0026rsquo;analyser une démarche connectée en intégration (car on passe sur le portail SP). Même en local, avec une configuration classique, cela ne fonctionne pas car on alterne entre 127.0.0.1 et localhost. Pour résoudre cela, il faut\nmodifier les données spécifiques avec la requête suivante : update exe_donnees_specifiques set simple_valeur_modifiee = REPLACE(simple_valeur_modifiee, \u0026rsquo;localhost\u0026rsquo;, \u0026lsquo;127.0.0.1\u0026rsquo;); modifier le code du bouchon OIDC pour remplacer les localhost par 127.0.0.1 puis compiler et redéployer le bouchon paramétrer le test CYPRESS pour accéder à la démarche locale avec une URL en 127.0.0.1 3.24.2 - Les tests automatisés dans le Back Quelques règles de base doivent être respectées :\nToute méthode (à minima) de chaque classe doit être couverte par un test automatisé. Les tests automatisés peuvent être de granularité unitaire (cf. Tests de développement). Tout test doit contenir une assertion (une vérification du résultat obtenu). Le plus efficace est d\u0026rsquo;écrire le test selon le modèle Arrange-Act-Assert. 3.24.3 - Les requêtes HTTP Le chapitre IDE UseBruno de l\u0026rsquo;installation de poste local décrit l\u0026rsquo;usage de la collection de requêtes HTTP. Cette capitalisation des requêtes permet de tester le système. Tout comme les tests automatisés le font sur la PIC, ces requêtes permettent de tester n\u0026rsquo;importe quel environnement.\nPour utiliser la collection :\nRAPPEL : mis à part deux APIs (les créations de token anonyme 021 et token SP 024), toutes les APIs du socle nécessitent un tokenPSL pour être appelées. La première chose à faire, avant d\u0026rsquo;exécuter le groupe APIs internes de la collection (ou seulement une sous-partie) est donc de créer un token PSL SP. Pour cela, il faut : A revoir à la fin de la migration vers UseBruno ouvrir la requête 024 accéder à l\u0026rsquo;onglet Authorization cliquer sur le bouton Get New Access Token suivre, dans le mini-navigateur, le processus de connexion SP ou FC (attention à ne pas cliquer plusieurs fois sur un lien/bouton car le mini-navigateur n\u0026rsquo;affiche pas les temps de chargement) cliquer sur le bouton Use Token une fois le token généré A revoir à la fin de la migration vers UseBruno Toutes les requêtes précisent, dans leur nom, le micro-service appelé, la fonctionnalité solicitée, le token utilisé (anonyme ou SP) et le résultat attendu. Certaines requêtes contiennent un (ou plusieurs) test(s) post-exécution. Si la création du token OIDC avec SP n\u0026rsquo;est pas possible, certains tests seront évidemment KO : la requête 024 et tous les tests utilisant un token SP. Les requêtes en dehors du groupe APIs internes ne sont pas à exécuter dans les tests classiques. Elles ne sont mises à disposition que pour capitaliser des besoins précis. 3.24.4 - Les tests en cas de modification structurelle du code du socle Dans le socle, est considérée comme modification structurelle tout changement dans les fichiers pom.xml ou *.properties.\nCes changements nécessitent que l\u0026rsquo;ensemble du socle soit retesté dans toutes ces modalités de démarrage :\nles tests automatisés les démarrages depuis la ligne de commande les démarrages depuis Eclipse La stratégie de test de chaque modalité de démarrage varie :\nles tests automatisés se valident eux-même. Il suffit de les lancer avec Maven. les démarrages en ligne de commande se valident avec : Modifier les fichiers de properties pour correctement paramétrer le proxy (. ./outils.sh PROXY FALSE si besoin) Démarrer tous les applicatifs avec la commande . ./demarrerTout.sh Vérifier que 4 services (admin, config, gateway et registry) et les 10 micro-services apparaissent dans le registre Vérifier que les 10 micro-services apparaissent dans l\u0026rsquo;admin (admin1 // admin) Vérifier que la javadoc des 10 micro-services est bien disponible dans swaggerUI Ouvrir Postman, y générer un token OIDC SP (requête 024) et exécuter toute la collection sauf les requêtes du répertoire APIs des systèmes externes Arrêter tous les applicatifs avec la commande . ./arreterTout.sh les démarrages depuis Eclipse se valident avec : Modifier les fichiers de properties pour correctement paramétrer le proxy (. ./outils.sh PROXY FALSE si besoin) Démarrer en premier lieu les services SpringCloud : admin, config, gateway, nosql, redis et registry Démarrer les micro-services ne nécessitant pas MongoDB : socle-referentiel, socle-referentielexterne, socle-securite, socle-soumission Vérifier que 4 services (admin, config, gateway et registry) et les 10 micro-services apparaissent dans le registre Vérifier que les 10 micro-services apparaissent dans l\u0026rsquo;admin (admin1 // admin) Vérifier que le fichier 2-code\\socle\\services-cloud\\service-nosql.log\\pid_service-nosql_1.pid existe bien Vérifier que la javadoc des 10 micro-services est bien disponible dans swaggerUI Ouvrir Postman, y générer un token OIDC SP (requête 024) et exécuter la collection Supprimer le fichier 2-code\\socle\\services-cloud\\service-nosql.log\\pid_service-nosql_1.pid pour arrêter la base NoSql Arrêter tous les applicatifs depuis Eclipse (carré rouge dans la vue console) Dans les logs du microservice soumission trouver le traceId d\u0026rsquo;une soumission (le premier terme alphanumerique entre crochet) Vérifier la présence de ce traceId dans les logs du microservice configuration (à minima) pour vérifier la bonne propagation des entêtes de tracing 3.24.5 - Tests E2E Du fait de leurs spécificités, les composants suivants ne sont pas testés par les tests automatiques de Cypress (information de 06/2022) :\nutilisateurConnecte et recapitulatif car ils ne sont pas des composants de saisie mais uniquement d\u0026rsquo;affichage (mauvaise raison) ; documents car, en mode bouchonné, tester le téléchargement n\u0026rsquo;a pas de sens et tester la présence du lien n\u0026rsquo;a que peu d\u0026rsquo;intérêt ; Les tests doivent tester un maximum de chose. Mais ils ne doivent pas planter/échouer si une validation ou un type de contenu n\u0026rsquo;est pas connu. Par contre, il faut générer un log Cypress commençant par */!*.\n/!\\ Les brouillons stockées dans les sources doivent contenir toutes les données (sauf les PJ).\n3.24.6 - Analyse de problème dans les tess E2E Voici quelques cas d\u0026rsquo;erreur E2E connus et analysés :\nune erreur dans blocObtenirTitre peut résulter d\u0026rsquo;un div.fmk-bloc\u0026gt;div.fr-col-12 vide. La source peut être dans la configuration : le bloc n\u0026rsquo;a pas de contenus (attention au s dans le nom de l\u0026rsquo;attribut du bloc). "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.25reglesdelog/",
	"title": "3.25 Règles-logs",
	"tags": [],
	"description": "",
	"content": "\r3.25.1 - Règles des logs 3.25.1 - Règles des logs Les règles impérieuses sont :\naucune donnée personnelle ne doit être logguée. Mais il peut être utile, durant les tests, de consulter le détail des données générées. Donc, les données interdites en production peuvent être loggées en niveau TRACE si et seulement si une ligne de log WARNING est ajoutée dans la classe et générée dès le début du micro-service pour avertir du problème (cf. ValidationSoumissionServiceImpl) en cas d\u0026rsquo;instanciation d\u0026rsquo;une exception volontairement imprécise (pour ne pas divulguer les mécaniques internes des micro-service - cf. ValidationSoumissionServiceImpl), une ligne de log ERROR précisant le problème peut être générée à condition qu\u0026rsquo;elle apporte une information supplémentaire et ne contienne pas la stacktrace de l\u0026rsquo;exception envoyée. en cas d\u0026rsquo;instanciation d\u0026rsquo;une exception volontairement imprécise + dans un catch d\u0026rsquo;exception + une erreur ne générant pas une log d\u0026rsquo;erreur (sécurité par exemple - OidcServiceImpl, il faut avoir un moyen de logguer l\u0026rsquo;exception de base. Dans ce cas, il faut ajouter un log DEBUG contenant la stacktrace. en cas de log d\u0026rsquo;une donnée venant du navigateur (paramètre d\u0026rsquo;URL, donnée soumise dans un POST, \u0026hellip;) avec une sévirité INFO, WARN ou ERROR, cette donnée doit passer dans LogUtil.nettoyerDonneesAvantDeLogguer avant d\u0026rsquo;être logguée Les règles importantes sont :\ntout appel à un service externe au SI doit être tracé précisément avec le contenu de la requête et de la réponse toute information utile peut être générée "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.26regesspecificiquesfront/",
	"title": "3.26 Règles-Front",
	"tags": [],
	"description": "",
	"content": "\r3.26.1 - Angular 3.26.2 - DSFR 3.26.3 - Material versus DSFR 3.26.1 - Angular Toutes les bonnes pratiques poussées par Angular doivent être respectées. C\u0026rsquo;est pour cette raison que, régulièrement, un projet Angular est créé de zéro avec Angular-cli. Ainsi toutes les règles (notamment tslint) sont réintégrées au projet front.\nEn plus de ces bonnes pratiques, des choix ont été faits sur le projet :\naucun fichier source ne doit être vide (notamment les fichiers SCSS bien souvent vides) les CSS de chaque composant ne sont pas encapsulées (cf. documentation Angular associée). Pour ce faire, tout composant Angular doit avoir l\u0026rsquo;attribut encapsulation: ViewEncapsulation.None Tout sélecteur CSS présent dans un fichier SCSS doit être unique tout composant Angular doit être standalone. Autrement dit, il est un module à lui tout seul (cf. documentation Angular dédiée). Attention donc aux dépendances cycliques (d\u0026rsquo;où la séparation entre les contenus simples et riches car contenu-\u0026gt;contenuIdentite-\u0026gt;contenu). 3.26.2 - DSFR Tous les développements doivent respecter la charte graphique DSFR et RGAA :\nen premier lieu, aucune CSS de la DSFR ne doit être surchargée. la structure HTML des composants DSFR (cf. documentation officielle et toute note, remarque et changement doivent être indiqués dans ce chapitre. concernant le RGAA et les règles Aria : tout input/select/textarea contient un attribut aria-describedby dont la valeur est l\u0026rsquo;ID d\u0026rsquo;une balise data-fmk-messagesvalidation toute balise label contient un attribut for contenant l\u0026rsquo;ID du champ de saisie associé tout texte doit être présent dans une balise P , SPAN, Hx, A, LABEL =\u0026gt; A TRAITER : upload.cadreGlisseDeposer un formulaire ne doit jamais contenir deux boutons fr-btn (donc primaire par défaut) sans que l\u0026rsquo;un d\u0026rsquo;eux soit fr-btn\u0026ndash;secondary, voire fr-btn\u0026ndash;tertiary (cf. documentation officielle). la classe fr-container ne doit pas être utilisées plusieurs fois les unes dans les autres au risque de cumuler une marge de chaque côté de l\u0026rsquo;écran. Les seuls usages autorisés sont : l\u0026rsquo;entête, la modale du menu, le conteneur de page, le pied de page haut et le pied de page bas. les messages d\u0026rsquo;erreur sous chaque INPUT doivent respecter les règles suivantes : chaque composant data-fmk-messagesvalidation doit être appelé sur un P pour s\u0026rsquo;approcher de la charte DSFR et aussi obtenir une marge stable sous le champ de saisie l\u0026rsquo;attribut aria-live=\u0026ldquo;assertive\u0026rdquo; est obligatoire car il permet d\u0026rsquo;indiquer au lecteur d\u0026rsquo;écran que cette zone doit être lue si elle change Bugs connus :\n30/04/2024 - connexionbrouillon : la case à cocher permettant d\u0026rsquo;afficher le mot de passe devrait être une icône d\u0026rsquo;oeuil selon la documentation mais ce n\u0026rsquo;est pas le cas. 30/04/2024 - contenuradio : la marge sous le composant est plus grande que pour les autres composants. Ceci vient de la balise FIELDSET qui doit être utilisée pour regrouper les champs associés aux valeurs possibles. Les autres types de contenu n\u0026rsquo;ont pas de Fieldset donc pas cette marge supplémentaire. 02/05/2024 - entete : la liste des liens présents dans l\u0026rsquo;entête ne sont pas bien recopiés par le JS DSFR dans la modale au passage en mobile. Il est nécessaire de recopier explicitement les liens dans la modale. 02/05/2024 - entete : si les éléments de l\u0026rsquo;entête sont copiés dans la modale (cf. point précédent), le sélecteur de langue ne fonctionne pas car la liste des options ne s\u0026rsquo;affiche pas dans la modale. 3.26.3 - Material versus DSFR En théorie, seule la librairie DSFR devrait être utilisée pour construire les écrans des démarches et des applications d\u0026rsquo;administration.\nMais la DSFR manque de plusieurs composants : une barre de progression (utilisée dans les uploads de composant) et une autocompletion (utilisée partout).\nDonc Material (historiquement utilisé avant la DSFR) a été conservé pour ses usages exclusivement.\n"
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.31proceduressitedocumentaire/",
	"title": "3.31 Procédures-site documentaire",
	"tags": [],
	"description": "",
	"content": "\r3.31.1 - Installer tous les éléments 3.31.2 - Démarrer / arrêter le site 3.31.3 - Modifier les pages 3.31.4 - Modifier l\u0026rsquo;arborescence 3.31.5 - Générer la documentation technique 3.31.6 - Créer le site documentaire statique 3.31.7 - Mettre à jour la version d\u0026rsquo;Hugo 3.31.1 - Installer tous les éléments Pour manipuler modifier le site documentaire, il est faut :\ncloner le dépôt des sources du projet installer le HOOK git pre-commit en copiant le fichier aInstaller_pre-commit présent à la racine du dépôt le renommant pre-commit le plaçant dans le répertoire .git/hooks Le reste de la procédure d\u0026rsquo;installation de poste est disponible au chapitre §3.2.\n3.31.2 - Démarrer / arrêter le site Pour manipuler Hugo :\ndémarrer le site en dev : double-cliquer sur startServer.cmd arrêter le site en dev : sélectionner la fenêtre de commande DOS et enfoncer les touches CTRL et C 3.31.3 - Modifier les pages Pour enrichir les pages, modifier les pages présentes dans l\u0026rsquo;arborescence /content.\nLes documentations de GoHugo est ici mais je vous conseille celle du thème utilisé (plus synthétique) ici.\n3.31.4 - Modifier l\u0026rsquo;arborescence L\u0026rsquo;ordre des pages est basé sur l\u0026rsquo;attribut weight présent dans les métadatas de chaque page (en haut entre les +++).\nDans ce projet, la documentation est prévue pour s\u0026rsquo;organiser sur 3 niveaux de profondeur maximum.\nDonc le poids est la concaténation du numéro du chapitre avec chaque chapitre sur 2 chiffres. On obtient :\nchapitre 1.2.3 =\u0026gt; weight = 10203 chapitre 2.3.12 =\u0026gt; wigth = 020312 3.31.5 - Générer la documentation technique Une grande quantité d\u0026rsquo;information de la documentation est issue de documentation générée (notamment de la Javadoc).\nPour générer cette documentation, il faut exécuter la commande mvn clean install -P qualimetrie\n__\n3.31.6 - Créer le site documentaire statique Pour cela, il faut :\nouvrir une ligne de commande dans le répertoire 1-conception exécuter le script build.cmd qui exécute la génération du site vérifie tous le contenu du site et notamment les liens (avec htmltest vérifier qu\u0026rsquo;aucun avertissement ou erreur ne remonte dans les logs affichés dans la console __\n3.31.7 - Mettre à jour la version d\u0026rsquo;Hugo Pour mettre à jour la version d\u0026rsquo;Hugo :\ndepuis le site officiel de Hugo, télécharger la dernière version disponible avec le packaging windows-amd64.zip extraire le fichier hugo.exe dans le répertoire 1-conception démarrer Hugo (cf. chapitre précédent Démarrer / arrêter le site) passer rapidement en revue les pages pour vérifier que tout fonctionne bien vérifier qu\u0026rsquo;aucun avertissement ou erreur ne remonte dans les logs affichés dans la console arrêter Hugo builder Hugo (cf. chapitre Créer le site documentaire statique) vérifier qu\u0026rsquo;aucun avertissement ou erreur ne remonte dans les logs affichés dans la console (autre que les erreurs de connexion à localhost ou dev-psl.guillaumetalbot.com) mettre à jour la page de suivi pour indiquer la version installée de Hugo et la date de la prochaine mise à jour (dans 3 mois) "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.32proceduresapplicationangular/",
	"title": "3.32 Procédures-règles de l&#39;application Angular",
	"tags": [],
	"description": "",
	"content": "\r3.32.1 - Recréer un workspace Angular avec des applications et un librairie commune 3.32.2 - Créer une nouvelle application de démarche 3.32.3 - Vérifier la cohérence d\u0026rsquo;une démarche 3.32.4 - Ajouter un nouveau type de contenu 3.32.5 - A savoir sur un type de contenu 3.32.6 - Ajout/retrait/modification d\u0026rsquo;un attribut dans un type de contenu ou une classe du package model 3.32.7 - Comment ajouter un nouveau type de validation de champ 3.32.8 - Règles de développement dans le code spécifique d\u0026rsquo;une démarche 3.32.9 - Intégration de la charte graphique de l\u0026rsquo;état (DSFR) 3.32.10 - Validation W3C du code HTML généré 3.32.11 - Quelques rappels TS/JS 3.32.1 - Recréer un workspace Angular avec des applications et un librairie commune Les informations/documentations/sources utiles :\nhttps://octoperf.com/blog/2019/08/22/kraken-angular-workspace-multi-application-project/#install-angular-material https://angular.io/guide/file-structure https://www.tektutorialshub.com/angular/angular-multiple-apps-in-one-project/ Les commandes à exécuter :\npour initialiser le workspace : ng new frontend --createApplication=false --directory=frontend --interactive=false pour créer un projet : ng generate application etatcivil --style=scss --routing=false ajouter Material au projet : ng add @angular/material --project=etatcivil pour créer une librairie : ng generate library framework pour déclarer un service partagé : il est possible d\u0026rsquo;utiliser la commande : ng generate service validation --project=framework attention à ne pas faire apparaitre le service dans le module de la librairie mais d\u0026rsquo;utiliser l\u0026rsquo;anotation @Injectable({ providedIn: 'root' }) (cf. documentation de l\u0026rsquo;anotation @Injectable) 3.32.2 - Créer une nouvelle application de démarche Les étapes à réaliser pour créer une application de démarche sont :\ncréer l\u0026rsquo;application Angular modifier le fichier package.json et remplacer xxxxxx par le code de la démarche (en minuscule) dans la commande creationDemarche exécuter la commande npm run creationDemarche (ou yarn à la place de npm) remettre le code xxxxxx dans la commande creationDemarche dans le package.json sur le modèle des commandes existantes, dans le package.json, en respectant l\u0026rsquo;ordre alphabétique créer les commandes xxxxxx-start, xxxxxx-startcoverage, xxxxxx-build-prod, xxxxxx-compodoc et xxxxxx-analyseBundle ajouter ces commandes dans les all-* (les commentaires dans ce json sont obligatoires et sur le modèle \u0026quot;//commande : mon commentaire\u0026quot;:\u0026quot;\u0026quot;) dupliquer un fichier assembly/xxxxxx-assembly.xml et en personnaliser le contenu avec le code de la démarche éditer le pom.xml du projet front pour y ajouter l\u0026rsquo;exécution gitInfos-xxxxxx sur le modèle des existants y ajouter l\u0026rsquo;exécution zip-xxxxxx sur le modèle des existants déclarer le nouveau répertoire de source dans le fichier tsconfig.json à la racine du projet front pour initialiser l\u0026rsquo;application Angular supprimer, s\u0026rsquo;ils existent, les fichiers src/favicon.ico et src/app/app-routing.module.ts dupliquer le fichier tsconfig.doc.json présent à la racine d\u0026rsquo;un autre projet dans ce nouveau projet dans le fichier angular.json, trouver le nouveau projet puis trouver ses 2 attributs styles pour y mettre le même contenu que celui des autres projets (au delta du code de la démarche) trouver ses 2 attributs assets pour y mettre le même contenu que celui des autres projets (au delta du code de la démarche) trouver l\u0026rsquo;attribut schematics pour y mettre le même contenu que celui des autres projets recréer la partie build-coverage à la place de la partie test ajouter les éléments nécessaires pour que la configuration de la démarche soit identique (au code de démarche près) aux autres (trop de modifications et trop changeante pour être listées ici) dans le répertoire projects/nouvelleDemarche, supprimer le fichier .eslintrc.json supprimer les fichiers tsconfig.spec.json et src/app/app.component.spec.ts récupérer la page index.html d\u0026rsquo;une autre démarche en changeant le contenu de la balise title et la balise base récupérer le répertoire des fichiers d\u0026rsquo;environnement (src/environments) en remplaçant le code de la démarche récupérer le composant app.component dans son ensemble (TS et HTML) depuis une autre démarche (etatcivil par exemple) sans oublier de retirer du HTML le code des pages spécifiques (etatcivil n\u0026rsquo;en a pas) récupérer le app.module depuis une autre démarche en en retirant les spécificités de la démarche (s\u0026rsquo;il y en a) récupérer le répertoire cypress à la racine d\u0026rsquo;un autre projet (autre qu\u0026rsquo;edition), le dupliquer dans la nouvelle démarche remplacer le code de la démarche dans le fichier src/cypress/e2e/e2e.cy.ts configurer la démarche créer la configuration publique de la démarche dans le fichier assets/bouchonapi/param.json du code Angular de la démarche (nom à définir en cohérence avec celui indiqué dans le fichier e2e.cy.ts) supprimer le fichier src/assets/.gitkeep (qui ne sert plus à rien car un répertoire existe maintenant) créer un brouillon dans le répertoire assets/bouchonapi du code Angular de la démarche créer la configuration privée de la démarche dans le répertoire 2-code/socle/socle-dbconfiguration/src/test/resources/db (ainsi que les templates de document à générer) tester supprimer le contenu de la base de données avec la commande . ./outils.sh PURGE DB (qui supprime le répertoire 2-code/socle/.embedmongo avant de démarrer la base de données MongoDB du socle (pour forcer l\u0026rsquo;initialisation) depuis les logs de démarrage de la base de données, vérifier que le nombre de configurations publiques, de configurations privées et de templates de document sont bien insérés démarrer la démarche avec la commande npm run xxxxxx-start (ou yarn à la place de npm) la démarche doit être fonctionnelle arrêter l\u0026rsquo;application activer tous les bouchons démarrer l\u0026rsquo;application avec la commande npm run xxxxxx-startcoverage (ou yarn à la place de npm) démarrer les tests E2E avec la commande npm run e2e (ou yarn à la place de npm) documenter la démarche ajouter un lien vers la documentation technique générée (compodoc) de la démarche dans la page des démarches ajouter le code de la démarche dans la page des principes de conception ajouter un lien vers la documentation technique générée (compodoc) de la démarche dans la page des liens documentaires ajouter un lien vers l\u0026rsquo;environnement de développement dans la page des liens ajouter une ligne pour la démarche dans la liste des tests réguliers à réaliser vérifier la cohérence de la démarche vis-à-vis des autres : exécuter la procédure du chapitre suivant dans le code Java, dans le projet socle-soumission, dans les classes SoumissionReelleServiceTest et GenerationServiceDepuisSourcesFrontTest, sur le modèle des tests existants, créer un test pour réaliser une soumission avec la configuration et les données du brouillon de la nouvelle démarche dans le projet IAS, dans le répertoire 2-code\\ias\\ansible, déclarer la nouvelle démarche dans : le playbook 03-deployer.yml sur le modèle de celui d\u0026rsquo;arnaqueinternet (en respectant l\u0026rsquo;ordre alphabétique) dans le fichier de variables de chaque inventaire (fichier inventory/*/group_vars/all/default.yml), ajouter la nouvelle démarche dans les variables applications_web_front et version_front 3.32.3 - Vérifier la cohérence d\u0026rsquo;une démarche Cette procédure ne s\u0026rsquo;applique au pied de la lettre que pour les démarches sans code spécifique. Elle permet de vérifier la cohérence entre les démarches et la bonne prise en compte de modifications globales (ajout d\u0026rsquo;une librairie ou d\u0026rsquo;une fonctionnalité) :\nouvrir l\u0026rsquo;outil KDIFF ouvrir ensemble les répertoires 2-code/front/projects/bibliotheque et 2-code/front/projects/xxxx avec xxxx le code de la démarche à comparer ne doivent être différents que : le code de la démarche dans le fichier cypress/e2e/e2e.cy.ts et potentiellement le nom des brouillons le contenu des fichiers src/assets/bouchonapi/brouillon.json et src/assets/bouchonapi/param.json car ils sont totalement spécifiques à chaque démarche le contenu des fichiers src/environments/environments.ts et src/environments/environments.prod.ts car ils contiennent le code de la démarche le contenu des fichiers src/index.html, src/environments/environments.ts et src/environments/environments.prod.ts car ils contiennent le code de la démarche 3.32.4 - Ajouter un nouveau type de contenu Tout type de contenu dispose des attributs suivants (@see ContenuDeBloc dans configurationdemarchecontenubloc.model.ts) : cliquer ici pour afficher le contenu clef : Clef unique définissant la donnée saisie. Cette clef est utilisable dans les conditions et les autres champs. titre : Titre du contenu de bloc. Cet attribut n\u0026rsquo;est pas obligatoire. S\u0026rsquo;il est vide, aucun titre ne s\u0026rsquo;affiche. aide : Aide affichée à côté du titre si elle est renseignée. type : Type du contenu conditionDesactivation : Condition de désactivation du champ (cf. conditionVisibilite) conditionVisibilite : Condition d\u0026rsquo;affichage du contenu. Cette attribut est optionnel et sa valeur par défaut est undefined. Cette condition est une expression JS évaluée avec l\u0026rsquo;équivalent de la méthode EVAL() ayant accès aux données de la démarche uniquement. Attention, toutes les données sont des chaines de caractères (même les boolean et les nombres). Pour ajouter un type de contenu, il faut :\ndéclarer un nouveau type dans TypeContenuDeBloc (@see configurationdemarchecontenubloc.model.ts) associer ce nouveau type avec les catégories définies dans UtilitaireModel (@see utilitaire.model.ts) déclarer une nouvelle classe avec les spécificités du contenu à gérer dans configurationdemarchecontenubloc.model.ts (si nécessaire) enrichir la méthode ConfigurationService.transtyperContenuDeBloc pour transtyper les objets JSON dans le bon type TS créer le composants TS du nouveau type de contenu déclarer ce nouveau composant Angular dans le module.ts ajouter un GETTER dans le composant FmkContenuComponent (en respectant l\u0026rsquo;ordre alphabétique des méthodes) ajouter une balise \u0026lt;fmk-contenuxxxxx dans la partie HTML du composant FmkContenuComponent (en respectant l\u0026rsquo;ordre alphabétique des composants) Côté Java, il faut aussi :\ndéclarer le type de contenu dans une des constantes de la classe ValidationSoumissionServiceImpl les champs de type autocompletion des composants complexes dans ValidationSoumissionServiceImpl.LISTE_SOUS_CHAMPS_AUCOMPLETION_DANS_COMPOSANT_COMPLEXE Côté Editeur, il ne faut pas oublier de :\nvérifier les impacts sur le formulaire d\u0026rsquo;un contenu Côté documentation, il faut enfin :\najouter le nouveau type de composant à la liste du chapitre 2.6 décrire le nouveau type de contenu dans le chapitre 2.10.2.2 3.32.5 - A savoir sur un type de contenu Concernant le fonctionnement d\u0026rsquo;un type de contenu, quelques éléments à savoir :\nne jamais utiliser une méthode/interface de hook du cycle de vie Angular (OnChange, OnInit\u0026hellip;) pour exécuter du code au chargement du composant, il suffit de surcharger la méthode protected initialiserComposant(contenu: ContenuDeBloc): void {} 3.32.6 - Ajout/retrait/modification d\u0026rsquo;un attribut dans un type de contenu ou une classe du package model En cas de modification d\u0026rsquo;une classe décrivant un type de contenu (ou une classe de la grappe de données des configurations publiques/inernes) pour y ajouter une un attribut saisissable dans un JSON (pas une donnée calculée), il est nécessaire de réaliser des modifications dans d\u0026rsquo;autres classes du projet :\ndans ConfigurationService : si l\u0026rsquo;attribut ajouté/modifié/supprimé est un type complexe (objet ou tableau), il est nécessaire de l\u0026rsquo;initialiser au cas où il serait absent de la configuration chargée en JSON. dans l\u0026rsquo;application d\u0026rsquo;édition de démarche, le/les composants graphiques doivent être adaptés à la structure de données dans l\u0026rsquo;éventuelle classe Java équivalente, la modification doit aussi être appliquée dans la démarche bibliotheque, un exemple doit être fourni 3.32.7 - Comment ajouter un nouveau type de validation de champ Il existe deux types de validation de champ : les paramétrables et les autres. Par exemple dateAvant-7j est une validation paramétrable et required ne l\u0026rsquo;est pas.\nCôté FRONT, pour ajouter une validation, il faut :\nmodifier la classe Validation dans le fichier configurationdemarchecontenubloc.model.ts pour ajouter le nom de la validation (ou la partie fixe si c\u0026rsquo;est une validation paramétrable) modifier la classe ValidationService pour ajouter le contrôle lui-même (en s\u0026rsquo;inspirant du code existant). Attention, si la validation est paramétrable, l\u0026rsquo;objet retourné par la méthode de validation doit contenir la partie fixe et non la variable v. modifier le fichier fmk.messagesvalidation.html pour ajouter le message d\u0026rsquo;erreur associé à la validation modifier la méthode ContenuMonoTestUtils.definirMauvaiseValeur pour y fournir une mauvaise valeur pour la nouvelle validation ajouter la nouvelle validation dans le second if de la méthode ContenuMonoTestUtils.validerLesValidationDunContenuMonoChamp si la validation est paramétrable, enrichir le calcul de la variable nomClasseAssocieAvalidation de la méthode ContenuMonoTestUtils.validerLesValidationDunContenuMonoChamp modifier la configuration de la démarche bibliotheque pour y ajouter un champ avec cette nouvelle validation modifier les données de brouillon de la démarche bibliotheque pour y ajouter une bonne valeur pour le nouveau champ si la bonne valeur n\u0026rsquo;est pas une valeur fixe (mais une valeur dépendante du jour par exemple), modifier la méthode ContenuMonoTestUtils.definirBonneValeur pour y ajouter une gestion spécifique de cette validation lancer les tests E2E de la démarche bibliotheque modifier la démarche devant utiliser cette nouvelle validation lancer les tests E2E de cette démarche Côté BACK, pour ajouter une validation, il faut :\nmodifier la classe ValidationEnum pour ajouter le nom de la validation (ou la partie fixe si c\u0026rsquo;est une validation paramétrable) modifier la méthode ValidationSoumissionServiceImpl.verifierValidationDuneValeur pour ajouter le contrôle lui-même (en s\u0026rsquo;inspirant du code existant). tester la nouvelle validation en modifiant les classes SoumissionObjectMother et ValidationServiceTest pour enrichir les cas passants existants ajouter des cas bloquants et aux limites lancer les tests automatisés sur projet socle-soumission 3.32.8 - Règles de développement dans le code spécifique d\u0026rsquo;une démarche aucune fonctionnalité du framework ne doit être enrichie. Il faut enrichir le framework (type de contenu, validation\u0026hellip;) toute souscription (alias appel à une méthode subscribe()) doit être détruite à la fin de la vie du composant qui réalise la souscription. La seule exception concerne les composants immortels (comme les AppComponent) pour lesquels un commentaire explicite est obligatoire. Pour réaliser cela, soit le composant détruit lui-même la souscription dans sa méthode ngOnDestroy (prendre modèle sur la classe AbstractComponent) soit le composant hérite de AbstractComponent et utilise les méthodes declarerSouscription et declarerSouscriptions pour ajouter la souscription créée à la liste des souscriptions à détruire 3.32.9 - Intégration de la charte graphique de l\u0026rsquo;état (DSFR) La documentation est disponible ici : https://gouvfr.atlassian.net/wiki/spaces/DB/pages/223019574/D+veloppeurs. La dépendance à DSFR (en version 1.1 au 10/11/2021) se fait via NPM/YARN. Pour intégrer les CSS DSFR à l\u0026rsquo;application, la configuration //build/options/styles est correctement renseignée dans le fichier angular.json. La feuille de style projects/framework/src/assets/stylesDSFR.scss est dédiée aux styles ajoutés à DSFR pour l\u0026rsquo;amender ou la compléter pour les besoins de la PSL.\n3.32.10 - Validation W3C du code HTML généré Pour valider le code HTML généré dans une démarche, il faut :\ndans une démarche donnée, recopier le contenu du fichier src/environments/environment.ts dans le fichier src/environments/environment.prod.ts depuis l\u0026rsquo;invite de commande, exécuter un xx-build-prod de la démarche lancer le serveur http via la commande npm http-start pour chaque écran de la démarche dans les outils de développement, dans l\u0026rsquo;onglet Elements, sélectionner la balise html et copier tout le contenu de la page aller sur le site du validateur W3C coller le code HTML lancer la validation interpréter les résultats la balise doctype n\u0026rsquo;est pas copiée dans la procédure mais est bien présente dans le code de la page. Donc cette erreur peut être ignorée. le contenu @charset \u0026ldquo;UTF-8\u0026rdquo; vient des CSS de la DSFR l\u0026rsquo;attribut type de la balise style est généré automatiquement par Angular le rôle banner sur la balise header est demandée explicitement par la documentation DSFR le rôle main sur la balise main est demandée explicitement par la documentation DSFR : lien 1 et lien 2 le rôle navigation sur la balise nav est demandée explicitement par la documentation DSFR l\u0026rsquo;attribut contentinfo sur la balise footer est demandée explicitement par la documentation DSFR 3.32.11 - Quelques rappels TS/JS Voici quelques liens à consulter pour (re)découvrir quelques bases de TypeScript/Javascript :\nles falsy "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.33proceduresmaven/",
	"title": "3.33 Procédures-environnement Maven",
	"tags": [],
	"description": "",
	"content": "\r3.33.1 - Utilisations courantes de Maven 3.33.2 - Changement de version du socle PSL 3.33.3 - Changement ou ajout d\u0026rsquo;une dépendance 3.33.4 - Astuce pour exécuter un unique plugin ou une unique exécution 3.33.1 - Utilisations courantes de Maven Pour compiler le socle PSL, il est nécessaire de systématiquement compiler les classes de test. Donc il ne faut pas utiliser le paramètre -Dmaven.test.skip. La bonne commande à utiliser est mvn clean install -DskipTests. Pour exécuter les tests durant le build, la commande est mvn clean install.\nPour lancer le build avec la génération de la documentation, la commande est mvn clean install -P qualimetrie\n3.33.2 - Changement de version du socle PSL Pour modifier la version dans ce pom.xml et tous ces sous-modules, utiliser les commandes suivantes :\nmvn versions:set -DprocessAllModules -DnewVersion=X.Y.Z-SNAPSHOT mvn versions:commit -DprocessAllModules 3.33.3 - Changement ou ajout d\u0026rsquo;une dépendance Toute modification de la version d\u0026rsquo;une dépendance (ou de son ajout) doit faire l\u0026rsquo;objet d\u0026rsquo;une vérification de la licence associée au composant.\nUnitairement, cette vérification peut se faire à la main depuis le site mvnRepoitory sur la page précise du composant (dans le tableau en tête de page). Globalement, cette vérification peut se faire via l\u0026rsquo;outil DependencyTrack. Son usage est documenté dans le chapitre §3.34.5. 3.33.4 - Astuce pour exécuter un unique plugin ou une unique exécution Maven peut être exécuter d\u0026rsquo;une phase de son cyle à une autre comme par exemple dans mvn clean install -DskipTests -T 1C (avec DskipTests qui saute l\u0026rsquo;exécution des tests mais pas leur compilation et -T 1C pour utiliser tous les coeurs de processeur pour paralléliser le travail).\nMais il est aussi possible de n\u0026rsquo;exécuter qu\u0026rsquo;une seule (ou plusieurs) exécutions avec la commande mvn idPlugin:goal@idExecution idPlugin2:goal2. Par exemple, pour builder complètement une unique application FRONT, il faut :\nnpm run adminpsl-build-prod mvn git-commit-id:revision@gitInfos-adminpsl assembly:single@zip-adminpsl install:install "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.34proceduressecurite/",
	"title": "3.34 Procédures-veille sécurité",
	"tags": [],
	"description": "",
	"content": "\r3.34.1. - Projet Socle 3.34.1.1 - Mettre à jour les dépendances Java 3.34.1.2 - Chiffrement / déchiffrement des mots de passe (ou clefs) dans les fichiers de configuration 3.34.2 - Projet Front 3.34.2.1 - Montée de version Angular 3.34.2.2 - Montée de version Angular compliquée 3.34.2.3 - Montée de version Angular 3.34.2.4 - Montée de version DSFR 3.34.2.5 - Montée de version des autres dépendances Node 3.34.3 - Mise à jour des outils 3.34.3.1 - VSCode 3.34.3.2 - Eclipse 3.34.3.3 - Java 3.34.3.4 - Node 3.34.3.5 - Maven 3.34.4 - Documentation du Socle 3.34.4.1 - Rapports du Socle 3.34.4.2 - Tests de sécurité avec OWASP ZAP 3.34.5 - Suivi de sécurité avec DependencyTrack 3.34.5.1 - Installation/réinstallation et préparation d\u0026rsquo;une instance locale de DependencyTrack 3.34.5.2 - Audit des projets SOCLE et FRONT 3.34.5.3 - Raffrachir un audit 3.34.5.4 - Analyse 3.34.1. - Projet Socle Le projet Socle est paramétré pour fournir une liste des failles de sécurité associées à chaque dépendance Maven utilisée dans les sources.\n/!\\ Il est préférable de réaliser l\u0026rsquo;analyse à la suite d\u0026rsquo;une montée de version des principales librairies et des principaux framework ! (et non avant)\n3.34.1.1 - Mettre à jour les dépendances Java Les fichiers pom.xml, 2-code/front/pom.xml et 2-code/socle/pom.xml sont aménagés pour faciliter cette montée de version : en face de chaque propriété \u0026lt;version.xxxx\u0026gt; est placé le lien direct vers le site mvnrepository.com permettant de vérifier la dernière version disponible.\nLa montée de version consiste donc en :\nla modification de la version de chaque dépendance directe (depuis les fichiers pom.xml) pour utiliser la dernière version disponible ; la déconnexion de tout réseau nécessitant un proxy et leur désactivation (le téléchargement des dépendances sera plus rapide et celui de flapdoodle ne supporte pas les proxy) la compilation uniquement (-DskipTests -T 1C) de l\u0026rsquo;ensemble du projet (au besoin, utiliser Eclipse pour tout compiler après le premier échec et le téléchargement de la plus part des dépendances) ; la correction de toutes les nouveaux avertissements (notamment Deprecated) le build de l\u0026rsquo;ensemble du code ; la purge de tous les éléments du socle (logs, données de base de données et cache) avec l\u0026rsquo;outil . ./outils.sh depuis le répertoire 2-code/socle ; pour gagner du temps, recréer le fichier de cache du référentiel des SIRET (cf. §3.2.11) le démarrage de tous les composants applicatifs avec la commande . ./demarrerTout.sh depuis le répertoire 2-code/socle ; la vérification du bon démarrage de tous les composants applicatifs ; l\u0026rsquo;exécution des tests depuis UseBruno : suivre les étapes du chapitre règles de test des requêtes HTTP ; le démarrage des démarches compilées avec la commande npm run http-start depuis le répertoire 2-code/front ; l\u0026rsquo;exécution de tests manuels depuis les démarches ; l\u0026rsquo;arrêt de tous les composants applicatifs avec la commande . ./arreterTout.sh depuis le répertoire 2-code/socle ; la suppression de la précédente version de flapdoodle (.embedmongo/windows/mongodb-windows-x86_64-xxx.zip et embedmongo/Windows-B64\u0026ndash;unknown\u0026mdash;xxx) ; la mise à jour, dans le fichier 4.2quoi.md, des dates de l\u0026rsquo;actuelle et de la prochaine mise à jour des dépendances du socle ; la vérification des licences associées aux dépendances (cf. §3.34.5) le commit de la montée de version. 3.34.1.2 - Chiffrement / déchiffrement des mots de passe (ou clefs) dans les fichiers de configuration Tout mot de passe ou clef de configuration doit être stocké(s) sous forme chiffrée. Pour cela il suffit :\nde démarrer (ou avoir déjà démarré) les services service-gateway et service-registry (nécessaires pour appeler les APIs exposées par service-config) de commenter, dans le fichier application-specifique.properties du projet service-config, les clefs spring.security.user.xx de commenter, dans le pom.xml du même projet, la dépendance à spring-boot-starter-security dans le pom.xml de service-config de démarrer le service service-config d\u0026rsquo;utiliser l\u0026rsquo;API http://localhost:xxxx/encrypt depuis l\u0026rsquo;IDE HTTP (UseBruno) pour chiffrer une valeur fournie dans le corps de la requête de placer cette valeur chiffrée dans le fichier de properties souhaité en la préfixant par {cipher} A savoir :\nPour déchiffrer une valeur, une API decrypt existe aussi. Pour créer le keystore, les étapes à suivre sont (ici) : se placer dans un répertoire et ouvrir une ligne de commande exécuter la commande keytool -genkeypair -alias clefDeTest -keyalg RSA -dname \u0026quot;CN=ServiceConfig,OU=Moi,O=Perso,L=Amiens,S=France,C=FR\u0026quot; -keystore service-config.jks -storepass MotDePasseStore placer le fichier service-config.jks n\u0026rsquo;importe où et utiliser la clef cheminkeystore pour pointer sur le répertoire contenant le keystore (dans les sources, le keystore est présent dans le répertoire src/test/resources du projet service-config pour ne pas être embarqué dans le JAR exécutable) 3.34.2 - Projet Front 3.34.2.1 - Montée de version Angular La mise à jour d\u0026rsquo;Angular est régulière car une version sort régulièrement. Elle est à réaliser de la manière suivante :\navant la montée de version, vérifier que le projet front fonctionne en exécutant un build complet npm run all-build-prod puis npm run all-postBuildProd-setOIDC exécutant les tests npm run e2e vs npm run xx-start avec xx chacune des démarches ouvrir le site guidant chaque montée de version Angular si une nouvelle version majeure est disponible sélectionner la version source (actuelle et donc présente dans le package.json) et la dernière version GA proposée sur le site suivre les instructions fournies par le site en complément des commandes ci-dessous (potentiellement avant ou après) ne pas exécuter la commande ng update ... de la procédure d\u0026rsquo;Angular (prévu plus bas) en cas de besoin, le paramètre \u0026ndash;allow-dirty de la commande ng update permet une exécution de la mise à jour sans devoir tout commiter dans une ligne de commande DOS, mettre @angular/cli à jour avec la commande npm install --save-dev @angular/cli pour réaliser la mise à jour, exécuter npm run update-angular vérifier que toutes les versions modifiées sont identiques entre elles sinon les harmoniser à la main (sauf @angular-builders*) installer les dépendances avec la commande npm install (normalement inutile) vérifier que le projet front fonctionne en exécutant un build complet npm run all-build-prod puis npm run all-postBuildProd-setOIDC exécutant les tests npm run e2e vs npm run xx-start avec xx chacune des démarches mettre à jour la page contenant la backlog et programmer la prochaine mise à jour pour le prochain trimestre 3.34.2.2 - Montée de version Angular compliquée En cas de problème sur une montée de version, il est parfois nécessaire de recréer un projet de zéro pour avoir une référence et de traiter à la main les différences entre le projet de référence et le vrai projet.\nPour cela, il faut\ncréer un nouveau workspace Angular avec une librairie et une application avec les commandes suivantes (source) : se placer dans le répertoire /2-code et y ouvrir une ligne de commande DOS (pas gitBash car des questions sont posées et gitBash ne le supporte pas en 11/2022) npm install --location=global @angular/cli@latest pour mettre à jour le CLI d\u0026rsquo;Angular (oui en NPM même si le reste du projet est en Yarn) supprimer le répertoire existant /2-code/front-exemple ng new front-exemple --create-application false pour créer une nouvelle application avec la dernière version disponible cd front-exemple pour entrer dans le répertoire de la nouvelle application ng generate library framework --skip-package-json true --skip-install true pour créer une librairie ng generate application bibliotheque --routing false --skip-tests true --style scss --ssr false pour créer une application npm install angular-oauth2-oidc espression ngx-logger font-awesome font-awesome-animation @gouvfr/dsfr @angular/material @angular/cdk --save pour ajouter les dépendances actuelles du projet en cas de problème avec la commande à cause d\u0026rsquo;une dépendance de la librairie DSFR, essayer d\u0026rsquo;ajouter le paramètre --legacy-peer-deps npm install @compodoc/compodoc @cypress/schematic cypress cypress-fail-fast cypress-html-validate html-validate ng-packagr npm-check-updates source-map-explorer @cypress/webpack-batteries-included-preprocessor @cypress/webpack-preprocessor @cypress/code-coverage http-server --save-dev pour ajouter les dépendances actuelles du projet en cas de problème avec la commande à cause d\u0026rsquo;une dépendance de la librairie DSFR, essayer d\u0026rsquo;ajouter le paramètre --legacy-peer-deps désinstaller le client Angular global avec la commande npm remove --location=global @angular/cli récupérer le contenu du projet actuel supprimer le fichier README.md dans le nouveau projet, supprimer les répertoires projects\\framework\\public, projects\\bibliotheque\\public, projects\\framework\\src et projects\\bibliotheque\\src récupérer les 4 mêmes répertoires du projet actuel récupérer aussi : cypress.config.ts projects\\framework\\cypress projects\\bibliotheque\\cypress éditer le fichier angular.json pour supprimer la balise architect \u0026gt; test et architect \u0026gt; extract-i18n récupérer la balise architect \u0026gt; cypress-open dans les assets du projet biliotheque, ajouter ,{\u0026quot;glob\u0026quot;: \u0026quot;**/*\u0026quot;,\u0026quot;input\u0026quot;: \u0026quot;projects/framework/public\u0026quot;,\u0026quot;output\u0026quot;: \u0026quot;/public/\u0026quot;},{\u0026quot;glob\u0026quot;: \u0026quot;**/*\u0026quot;,\u0026quot;input\u0026quot;: \u0026quot;@gouvfr/dsfr/dist/favicon\u0026quot;,\u0026quot;output\u0026quot;: \u0026quot;/dsfr/\u0026quot;} dans les styles du projet biliotheque, ajouter ,\u0026quot;@gouvfr/dsfr/dist/dsfr/dsfr.min.css\u0026quot;,\u0026quot;@gouvfr/dsfr/dist/utility/utility.main.min.css\u0026quot;,\u0026quot;projects/framework/public/styles.scss\u0026quot; dans les scripts du projet biliotheque, ajouter \u0026quot;@gouvfr/dsfr/dist/dsfr.module.min.js\u0026quot; éditer le fichier package.json pour récupérer la balise author récupérer les scripts install-1-cypress, install-2-cypress, bibliotheque-start et e2e tester ce projet en installant Cypress avec les deux script d\u0026rsquo;installation en démarrant la démarche avec la commande npm run bibliotheque-start en lançant _Cypress _ et exécutant les tests avec la commande npm run e2e généraliser à tous les projets importer le code de tous les projets tester tous les projets avec les tests Cypress relire les logs et vérifier les screenshots générés réaliser les tests spéciaux : vérifier la bonne validation HTML des pages durant les tests E2E\nen retirant la configuration spécifique du projet en commentant la partie configuration du code require('cypress-html-validate/plugin').install(on, {...}) dans le fichier cypress.config.ts relançant les tests E2E sur le projet bibliotheque qui devrait échouer tester les build-prod\nexécuter un npm run all-build-prod exécuter un npm run http-start exécuter tous les tests E2E tester la génération de la documentation\nrecopier les fichiers tsconfig.doc.json et le fichier tsconfig.doctest.json présents dans les répertoires de projet depuis l\u0026rsquo;ancienne arborescence vers la nouvelle exécuter npm run all-compodoc démarrer le serveur de documentation avec 1-conception\\startServer.cmd vérifier la présence et la qualité de la documentation depuis le site documentaire (lien dans le chapitre §3.1) couverture de code avec les tests E2E\ndepuis la version Angular-18 (juillet 2024), l\u0026rsquo;instrumentation via les fonctionnalités de WebPack n\u0026rsquo;est plus possible (changement du builder Angular). Donc la couverture de code n\u0026rsquo;est plus possible pour le moment. lignes de code (CLOC)\nremettre en place les scripts cloc* dans le package.json exécuter les deux commandes cloc* et en vérifier la cohérence manuellement remettre Maven en place\nà modifier : récupérer le pom.xml et le répertoire assembly pour tester : exécuter la commande mvn clean install exécuter la commande mvn clean install -P qualimetrie tester le build Maven nominal /!\\ retirer le fichier de conf et le bouchonAPI du ZIP généré par Maven\ntester le build Maven nominal avec le profile qualimetrie\nPour vérifier que cela fonctionne, exécuter les commandes :\nde build de la démarche bibliotheque avec la commande npm run bibliotheque-build-prod d\u0026rsquo;analyse de la démarche bibliotheque avec la commande npm run bibliotheque-analyseBundle de génération de la documentation de la démarche bibliotheque avec la commande npm run bibliotheque-compodoc de démarrage de la démarche bibliotheque avec la commande npm run bibliotheque-start de démarrage des tests E2E de la démarche bibliotheque avec la commande npm run bibliotheque-e2e 3.34.2.3 - Montée de version Angular _ Cette procédure est à mettre à jour depuis l\u0026rsquo;abandon de YARN_ La DINUM publie régulièrement des versions de la librairie System Design de l\u0026rsquo;état. Une montée de version est à réaliser de la manière suivante :\ndans une commande DOS et pas Git4windows, démarrer l\u0026rsquo;outil d\u0026rsquo;upgrade de Yarn avec la commande (s\u0026rsquo;il n\u0026rsquo;est pas installé, yarn plugin import interactive-tools) yarn upgrade-interactive attendre que toutes les libs soient chargées sélectionner (carré vert) la dernière version de la librairie DSFR taper ENTRER pour valider les sélections et lancer l\u0026rsquo;installation vérifier que le projet front fonctionne en exécutant un build complet : npm run all-build-prod exécutant les tests npm run e2e vs npm run xx-start avec xx chacune des démarches exécutant les tests avec couverture de code npm run e2e vs npm run xx-startcoverage avec xx chacune des démarches 3.34.2.4 - Montée de version DSFR _ Cette procédure est à mettre à jour depuis l\u0026rsquo;abandon de YARN_\nLa mise à jour de la dépendance DSFR est régulière. Elle est à réaliser de la manière suivante :\ndans une commande DOS et pas Git4windows, démarrer l\u0026rsquo;outil d\u0026rsquo;upgrade de Yarn avec la commande (s\u0026rsquo;il n\u0026rsquo;est pas installé, yarn plugin import interactive-tools) yarn upgrade-interactive attendre que toutes les libs soient chargées sélectionner (carré vert) la version à installer dans la colonne Range pour la librairie DSFR taper ENTRER pour valider les sélections et lancer l\u0026rsquo;installation vérifier que le projet front fonctionne en exécutant un build complet : npm run all-build-prod exécutant les tests npm run e2e vs npm run xx-start avec xx chacune des démarches exécutant les tests avec couverture de code npm run e2e vs npm run xx-startcoverage avec xx chacune des démarches pour chaque composant HTML de la DSFR utilisé dans l\u0026rsquo;application, vérifier la structure HTML de chacun (La structure évolue. La documentation aussi. Mais aucun guide de migration n\u0026rsquo;existe) : Composant(s) PSL Composant DSFR Adaptation(s) contenu/contenuautocompletion composants/champ-de-saisie valide vis-à-vis du chapitre \u0026ldquo;Autres types de champs\u0026rdquo; contenu/contenucase composants/case-a-cocher valide vis-à-vis du chapitre \u0026ldquo;Pour les développeurs\u0026rdquo; contenu/contenudate composants/champ-de-saisie valide vis-à-vis du chapitre \u0026ldquo;Autres types de champs\u0026rdquo; contenu/contenudocuments composants/telechargement-de-fichier valide vis-à-vis du chapitre \u0026ldquo;Carte\u0026rdquo; contenu/contenufindemarchenonconnecte composants/groupe-de-boutons valide vis-à-vis du chapitre \u0026ldquo;Tailles\u0026rdquo; contenu/contenulistefinie composants/liste-deroulante valide vis-à-vis du chapitre \u0026ldquo;État de succès\u0026rdquo; contenu/contenuparagraphe composants/mise-en-avant valide vis-à-vis du chapitre \u0026ldquo;Structure\u0026rdquo; mais le composant paragraphe ne gère pas de titre ou de bouton disponibles les callout. Si cela est, un jour, nécessaire, il faudra créer un composant dédié différent de paragraphe contenu/contenuparagraphe composants/mise-en-exergue valide vis-à-vis du chapitre \u0026ldquo;Structure\u0026rdquo; contenu/contenuradio composants/bouton-radio/ valide vis-à-vis des chapitre \u0026ldquo;Liste horizontale\u0026rdquo; (pour la structure) et \u0026ldquo;Pour les développeurs\u0026rdquo; (pour les styles valid et error) contenu/contenusaisie composants/champ-de-saisie valide vis-à-vis du chapitre \u0026ldquo;États erreur et succès\u0026rdquo; sauf une modification assumée : Dans la documentation, les messages de validation (valid ou error) sont affichés, dans tous les composants, dans une DIV contenant des P sauf le composant de saisie. Pour ne pas dupliquer/multiplier les composants, la même structure est utilisée pour le composant de saisie malgré ce que dit la documentation. La seule concession est l\u0026rsquo;usage d\u0026rsquo;un P pour invoquer le composant data-fmk-messagesvalidation. contenu/contenusaisielongue composants/champ-de-saisie valide vis-à-vis du chapitre \u0026ldquo;Zone de texte - textarea\u0026rdquo; sauf une modification assumée : Dans la documentation, les messages de validation (valid ou error) sont affichés, dans tous les composants, dans une DIV contenant des P sauf le composant de saisie. Pour ne pas dupliquer/multiplier les composants, la même structure est utilisée pour le composant de saisie malgré ce que dit la documentation. La seule concession est l\u0026rsquo;usage d\u0026rsquo;un P pour invoquer le composant data-fmk-messagesvalidation. contenu/contenuuploaddocument composants/ajout-de-fichier invalide car le composant PSL est plus riche que celui de la DSFR. Il ne supporte pas le drag\u0026amp;drop. Donc la balise INPUT est masquée et s\u0026rsquo;affiche, à la place, une zone de drag\u0026amp;drop. De plus, la structure du label est enrichie avec un second fr-hint-text pour différencier l\u0026rsquo;aide à la saisie des contraintes de document (type et taille). contenu/messagesvalidation - valide vis-à-vis du composant DSFR radio et liste déroulante conteneurPages/fildariane composants/indicateur-d-etapes valide modale/connexionbrouillon modeles/page-de-connexion valide en retirant beaucoup d\u0026rsquo;éléments du premier chapitre morceaudepage/entete composants/en-tete valide vis-à-vis des chapitres combinés de la documentation morceaudepage/entete composant/selecteur-de-langue valide morceaudepage/entete/messageglobal composants/alerte valide morceaudepage/pieddepage composants/pied-de-page invalide car construit depuis le pied de page de la vrai PSL 3.34.2.5 - Montée de version des autres dépendances Node _ Cette procédure est à mettre à jour depuis l\u0026rsquo;abandon de YARN_\nLa mise à jour des dépendances autres que celles d\u0026rsquo;Angular et DSFR est régulière. Elle est à réaliser de la manière suivante :\ndans une commande DOS et pas Git4windows, démarrer l\u0026rsquo;outil d\u0026rsquo;upgrade de Yarn avec la commande (s\u0026rsquo;il n\u0026rsquo;est pas installé, yarn plugin import interactive-tools) yarn upgrade-interactive attendre que toutes les libs soient chargées sélectionner (carré vert) les versions à installer dans la colonne Range sauf la librairie DSFR taper ENTRER pour valider les sélections et lancer l\u0026rsquo;installation vérifier que le projet front fonctionne en exécutant un build complet : npm run all-build-prod exécutant les tests npm run e2e vs npm run xx-start avec xx chacune des démarches exécutant les tests avec couverture de code npm run e2e vs npm run xx-startcoverage avec xx chacune des démarches 3.34.3 - Mise à jour des outils 3.34.3.1 - VSCode La mise à jour de VSCode est opportuniste car elle se fait dès que l\u0026rsquo;IDE annonce la sortie d\u0026rsquo;une nouvelle version. Elle est à réaliser de la manière suivante :\ntélécharger l\u0026rsquo;archive contenant l\u0026rsquo;IDE depuis Internet (site internet ou depuis l\u0026rsquo;IDE) dézipper l\u0026rsquo;archive dans le répertoire des outils en faisant attention à conserver le numéro de version de l\u0026rsquo;IDE dans le nom du répertoire modifier le raccourci vers l\u0026rsquo;IDE en y changeant le numéro de version mettre à jour la page contenant la backlog et programmer la prochaine mise à jour pour le prochain trimestre modifier la version à installer dans les chapitre 3.2 3.34.3.2 - Eclipse La mise à jour d\u0026rsquo;Eclipse est régulière car une version sort tous les trimestres. Elle est à réaliser de la manière suivante :\ntélécharger l\u0026rsquo;archive contenant la version Eclipse IDE for Java Developers de l\u0026rsquo;IDE depuis le site Internet officiel dézipper l\u0026rsquo;archive dans le répertoire des outils en faisant attention à conserver le numéro de version de l\u0026rsquo;IDE dans le nom du répertoire modifier le raccourci vers l\u0026rsquo;IDE en y changeant le numéro de version accepter, au démarrage, qu\u0026rsquo;Eclipse transforme le workspace pour le rendre compatible avec la nouvelle version de l\u0026rsquo;IDE (au besoin, recréer un workspace avec la procédure ci-dessous) après le démarrage, il est nécessaire d\u0026rsquo;installer le plugin SonarLint mettre à jour la page contenant la backlog et programmer la prochaine mise à jour pour le prochain trimestre modifier la version à installer dans les chapitre 3.2 Si, à la montée de version Eclipse, le workspace n\u0026rsquo;est plus utilisable (par exemple, raccourci cassé à la montée de version 2022-12), il faut :\narrêter Eclipse renommer le répertoire du workspace existant en le suffixant de -old démarrer Eclipse (il va recréer un répertoire puisqu\u0026rsquo;il est en paramètre de l\u0026rsquo;exécutable dans le raccourci - cf. procédure d\u0026rsquo;installation du poste) configurer : General \u0026gt; Workspace : définir l\u0026rsquo;encoding UTF8 et le délimiteur Unix pour tout nouveau fichier Maven : définir l\u0026rsquo;installation externe à Eclipse Maven : définir le chemin du fichier de configuration et cliquer sur le bouton Update settings Java \u0026gt; Installed JRE : ajouter le dernier JDK en date, en faire la version par défaut et supprimer tout autre installation Java Java \u0026gt; Code style \u0026gt; Formatter : importer le fichier de configuration présent dans la documentation Java \u0026gt; Editor \u0026gt; Save actions : configurer chaque formulaire jusqu\u0026rsquo;à obtenir cette configuration General \u0026gt; Keys : créer vos raccourcis si vous en paramétrer habituellement (²² pour rerun Junit test par exemple) Run/Debug \u0026gt; console : désactiver la limite de sortie de la console Run/Debug \u0026gt; Launching : cocher always pour la sauvegarde des fichiers en cours d\u0026rsquo;édition (première question du formulaire en version 2023-06) Run/Debug \u0026gt; Perspective : cocher always pour l\u0026rsquo;ouverture de la prespective au lancement (première question du formulaire en version 2023-06) Version control \u0026gt; Git \u0026gt; Project : décocher toutes les cases SonarLint \u0026gt; File exclusions : ajouter une exclusion *.rdb réorganiser les perspectives Java et Debug pour faire apparaitre les vues progress au besoin, comparer les fichiers présents dans _.metadata.plugins\\org.eclipse.core.runtime.settings_ arrêter Eclipse créer une archive ZIP du répertoire .metadata et la conserver dans la documentation supprimer le répertoire du workspace précédent suffixé par -old importer les projets du socle qui ne sont pas de type POM (ceux qui n\u0026rsquo;ont pas d\u0026rsquo;enfant) 3.34.3.3 - Java La mise à jour de Java est régulière car une version sort régulièrement. Elle est à réaliser de la manière suivante :\ntélécharger l\u0026rsquo;archive contenant le nouveau JDK depuis le site Internet officiel dézipper l\u0026rsquo;archive dans le répertoire des outils en faisant attention à conserver le numéro de version du JDK dans le nom du répertoire ouvrir les paramètres système pour modifier les variables d\u0026rsquo;environnement (rechercher modifier les variables d\u0026rsquo;environnement système dans le menu démarrer) modifier la variable d\u0026rsquo;environnement JAVA_HOME vérifier que JAVA_HOME fait partie de path fermer les fenêtres de commandes déjà ouvertes et ouvrir une nouvelle fenêtre de commandes vérifier que la version de Java est bien prise en compte avec la commande java -version vérifier que le projet socle fonctionne en exécutant un build nominal mvn clean install ajouter le certificat racine de l\u0026rsquo;entreprise (si nécessaire) dans le nouveau JDK avec les informations du chapitre 3.2.7 ajouter le certificat TLS newPSL dans le nouveau JDK avec les informations du chapitre 3.2.8.1 (rechercher Importer le certificat racine) dans le raccourci démarrant Eclipse, changer le chemin du JDK modifier la version du JDK dans la description du raccourci présente au chapitre 3.2.5.2 dans le workspace d\u0026rsquo;Eclipse, ajouter le nouveau JDK et retirer l\u0026rsquo;ancien (Window \u0026gt; Preferences \u0026gt; Java \u0026gt; Installed JRE) revoir l\u0026rsquo;intéret de l\u0026rsquo;argument _-XX:+EnableDynamicAgentLoading _ dans 2-code/socle/pom.xml et dans tous les .launch qui permet de désactiver les warning s\u0026rsquo;affichant durant les tests automatisés (cf. https://github.com/mockito/mockito/issues/3037 et https://openjdk.org/jeps/451) de l\u0026rsquo;argument \u0026ndash;enable-preview non activable actuellement car Eclipse-202309 ne le supporte pas pour le JDK-21. mettre à jour la page contenant la backlog et programmer la prochaine mise à jour pour le prochain trimestre modifier la version à installer dans les chapitre 3.2 3.34.3.4 - Node _ Cette procédure est à mettre à jour depuis l\u0026rsquo;abandon de YARN _\nLa mise à jour de Node/npm est régulière car une version sort régulièrement. Elle est à réaliser de la manière suivante :\ntélécharger l\u0026rsquo;archive contenant la nouvelle version de Node depuis le site Internet officiel en version Windows Binary (.zip) et 64 bits dézipper l\u0026rsquo;archive dans le répertoire des outils en faisant attention à conserver le numéro de version de Node dans le nom du répertoire ouvrir les paramètres système pour modifier les variables d\u0026rsquo;environnement (rechercher modifier les variables d\u0026rsquo;environnement système dans le menu démarrer) modifier la variable d\u0026rsquo;environnement NODE_HOME vérifier que NODE_HOME fait partie de path redémarrer la console GIT et VSCode pour prendre en compte la modification de la variable d\u0026rsquo;environnement si un outil de sécurité modifie l\u0026rsquo;autorité de certification sur l\u0026rsquo;URL https://registry.npmjs.org/, il faut (source) : accéder au site https://registry.npmjs.org/ avec le navigateur Chrome afficher les détails du certificat télécharger le certificat racine de l\u0026rsquo;outil dans un fichier au format CRT exécuter la commande suivante : set NODE_EXTRA_CA_CERTS=%JAVA_HOME%\\lib\\security\\xxx.crt vérifier les versions installées avec les commandes node -v et npm -v dans une commande DOS (et pas git4windows), utiliser la commande yarn upgrade-interactive pour mettre à jour la dépendance @types/node à la version de l\u0026rsquo;outil Node installée mettre à jour le fichier 2-code/front/pom.xml pour mettre à jour la version de Node avec la version affichée dans la console, de Npm avec la version affichée dans la console, vérifier que le projet front fonctionne en exécutant un npm install un simple démarrage avec npm run etatcivil-start un build complet via Node avec la commande npm run all-build-prod un build complet via Maven avec la commande mvn clean install -P qualimetrie mettre à jour la page contenant la backlog et programmer la prochaine mise à jour pour le prochain trimestre modifier la version à installer dans les chapitre 3.2 3.34.3.5 - Maven La mise à jour de Maven est régulière car une version sort régulièrement. Elle est à réaliser de la manière suivante :\ntélécharger l\u0026rsquo;archive contenant la nouvelle version de maven depuis le site Internet officiel dézipper l\u0026rsquo;archive dans le répertoire des outils en faisant attention à conserver le numéro de version dans le nom du répertoire ouvrir les paramètres système pour modifier les variables d\u0026rsquo;environnement (rechercher modifier les variables d\u0026rsquo;environnement système dans le menu démarrer) modifier la variable d\u0026rsquo;environnement MAVEN_HOME vérifier que MAVEN_HOME fait partie de path remplacer le fichier MAVEN_HOME/conf/settings.xml du nouveau Maven par celui de l\u0026rsquo;ancien fermer toutes les fenêtres de commande et en ouvrir une nouvelle vérifier la version de Maven en exécutant la commande mvn -v vérifier que le projet socle fonctionne en exécutant un build nominal mvn clean install dans Eclipse, la version embarquée de Maven est utilisée. Mais il faut pointer sur le même fichier de configuration (Window \u0026gt; Preferences \u0026gt; Maven \u0026gt; User Settings) une fois le workspace du projet modifié, il est certainement nécessaire de modifier le workspace des autres projets présents sur le poste de développement mettre à jour la page contenant la backlog et programmer la prochaine mise à jour pour le prochain trimestre modifier la version à installer dans les chapitre 3.2 3.34.4 - Documentation du Socle Depuis l\u0026rsquo;usage de DependencyTrack, les rapports HTML DependencyCheck n\u0026rsquo;ont plus de sens. La veille sécuritaire (recherche et analyses) se fait donc via l\u0026rsquo;outil DependencyTrack (cf. §3.34.5).\nLa documentation générée pour le Socle a néanmoins encore du sens.\n3.34.4.1 - Rapports du Socle La génération des rapports a particulièrement de sens à être exécutée après les montées de version des dépendances du Socle.\nPuis il suffit d\u0026rsquo;utiliser la commande mvn clean install -P qualimetrie. Cette commande exécute l\u0026rsquo;ensemble complet de toutes les actions possibles :\nexécution des tests automatisés avec couverture packaging des livrables des sources (en jar-source) des javadoc (en jar-javadoc](https://maven.apache.org/plugins/maven-javadoc-plugin/jar-mojo.html)) génération de rapport de couverture de code copie de certains éléments dans la partie documentaire du dépôt : dans la page des liens documentaires Une fois les rapports générés, ces derniers sont consultables immédiatement dans la page des liens documentaires.\n3.34.4.2 - Tests de sécurité avec OWASP ZAP Pour installer l\u0026rsquo;outil :\ntélécharger, depuis le site officiel, l\u0026rsquo;archive ZAP_2.11.1_Crossplatform.zip ouvrir l\u0026rsquo;archive téléchargée avec 7zip pour modifier le fichier lib/log4j-core-2.15.0.jar en log4j-core-2.15.0.abc (car certains outils de protection refusent l\u0026rsquo;écriture sur disque de ce fichier) extraire le contenu de l\u0026rsquo;archive dans le répertoire outils ouvrir l\u0026rsquo;archive xxxxxx/ZAP_2.xx.x/zap-2.xx.x.jar avec 7zip et modifier, dans le fichier META_INF/MANIFEST.MF, le nom du jar de log4j Pour utiliser OWASP ZAP :\ndémarrer l\u0026rsquo;outil via le script zap.bat sélectionner la session présente dans le projet documentaire (nommée _sessionOwaspZap décrite plus bas) dans la liste déroulante en haut à gauche, sélectionner la valeur mode standard dans la fenêtre principale, cliquer sur Automated scan saisir l\u0026rsquo;URL http://dev-psl.guillaumetalbot.com/mademarche/bibliotheque/ avec les spider ajax (avec Chrome headless) et traditionnel lancer l\u0026rsquo;audit (plusieurs dizaines de minutes) analyser les résultats Pour information, la session créée a été paramétrée avec :\nl\u0026rsquo;exclusion des sites https://.* dans exclure du proxy, exclure du balayage et exclure du robot d\u0026rsquo;indexation l\u0026rsquo;inclusion, dans le contexte, des sites http://dev-psl.guillaumetalbot.com/mademarche, http://dev-psl.guillaumetalbot.com/mademarche.*, http://localhost:8080 et http://localhost:8080.* l\u0026rsquo;import du swagger des APIs 3.34.5 - Suivi de sécurité avec DependencyTrack 3.34.5.1 - Installation/réinstallation et préparation d\u0026rsquo;une instance locale de DependencyTrack procédure issue de la documentation officielle\n!!! ATTENTION A PREVOIR 2Go DE DISQUE ET, AU MINIMUM, 45 MINUTES DE TEMPS D\u0026rsquo;EXECUTION DE L\u0026rsquo;OUTIL POUR SON INITIALISATION (téléchargement de 1,2Go de JSON du NIST compressé en 70Mo de GZ) !!!\nPour installer DependencyTrack, exécuter les actions suivantes :\nSortir de tout réseau nécessitant un proxy pour accéder à Internet Télécharger, depuis le site GitHub la dernière release nommée dependency-track-bundled.jar. Placer le livrable dans le répertoire 2-code\\securite\\dependencyTrack (écraser l\u0026rsquo;existant s\u0026rsquo;il est présent) Ouvrir une ligne de commande dans ce répertoire Démarrer l\u0026rsquo;application avec le script 2-code/socle/securite/dependencyTrack/dependencyTrack.sh ou la commande java -Xmx4G -jar dependency-track-bundled.jar -port 9999 (testé en 04/2024 avec Java-21) Ignorer les avertissements concernant le fichier id.system Ne rien arrêter tant que les logs indiquent des téléchargements et du parsing de fichier Pour simplement mettre à jour DependencyTrack, exécuter les étapes suivantes :\nVérifier son bon fonctionnement en cliquant sur ce lien menant à l\u0026rsquo;application démarrée localement Se connecter avec le compte admin et le nouveau mot de passe défini (à sauvegarder dans un KeePass) Pour initialiser DependencyTrack la première fois, exécuter les étapes suivantes :\nVérifier son bon fonctionnement en cliquant sur ce lien menant à l\u0026rsquo;application démarrée localement Se connecter avec le compte admin et le mot de passe admin Changer le mot de passe comme l\u0026rsquo;impose l\u0026rsquo;application Se reconnecter avec le compte admin et le nouveau mot de passe défini (à sauvegarder dans un KeePass) Accéder à la page administration \u0026gt; Access management \u0026gt; Teams Créer une équipe nommée AnalyseLocale Cliquer sur la ligne de l\u0026rsquo;équipe créée Mettre la clef d\u0026rsquo;API (dans la suite de la procédure, elle se nomme XXCLEFAPIXX) Ajouter les droits BOM_UPLOAD et VIEW_PORTFOLIO Accéder à la page Policy Management Créer les policy suivantes 1 (ne semble pas fonctionnel au 11/2023) : Name : Composant avec version majeure de retard Operator : any Violation state : Warn Conditions : Version Distance \u0026gt; 0 1 0 0 2 : Name : Composant de plus d\u0026rsquo;un an Operator : any Violation state : Inform Conditions : Age \u0026gt; P1Y 3 (ne semble pas fonctionnel au 11/2023) : Name : Composant pas à la dernière version Operator : any Violation state : Inform Conditions : Version Distance \u0026gt; 0 0 0 1 4 : Name : Licence CopyLeft Interdite Operator : any Violation state : Fail Conditions : Licence group is copylef 5 : Name : Licence NonCommeciale Interdite Operator : any Violation state : Fail Conditions : Licence group is Nom-Commercial 3.34.5.2 - Audit des projets SOCLE et FRONT Réaliser une analyse du socle en exécutant les étapes suivantes :\nDans le répertoire 2-code/socle, exécuter la commande mvn org.cyclonedx:cyclonedx-maven-plugin:makeAggregateBom Vérifier que DependencyTrack s\u0026rsquo;exécute Exécuter la commande curl -X \u0026quot;POST\u0026quot; http://localhost:9999/api/v1/bom -H 'Content-Type: multipart/form-data' -H \u0026quot;X-Api-Key: XXCLEFAPIXX\u0026quot; -F \u0026quot;autoCreate=xxAUTOxx\u0026quot; -F \u0026quot;projectName=newPslSocle\u0026quot; -F \u0026quot;projectVersion=xxVERSIONxx\u0026quot; -F bom=@target/bom.xml avec xxVERSIONxx une date au format yyyyMM (par exemple 202404 pour avril 2024) avec XXCLEFAPIXX la clef créée plus tôt (ou à récupérer dans DependencyTrack \u0026gt; Access Management \u0026gt; Teams \u0026gt; AnalyseLocale) Vérifier que la réponse soit au format {\u0026quot;token\u0026quot;:\u0026quot;eef176b8-feea-4786-97e4-817e97763a2a\u0026quot;} Dans l\u0026rsquo;IHM de DependencyTrack, vérifier la présence du projet dans la page Projects Réaliser une analyse du front en exécutant les commandes suivantes !!!!!!!NE FONCTIONNE PAS POUR LE MOMENT (04/2024) !!!!!!!!!!! :\nDans le répertoire 2-code/front, depuis une ligne de commande DOS, exécuter les commandes suivantes : Pour installer globalement l\u0026rsquo;outil d\u0026rsquo;analyse npm install --global @cyclonedx/cyclonedx-npm Pour créer un package-lock.json pour les besoins de l\u0026rsquo;analyse npm install --package-lock-only --force Pour générer le BOM du front cyclonedx-npm --output-format XML --output-file bom.xml Supprimer le répertoire node_modules Supprimer le fichier package-lock.json Créer le projet newPslFront avec la commande suivante (en remplaçant la clef) curl -X \u0026quot;POST\u0026quot; http://localhost:8080/api/v1/bom -H 'Content-Type: multipart/form-data' -H \u0026quot;X-Api-Key: XXCLEFAPIXX\u0026quot; -F \u0026quot;autoCreate=true\u0026quot; -F \u0026quot;projectName=newPslFront\u0026quot; -F \u0026quot;projectVersion=1.0.0\u0026quot; -F bom=@bom.xml 3.34.5.3 - Raffrachir un audit Pour relancer (après modification d\u0026rsquo;un paramètre ou évolution du BOM) une analyse, exécuter la commande en y remplaçant la clef d\u0026rsquo;API, le nom du projet et le chemin vers le bom.xml : curl -X \u0026quot;POST\u0026quot; http://localhost:9999/api/v1/bom -H 'Content-Type: multipart/form-data' -H \u0026quot;X-Api-Key: XXCLEFAPIXX\u0026quot; -F \u0026quot;projectName=newPslXXXX\u0026quot; -F \u0026quot;projectVersion=1.0.0\u0026quot; -F bom=@target/bom.xml\n3.34.5.4 - Analyse Pour information, le code Java du Socle se base sur de nombreuses dépendances toute sous licence. Certaines de ces licences autorisent un usage en milieu professionnel mais d\u0026rsquo;autres non : elles imposent que le code dépendant soit tout aussi OpenSource que la dépendance elle-même. Ceux sont les licences Copyleft.\nEtudier une analyse DependencyTrack avec les consignes suivantes :\nDans l\u0026rsquo;IHM de DependencyTrack, accéder à la page Projects \u0026gt; newPslSocle Vérifier la présence de licence interdites (commerciale ou copyLeft) dans l\u0026rsquo;onglet Policy violations Vérifier si la version est la plus récente Vérifier si la licence a évolué récemment (à l\u0026rsquo;échelle du rythme des release de ce composant) Vérifier si la dépendance est directe ou pas. Si elle est indirecte, peut-on s\u0026rsquo;en passer ? Commenter chaque violation pour un suivi Vérifier la présence de vulnérabilité dans l\u0026rsquo;onglet Audit Vulnerabilities Traiter les vulnérabilités par sévérité décroissantes : Si la faille existe et qu\u0026rsquo;il est possible de la combler en changeant le code appelant ou en modifiant la dépendance directe (et uniquement la dépendance directe !), la correction est à faire. Si la faille existe et qu\u0026rsquo;il n\u0026rsquo;est pas possible de la combler, autant savoir qu\u0026rsquo;elle existe et surveiller de près la dépendance fautive pour réaliser une mise à jour rapidement. Si la faille n\u0026rsquo;existe pas, il est possible de l\u0026rsquo;ignorer dans l\u0026rsquo;outil (sans oublier de mettre un commentaire) Systématiquement, commenter chaque vulnérabilité pour un suivi Un bon référentiel des licences est disponible sur Wikipedia\n"
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.35procedureselastic/",
	"title": "3.35 Procédures-elastic",
	"tags": [],
	"description": "",
	"content": "\r3.35.1 - Comment mettre en place et utiliser la pile Elastic 3.35.2 - Comment faire évoluer la pile Elastic 3.35.3 - Kibana - ajouter un champ calculé 3.35.4 - Pile Elastic - montée de version 3.35.5 - Kibana - astuces diverses et informations à connaître Ce chapitre contient des procédures et des aides pour des manipuler la pile Elastic.\n3.35.1 - Comment mettre en place et utiliser la pile Elastic Pour plus de détails sur la pile Elastic elle-même, cette dernière est décrite au chapitre §2.7.2.\nPour télécharger et installer les binaires associés à la pile Elastic, il suffit d\u0026rsquo;exécuter la commande . ./elastic.sh INSTALLATION. Ceci va :\ntélécharger les binaires depuis Internet (via l\u0026rsquo;éventuel proxy configuré dans le script) placer les archives dans \u0026hellip;/socle/.elastic/zip extraire les archives dans \u0026hellip;/socle/.elastic/bin Pour démarrer tous les processus, il suffit d\u0026rsquo;exécuter la commande . ./elastic.sh DEMARRER_TOUT. Ceci va :\ndémarrer ElasticSearch démarrer Kibana importer les configurations par défaut de Kibana si c\u0026rsquo;est le premier démarrage (en se basant sur la présence du répertoire de données \u0026hellip;/socle/.elastic/bin) démarrer Filebeat Pour tout arrêter, la commande . ./elastic.sh ARRETER_TOUT est disponible.\nEn cas de problème, de modification profonde ou de modification de l\u0026rsquo;import des données depuis Filebeat, il est possible de supprimer toutes les données avec la commande . ./elastic.sh PURGE.\n3.35.2 - Comment faire évoluer la pile Elastic Concernant ElasticSearch et Filebeat, toutes les configurations sont dans des fichiers présents dans le répertoire socle\\services-cloud\\service-elastic. Ces fichiers sont utilisés dans les scripts de démarrage de ces applicatifs. Concernant Kibana, outre les fichiers de configuration disponible au même endroit que ceux de ElasticSearch et Filebeat, existe un fichier configuration.ndjson. Ce fichier est un export des saved objects de Kibana.\nA chaque création d\u0026rsquo;un objet (configuration globale, requête sauvegardée, visualisation, tableau de bord, \u0026hellip;), il est nécessaire de faire un export de tous les objets personnalisés depuis la création de l\u0026rsquo;instance. Ceci comprend les objets précédemment importés.\nLe fichier exporté doit sauvegardé en tant que nouveau configuration.ndjson. Avant de commiter ce fichier, il est impératif de s\u0026rsquo;assurer que rien n\u0026rsquo;a été perdu durant l\u0026rsquo;export ou modifié dans l\u0026rsquo;instance avant l\u0026rsquo;export.\n3.35.3 - Kibana - ajouter un champ calculé Dans les versions récentes de Kibana, il est possible de définir, depuis kibana, des champs dont la valeur est calculée à partir de celle des autres champs. Ceci se nomme runtime field (documentation).\nPour créer (ou modifier) un tel champ, il faut accéder à la page stackmanagement \u0026gt; data views \u0026gt; logs-* \u0026gt; Fields. Depuis cette page, les champs calculés sont marqués d\u0026rsquo;une icone supplémentaire à côté de leur nom et sont nommés psl.runtime.xxx.\nVoici un exemple de script :\nname=psl.runtime.nomApplication type=keyword setValue= // // Crée un champ \u0026#34;nomFichierLog\u0026#34; à partir du chemin du fichier de log // // toujours vérifié la présence du champs def nomAttributFichierLog = \u0026#39;log.file.path\u0026#39;; if (doc.containsKey(nomAttributFichierLog)) { // lecture des valeurs def fichierLog = doc[nomAttributFichierLog].value; // extraction via une regex def m = /^.*[\\\\\\/]log_([^\\\\\\/]*)\\-[0-9]*\\.log/.matcher(fichierLog); if (m.matches()){ // Publication de la valeur emit(m.group(1)); } } ou\nname=psl.runtime.codeException type=keyword setValue= // toujours vérifié la présence du champs def nomAttributSeverite = \u0026#39;psl.severite\u0026#39;; def nomAttributMessage = \u0026#39;psl.message\u0026#39;; // Si c\u0026#39;est bien une erreur (sinon, on passe pour les performances) if (doc.containsKey(nomAttributSeverite) \u0026amp;\u0026amp; \u0026#34;\u0026#34;+doc[nomAttributSeverite] == \u0026#34;[ERROR]\u0026#34; \u0026amp;\u0026amp; doc.containsKey(nomAttributMessage)){ // lecture du message def message = doc[nomAttributMessage]; if (message.contains(\u0026#39;java.lang.RuntimeException: boum\u0026#39;)) { emit(\u0026#34;NOTIFICATION_01_boum\u0026#34;); } } D\u0026rsquo;autres exemples sont disponible (ici)[https://elastic-content-share.eu/elastic-runtime-field-example-repository/].\n3.35.4 - Pile Elastic - montée de version La montée de version passe par les étapes suivantes (les commandes s\u0026rsquo;exécutent depuis le répertoire 2-code/socle) :\nDétruire la version actuelle : exécuter les commandes suivantes echo \u0026#34;purger les logs\u0026#34; . ./outils.sh PURGE LOG echo \u0026#34;désinstaller complètement la pile Elastic\u0026#34; . ./elastic.sh DESINSTALLATION vérifier la bonne désinstallation en confirmant la suppression du répertoire 2-code/socle/.elastic Rechercher la dernière version disponible de chaque élément (normalement identique) de la pile Elastic sur les sites de téléchargement d\u0026rsquo;ElasticSearch de téléchargement de FileBeat de téléchargement de Kibana Modifier la version à utiliser déchiffrer le fichier contenant les variables des scripts du socle avec la commande gpg -dq variablesPourScripts.properties.gpg éditer le fichier variablesPourScripts.properties pour y modifier la variable versionElastic avec la valeur définie précédemment rechiffrer le fichier avec la commande gpg -c variablesPourScripts.properties Réinstaller et redémarrer la pile Elastic sortir de tout VPN (pour ne pas avoir de proxy entre le poste et Internet) exécuter les commandes echo \u0026#34;installer\u0026#34; . ./elastic.sh INSTALLATION echo \u0026#34;démarrer la pile\u0026#34; . ./elastic.sh DEMARRER_TOUT Vérifier le bon fonctionnement récupérer le login et le mot de passe du compte elastic dans les logs de la commande précédente Accéder à Kibana avec [http://localhost:5601](ce lien) et le compte précédemment récupéré Vérifier la bonne intégration des logs Générer une quantité \u0026ldquo;limitée\u0026rdquo; de logs en exécutant, depuis le répertoire 2-code/socle, les commandes mvn clean install -T 1C -DskipTests . ./demarrerTout.sh Vérifier, dans la page Discover de Kibana, la présence de logs Assurer le suivi en modifiant la page pour y inscrire la nouvelle version de la pile Elastic la date de la mise à jour la date de la prochaine mise à jour (+3 mois) 3.35.5 - Kibana - astuces diverses et informations à connaître Au démarrage de la pile sur le poste de développement, il faut attendre quelques minutes pour que les logs soient intégrées et disponibles à travers Kibana. Si, dans l\u0026rsquo;écran Discover de Kibana, la saisie d\u0026rsquo;un filtrage temporel n\u0026rsquo;est pas disponible, c\u0026rsquo;est qu\u0026rsquo;aucune donnée n\u0026rsquo;est disponible (aucun champ d\u0026rsquo;indexation temporel n\u0026rsquo;existe). Dans les filtres de Kibana, il est possible de manipuler le temps en relatif avec des arondis comme now-1w/d signifiant maintenant moins une semaine arrondi à la journée. "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.36procedurestest/",
	"title": "3.36 Procédures-test",
	"tags": [],
	"description": "",
	"content": "\r3.36.1 - Campagnes de test 3.36.2 - C1 La vérification du build 3.36.3 - C2 Les tests du système sur le poste local 3.36.4 - C2 Les tests du système sur WSL 3.36.5 - Tests du socle 3.36.6 - Tests des applications WEB 3.36.7 - FAQ Ce chapitre contient les procédures de test\n3.36.1 - Campagnes de test Pour tout tester, il est nécessaire de réaliser plusieurs campagnes de test :\nC1/ La vérification du build C2/ Les tests du système sur le poste local C2/ Les tests du système sur WSL 3.36.2 - C1 La vérification du build Cette campagne vérifie que tous les éléments de build et de documentation sont présents :\n1/ mettre à jour les sources sur votre poste 2/ supprimer le répertoire 1-conception\\static\\documentationgeneree 3/ recompiler l\u0026rsquo;ensemble du projet en exécutant, depuis la racine du dépôt, la commande mvn clean install -P qualimetrie (sans skip ni -T 1C) 4/ vérifier la bonne génération du site avec les répertoires : TODO à compléter 3.36.3 - C2 Les tests du système sur le poste local Cette campagne vérifie le code Java pur à partir des scripts SH présents dans le répertoire 2-code/socle :\n0/ prérequis : être en mesure d\u0026rsquo;appeler les APIs SP 1/ recompiler l\u0026rsquo;ensemble du code (répertoire 2-code) 2/ démarrer l\u0026rsquo;ensemble des applications en exécutant, depuis le répertoire 2-code/socle, les commandes . ./outils.sh PROXY TRUE . ./demarrerTout.sh 3/ exécuter tous les tests décrits au chapitre §3.36.5 4/ modifier les URLs des APIs dans le code des applicatifs construits : remplacer https://admin.dev-psl.guillaumetalbot.com par https://localhost:8989 dans le fichier 2-code\\front\\dist\\mademarche\\adminpsl\\main.xxx.js 5/ démarrer un serveur WEB simpliste exposant les applicatifs avec la commande npm run http-start 6/ exécuter tous les tests décrits au chapitre §3.36.6 3.36.4 - C2 Les tests du système sur WSL Cette campagne vérifie le code Java déployé via le projet IAS :\n1/ recompiler l\u0026rsquo;ensemble du code (répertoire 2-code) 2/ démarrer les machines WSL (cf. §4.2.2) 3/ démarrer tous les applicatifs (cf. §4.2.2) 4/ mettre à jour la documentation des playbooks Créer les images SVG en exécutant, dans la machine UbuntuAnsible, depuis le répertoire 2-code/ias/ansible, la commande for f in *.yml; do ansible-playbook-grapher --include-role-tasks $f; done Copier les images générées dans le répertoire 1-conception\\static\\documentationgeneree\\ias Vérifier leur bon affichage dans la page 5/ exécuter tous les tests décrits au chapitre §3.36.5 6/ charger la base de données MongoDB en déclarant, avec l\u0026rsquo;application socle-admin toutes les démarches à tester 7/ exécuter tous les tests décrits au chapitre §3.36.6 8/ vérifier que la documentation est bien publiée et protégée par un mot de passe (compte lié au LDAP donc admin1/admin) quand on passe par le [https://admin.dev-psl.guillaumetalbot.com/documentation/](DNS d\u0026rsquo;administration) 3.36.5 - Tests du socle Pour tester toutes les fonctionnalités importantes des services, il faut :\nservices et administration (cf. liens) : service-registre : accéder à l\u0026rsquo;IHM du registre vérifier que 2 services sont présents (SERVICE-CONFIG et SERVICE-GATEWAY) vérifier que 10 socles sont présents (SOCLE-ADMINPSL, SOCLE-DBBROUILLON, SOCLE-DBCONFIGURATION, SOCLE-DBDOCUMENT, SOCLE-DBNOTIFICATION, SOCLE-REFERENTIEL, SOCLE-REFERENTIELEXTERNE, SOCLE-SECURITE, SOCLE-SOUMISSION, SOCLE-TRANSFERT) vérifier que les 12 composants ont un statut UP (colonne de droite) service-admin se connecter au service d\u0026rsquo;administration avec le compte admin1 (mot de passe admin) vérifier que les 10 instances sont bien UP (si socle-dbnotification est en alerte, vérifier que le serveur de mail est bien démarré) cliquer sur un applicatif socle-* (pas sur l\u0026rsquo;URL) pour afficher la liste des instances de cet applicatif cliquer sur l\u0026rsquo;unique instance disponible de cet applicatif pour afficher la page de détails de l\u0026rsquo;instance vérifier que la page Aperçus \u0026gt; Détails affiche bien la version de l\u0026rsquo;applicatif et les informations GIT (branche, commit et date) vérifier que les valeurs affichées dans les pages Aperçus \u0026gt; Environnement et Aperçus \u0026gt; Propriétés de configuration sont toutes masquées vérifier que la page Logging \u0026gt; Loggers permet bien de changer les niveaux de log (changer une valeur et vérifier qu\u0026rsquo;aucun message d\u0026rsquo;erreur n\u0026rsquo;apparaît) ouvrir les logs de l\u0026rsquo;instance sélectionnée (un tail -f par exemple) dans l\u0026rsquo;écran Aperçus \u0026gt; Environnement, cliquer sur le bouton Raffraîchir le contexte et confirmer attendre quelques secondes pour voir le libellé du bouton changer en Contexte rafraîchi vérifier que l\u0026rsquo;application a bien rechargé son contexte (logs Fetching config from server puis Discovery Client initialized) service-nosql démarrer MongoDBcompas et se connecter à la base de données NOsql service-redis éditer le fichier de configuration des logs de service-gateway (2-code\\socle\\services-cloud\\service-gateway\\src\\test\\resources\\logback.xml dans les sources ou /psl/applicatifs/service-gateway/logback.xml dans WSL) modifier le niveau de log de la classe org.springframework.cloud.gateway.filter.ratelimit.RedisRateLimiter en debug arrêter puis redémarrer le service-gateway pour prendre en compte la modification de la configuration surveiller les logs de la gateway avec la commande suivante tail -f log_service-gateway-1.log depuis une autre ligne de commande, exécuter 30 requêtes HTTPs d\u0026rsquo;authentification anonyme par paquets de 5 simultannées avec la commande xargs -I % -P 5 curl -k -X 'POST' 'https://localhost:8080/socle/securite/public/authentificationAnonyme' -H 'accept: application/json' -d '' \u0026lt; \u0026lt;(printf '%s\\n' {1..30}) vérifier, dans les logs, que la valeur X-RateLimit-Remaining fluctue annuler (via git par exemple) la modification dans le fichier de configuration des logs service_gateway accéder à l\u0026rsquo;UI de swagger vérifier que l\u0026rsquo;écran s\u0026rsquo;affiche sans erreur pour chacun des composants sélectionnables depuis la liste déroulante en haut à droite de la page vérifier que la liste contient tous les micro-services du socle sélectionner le composant socle-securite exécuter une authentification anonyme service-config (non testable manuellement mais est testé dans la collection de tests HTTP) API : exécuter la collection de tests HTTP (cf. documentation associée) 3.36.6 - Tests des applications WEB Pour tester les applicatifs WEB, il faut :\nadministration (cf. liens) : socle-admin : connexion : accéder à l\u0026rsquo;IHM de l\u0026rsquo;application d\u0026rsquo;administration du socle se connecter avec le compte admin1 // admin Configuration démarche : cliquer sur l\u0026rsquo;onglet Configuration démarche sélectionner une démarche et une version cliquer sur le bouton Modifier modifier le JSON (un espace dans le titre de la démarche par exemple) saisir un commentaire cliquer sur le bouton Enregistrer vérifier la présence d\u0026rsquo;une nouvelle version avec le commentaire et le nom de l\u0026rsquo;utilisateur Configuration soumission : cliquer sur l\u0026rsquo;onglet Configuration soumission sélectionner une démarche, une version et configuration cliquer sur le bouton Modifier modifier le JSON (un x dans _nomFinalDuDocument par exemple) saisir un commentaire cliquer sur le bouton Enregistrer vérifier la présence d\u0026rsquo;une nouvelle version avec le commentaire et le nom de l\u0026rsquo;utilisateur transfert cliquer sur l\u0026rsquo;onglet Transfert vérifier la présence de télédossiers (sauf si l\u0026rsquo;environnement est vierge) tester les filtres en fonction des données disponibles (à minima, vérifier l\u0026rsquo;absence d\u0026rsquo;erreur au clic sur le bouton Rechercher) administration déconnexion : cliquer sur le login en haut à droite pour se déconnecter Applications WEB démarrer l\u0026rsquo;outil Cypress avec la commande npm run cypress depuis le répertoire 2-code/front dans la fenêtre qui démarre, exécuter chaque campagne de test Pile Elastic TODO 3.36.7 - FAQ Pourquoi l\u0026rsquo;applicatif service-redis ne démarre pas en local ? si la machine WSL UbuntuTest est démarrée, alors le package RPM Redis installé est déjà démarré (démarrage automatique). "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.37proceduresdiverses/",
	"title": "3.37 Procédures-diverses",
	"tags": [],
	"description": "",
	"content": "\r3.37.1 - Comment ajouter le client d\u0026rsquo;API d\u0026rsquo;un micro-service dans un autre micro-service ? 3.37.2 - Ajout d\u0026rsquo;une dépendance dans le framework du workspace FRONT 3.37.3 - Cypress démarré avec xx-e2e ne trouve pas l\u0026rsquo;application qui est pourtant démarré 3.37.4 - Jackson n\u0026rsquo;arrive pas à transformer un JSON en Record (classcastexception LinkedHashMap) 3.37.5 - Erreur de compilation dans Eclipse 3.37.6 - Comment chiffrer/déchiffrer le fichier variablesPourScripts.properties.gpg 3.37.7 - Le micro-service SOCLE-REFERENTIEL ne démarre plus 3.37.8 - Débugger un micro-service démarré en ligne de commande Ce chapitre contient des procédures et des aides pour des points particuliers nécessitant des explications.\n3.37.1 - Comment ajouter le client d\u0026rsquo;API d\u0026rsquo;un micro-service dans un autre micro-service ? En tout premier lieu, il faut ajouter la dépendance du client d\u0026rsquo;appel dans le micro-service appelant. Donc éditer le fichier $projetAppelant/pom.xml :\n\u0026lt;!-- Le classifier CLIENT du projet xxxxxxx pour la compilation/exécution normale --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.talbotgui.psl.socle\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;socle-xxxxxxx\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${project.version}\u0026lt;/version\u0026gt; \u0026lt;classifier\u0026gt;client\u0026lt;/classifier\u0026gt; \u0026lt;exclusions\u0026gt;\u0026lt;exclusion\u0026gt;\u0026lt;groupId\u0026gt;*\u0026lt;/groupId\u0026gt;\u0026lt;artifactId\u0026gt;*\u0026lt;/artifactId\u0026gt;\u0026lt;/exclusion\u0026gt;\u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Pour faire fonctionner les tests dans Eclipse qui gère mal le classifier \u0026#34;client\u0026#34; (cf. chapitre 3.37.1 de la documentation) --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.talbotgui.psl.socle\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;socle-xxxxxxx\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${project.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt;\u0026lt;exclusion\u0026gt;\u0026lt;groupId\u0026gt;*\u0026lt;/groupId\u0026gt;\u0026lt;artifactId\u0026gt;*\u0026lt;/artifactId\u0026gt;\u0026lt;/exclusion\u0026gt;\u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; Pour rendre disponible le client Feign dans l\u0026rsquo;application appelante, il faut :\n//pour activer les clients Feign et appeler un service exposé d\u0026#39;un autre micro-service via une simple interface //Le basePackage permet de générer automatiquement un client pour les interfaces de @Controler d\u0026#39;un package @EnableFeignClients(basePackages = { \u0026#34;com.github.talbotgui.psl.socle.xxxxxxxxxxxxxxx.apiclient.api\u0026#34; }) Pour disposer du client d\u0026rsquo;appel dans la classe de service, il suffit d\u0026rsquo;ajouter :\n/** Client d\u0026#39;appel de l\u0026#39;API des xxxxxxxx */ @Autowired private XxxxxxxAPI clientXxxxxxx; Dans le test du service, il est nécessaire d\u0026rsquo;ajouter un bouchon du client d\u0026rsquo;appel à l\u0026rsquo;API appelée.\nSi ce n\u0026rsquo;est pas déjà fait, ajouter, sur la classe XxxServiceTest, la configuration nécessaire à Mockito : //Activation de Mockito dans ce test qui ne génére qu\u0026#39;une unique instance de la classe de test pour l\u0026#39;ensemble des méthodes de la classe @TestInstance(Lifecycle.PER_CLASS) @ExtendWith(MockitoExtension.class) Déclarer le nouveau bouchon : /** Bouchon du client d\u0026#39;appel à l\u0026#39;API Xxxxx présent dans le service. */ @Mock() private xxxxxxxxxClient clientXxxxxxxxxxx; Si ce n\u0026rsquo;est pas déjà fait, ajouter l\u0026rsquo;annotation @InjectMocks sur l\u0026rsquo;intance de service présente dans la classe de test. Réinitialiser le nouveau bouchon entre chaque test, dans la méthode annotée @Before : // Gestion des bouchons Mockito.reset(this.clientXxxxxxxxxxx); Dans les tests unitaires, sont maintenant présents plusieurs contextes Feign (les APIs de l\u0026rsquo;appelant et de l\u0026rsquo;appelé). Spring n\u0026rsquo;aime pas ça. Pour le contenter exclusivement dans les tests, il faut ajouter dans le fichier $projetAppelant/src/test/resources/application-testspecifique.properties les lignes suivantes :\n# Configuration permettant le fonctionnement du test BrouillonAPITest car deux contextes Feign sont d�marr�s (et donc deux Bean du m�me nom). spring.main.allow-bean-definition-overriding=true 3.37.2 - Ajout d\u0026rsquo;une dépendance dans le framework du workspace FRONT Toute dépendance du framework FRONT doit être déclarée dans peerDependencies du package.json (comprendre j\u0026rsquo;en ai besoin) ainsi que dans le package.json à la racine (comprendre la voici).\n3.37.3 - Cypress démarré avec xx-e2e ne trouve pas l\u0026rsquo;application qui est pourtant démarré Il arrive que, dans l\u0026rsquo;application Cypress démarrée avec la commande npm run cypress, s\u0026rsquo;affiche le message \u0026ldquo;http://xxxx non trouvé\u0026rdquo;. Ceci vient souvent du proxy. Ce dernier est sans doute mal paramétré. Si l\u0026rsquo;application est démarrée en local sur un poste de développement, il est nécessaire d\u0026rsquo;exécuter les commandes suivantes : export HTTP_PROXY= et export HTTPS_PROXY=.\n3.37.4 - Jackson n\u0026rsquo;arrive pas à transformer un JSON en Record (classcastexception LinkedHashMap) Un record est un type de structure récent dans Java. Il ne dispose pas de SETTER. Donc Jackson ne peut travailler qu\u0026rsquo;avec les constructeurs. Pour cela, il faut lui fournir :\nun constructeur complet qui ne soit pas le constructeur par défaut du record (la convention du projet est : déplacer le premier paramètre en dernière position) avec l\u0026rsquo;annotation @JsonCreator sur le constructeur avec l\u0026rsquo;annotation @JsonProperty(\u0026ldquo;cases\u0026rdquo;) sur chacun des paramètres Exemple :\n/** * Constructeur contenant tous les attributs mais avec le premier en dernier pour fournit à Jackson un constructeur à utitiliser (les setter * n\u0026#39;existe pas dans un record). De plus, pour Jackson, il faut ajouter un @JsonCreator sur le constructeur et un @JsonProperty sur chaque * paramètre. */ @JsonCreator public HubeeFolderDto(@JsonProperty(\u0026#34;externalId\u0026#34;) String externalId, @JsonProperty(\u0026#34;applicant\u0026#34;) HubeeApplicantDto applicant, @JsonProperty(\u0026#34;cases\u0026#34;) List\u0026lt;HubeeCaseDto\u0026gt; cases, @JsonProperty(\u0026#34;attachments\u0026#34;) List\u0026lt;HubeeAttachmentDto\u0026gt; attachments, @JsonProperty(\u0026#34;createDateTime\u0026#34;) Date createDateTime, @JsonProperty(\u0026#34;updateDateTime\u0026#34;) Date updateDateTime, @JsonProperty(\u0026#34;closeDateTime\u0026#34;) Date closeDateTime, @JsonProperty(\u0026#34;id\u0026#34;) String id, @JsonProperty(\u0026#34;globalStatus\u0026#34;) String globalStatus, @JsonProperty(\u0026#34;processCode\u0026#34;) String processCode) { this(processCode, externalId, applicant, cases, attachments, createDateTime, updateDateTime, closeDateTime, id, globalStatus); } 3.37.5 - Erreur de compilation dans Eclipse De temps en temps, Eclipse redéfini la configuration d\u0026rsquo;un ou plusieurs projets qui, du coup, ne sont plus cohérents avec la configuration du workspace ou du pom.xml.\nLa principale cause est la configuration du compilateur. Pour rechercher puis corriger ces erreurs :\nrechercher org.eclipse.jdt.core.compiler.source dans les fichiers org.eclipse.jdt.core.prefs générés par Eclipse dans les répertoires .settings remplacer le contenu de ces fichiers par eclipse.preferences.version=1 org.eclipse.jdt.core.compiler.problem.forbiddenReference=warning 3.37.6 - Comment chiffrer/déchiffrer le fichier variablesPourScripts.properties.gpg Le fichier variablesPourScripts.properties.gpg est une version chiffrée du fichier variablesPourScripts.properties. Ce dernier était utilisé pour contenir les variables d\u0026rsquo;environnement utilisées par les différents scripts SH du socle. Mais, parmis elles, se trouvaient des mots de passe. Pour éviter que ces derniers soient trop facilement accessibles, en plus du bon chmod, le plus simple est de chiffrer le document. Pour cela, la commande gpg est utilisée :\nLa commande gpg -c variablesPourScripts.properties avec la passphrase nouvelleAnnee2023 a permis le chiffrement du fichier. La commande gpg -dq variablesPourScripts.properties.gpg permet le déchiffrement. Associée à la commande eval \u0026quot;$(...)\u0026quot; permettant d\u0026rsquo;exécuter la sortie standard d\u0026rsquo;une commande, on obtient l\u0026rsquo;exécution du fichier de properties et la définition des variables.\n3.37.7 - Le micro-service SOCLE-REFERENTIEL ne démarre plus Ce micro-service ne démarre pas si un référentiel ne s\u0026rsquo;initialise pas à cause d\u0026rsquo;une erreur 401 sur un appel HTTP.\nIl est possible que des données en cache soit le problème dans le cas où :\nun access token d\u0026rsquo;API soit en cache (et donc vieux et périmé) les données associées ne soient pas en cache Alors le service tente de télécharger les données avec un vieux token. Il faut retirer les données de token présentes dans le cache.\n3.37.8 - Débugger un micro-service démarré en ligne de commande /!\\ En cas de problème entre l\u0026rsquo;exécution du code dans Eclipse et celle du code compilé, regarder à Proguard !! /!\\\n/!\\ Pour analyser rapidement un problème, il est possible de debugger, non le code offusqué, mais le code des librairies. Un point d\u0026rsquo;arrêt sur exception est une bonne solution.\nLes micro-services démarrés en ligne de commande ont un code offusqué. Ils n\u0026rsquo;est pas possible de faire du debug dans ces conditions.\nEn cas de problème non reproductible en démarrant le micro-service depuis Eclipse, il faut\ncommenter la ligne \u0026lt;excludeGroupIds\u0026gt;com.github.talbotgui.psl.socle\u0026lt;/excludeGroupIds\u0026gt; du pom.xml du socle commenter la balise proguard-maven-plugin des pom.xml du micro-service concerné recompiler chaque projet mvn clean install -DskipTests -f ./socle-xxxx/ redémarrer le micro-service redémarrer le remote debug Après usage, annuler les modifications du pom.xml et recompiler le projet.\n"
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.41chosesasavoir/",
	"title": "3.41 Les choses à savoir",
	"tags": [],
	"description": "",
	"content": "\rCe chapitre contient une liste non exhaustive d\u0026rsquo;informations, liens et sujets que tout membre de l\u0026rsquo;équipe devrait connaître pour développer efficacement.\nculture informatique\nles expressions régulières l\u0026rsquo;usage de KeePass les groupes d\u0026rsquo;onglet dans Chrome les outils de développement dans les navigateurs WEB les requêtes HTTP (méthodes, code de retour, entêtes, cookies) UNIX\nles commandes de base pour parcourir une machine : cd, cat, vi, ls les redirections de sortie standard et sortie d\u0026rsquo;erreur (cd. documentation externe) les commandes de base pour gérer les utilisateurs et les droits : su, chown, chmod les commandes de base pour rechercher et manipuler un processus ou une application : ., ps, kill les commandes de base pour manipuler l\u0026rsquo;historique des commandes : ctrl+R et history astuce : privilégier toujours l\u0026rsquo;usage des chemins absolus dans une commande (permet un usage plus facile de l\u0026rsquo;historique) règle de sécurité : toujours supprimer de l\u0026rsquo;historique une commande contenant un identifiant (commande history pour récupérer l\u0026rsquo;index de la commande puis history -d LeNumeroDeLaCommande pour la détruire) le langage Shell la commande pour exécuter une requête HTTP : curl astuce : pour ne pas réécrire une commande CURL et du fait que la plus part contiennent des identifiants, il est utile et pratique de les stocker dans KeePass Java \u0026amp; ses frameworks\nJava : les streams : filter, map, collect, reduce les patterns de base : singleton (documentation externe et comment l\u0026rsquo;implémenter) stateless (documentation externe) service layer (documentation externe) repository (documentation externe) (différentes sources de documentation sont utilisées car ces sites expliquent des dizaines d\u0026rsquo;autres patterns) Spring : les patterns liés à Spring : inversion de contrôle, injection de dépendance (documentation externe) le cycle de vie d\u0026rsquo;un composant Spring la gestion des transactions, de leur propagation et des conditions de rollback (documentation externe) les conditions de rollback des transactions de Spring (documentation externe) Slf4j : l\u0026rsquo;utilisation de {} dans les messages de log vérifier qu\u0026rsquo;un niveau de log est actif avant d\u0026rsquo;exécuter du code créant un contenu à logguer Typescript et Angular\nRxJS : Souscrire à un Observable et penser à détruire la souscription Créer un pipe à partir d\u0026rsquo;une souscription pour traiter la(les) réponse(s) sous forme d\u0026rsquo;un flux de map, filter, merge, mergeMap, mergeAll (documentation externe) IDE\nles raccourcis Eclipse : Shift+Ctrl+T : recherche de classe Shift+Ctrl+R : recherche de fichier F3 ou Ctrl+clic : pour aller à la déclaration d\u0026rsquo;une classe, méthode ou variable Shift+Ctrl+G : pour rechercher les appels/usages d\u0026rsquo;une classe, méthode ou variable Alt+Shift+X puis J : pour démarrer la classe Java en cours d\u0026rsquo;édition comme un programme Java Alt+Shift+X puis T : pour démarrer la classe Java en cours d\u0026rsquo;édition comme un JUnit ² ² : pour relancer les derniers tests JUnit exécutés (pour ceux qui ont créé le raccourci) Ctrl+o : pour lister les membres et méthodes de la classe en cours d\u0026rsquo;édition Ctrl+l : pour aller à un numéro de ligne précis Shift+Ctrl+s : pour sauvegarder tous les fichiers en cours d\u0026rsquo;édition Alt+haut ou Alt+bas : pour déplacer la ligne du curseur ou déplacer les lignes sélectionnées Alt+Shift+r : pour renommer la variable, méthode ou classe présente sous le curseur "
},
{
	"uri": "http://localhost:1313/documentation/3developpement/3.99faq/",
	"title": "3.99 Foire aux questions (FAQ)",
	"tags": [],
	"description": "",
	"content": "\r3.99.1 - Que faire de la log \u0026ldquo;OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended\u0026rdquo; ? 3.99.2 - Des membres Java sont renommés \u0026ldquo;a\u0026rdquo; ou \u0026ldquo;b\u0026rdquo; quand le code s\u0026rsquo;exécutant a été compilé via Maven mais pas en DEBUG avec Eclipse 3.99.3 - Pourquoi le Hot Module Reload de WebPack ne permet pas de garder la configuration, les données et la progression dans une démarche Ce chapitre contient des éléments très diverses et la capitalisation de toutes les questions qu\u0026rsquo;un membre de l\u0026rsquo;équipe peut se poser.\nIl est préférable de documenter une fonctionnalité dans un chapitre dédié que de faire grandir ce chapitre de manière outrancière.\n3.99.1 - Que faire de la log \u0026ldquo;OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended\u0026rdquo; ? Suite à une montée de version de JDK (version indéterminée mais avant 14), est apparue la ligne de log OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended.\nPour retirer cet avertissement, il est possible d\u0026rsquo;ajouter, dans la ligne de commande de démarrage de chaque applicatif, l\u0026rsquo;argument -Xshare:off.\nRéférence : https://github.com/DataDog/dd-trace-java/issues/1294#issuecomment-597869917 et https://nipafx.dev/java-application-class-data-sharing/\n3.99.2 - Des membres Java sont renommés \u0026ldquo;a\u0026rdquo; ou \u0026ldquo;b\u0026rdquo; quand le code s\u0026rsquo;exécutant a été compilé via Maven mais pas en DEBUG avec Eclipse Pour rappel, le code est anonymisé avec ProGuard. Si les membres sont renommés, c\u0026rsquo;est que la classe n\u0026rsquo;est pas exclue de l\u0026rsquo;obfuscation.\nPar exemple, les DTO en entrée des API exposées par le Socle doivent être dans un package \u0026hellip;apiclient.dto. Les DTO utilisés pour appeler des APIs externes doivent être dans un package \u0026hellip;client.dto.\nLe détail est dans le fichier 2-code/socle/obfuscation-proguard.conf.\n3.99.3 - Pourquoi le Hot Module Reload de WebPack ne permet pas de garder la configuration, les données et la progression dans une démarche En 03/2024 (et pas pour la première fois), ce point a été étudié.\nLe problème vient du fait que toute modification peut avoir un impact sur la configuration, les données et la progression. Donc quand sauvegarder/restaurer et quand ne pas le faire.\nSi le seul gain attendu est de revenir à une étape précise avec des données précises, alors la mécanique de brouillon est là pour ça.\n"
},
{
	"uri": "http://localhost:1313/documentation/4ops/",
	"title": "4. Ops",
	"tags": [],
	"description": "",
	"content": "Chapitre 4 OPS Ce chapitre décrit le plan de déploiement, les outils utilisés pour réaliser ces déploiements (et les tester) ainsi que les procédures diverses utiles au quotidien. 4.1 Plan 4.2 Ansible 4.3 Règles 4.4 Exploitation "
},
{
	"uri": "http://localhost:1313/documentation/4ops/4.1plan/",
	"title": "4.1 Plan",
	"tags": [],
	"description": "",
	"content": "Voici le plan de déploiement imaginé au 13/06/2023 (aucun environnement cible n\u0026rsquo;existe encore à cette date).\n4.1.1 - Les composants applicatifs et leurs contraintes 4.1.2 - Plan de déploiement 4.1.3 - Besoins vis-à-vis de l\u0026rsquo;hébergeur/exploitant 4.1.4 - Installation avec Ansible 4.1.5 - Commandes à connaître 4.1.1 - Les composants applicatifs et leurs contraintes Les services du socle sont des fonctionnalités que peuvent proposer les fournisseurs de Cloud. Ils ne seront donc pas tous installés en production. Mais, ceux développés permettent de démarrer, sur le poste local ou sur un serveur OnPremise, un SI complet.\nSont définies 3 catégories de composants :\ncatégorie 3 : le composant est vital et doit être redondé pour assurer le fonctionnement du système. catégorie 2 : le composant n\u0026rsquo;est pas assez vital pour que tout le SI soit indisponible s\u0026rsquo;il est absent. Mais son indisponibilité réduit les fonctionnalités proposées aux usagers. catégorie 1 : le composant peut être indisponible sans gêne particulière pour les fonctionnalités proposées aux usagers mais son absence réduit les fonctionnalités du SI. catégorie * : certains composants à la criticité faible peuvent nécessiter plusieurs instances pour tenir la charge induite par les usagers. Sont aussi définies\ndes couches réseaux exposée interne profonde et des colonnes séparant les instances des applicatifs dans des zones réseaux verticales (DNS dédié obligatoire) exécution administration Voici les contraintes et la catégorisation de tous les services :\nservices-cloud service-admin : [catégorie 1] [interne] [administration] Le service d\u0026rsquo;administration n\u0026rsquo;a pas besoin d\u0026rsquo;être redondée. S\u0026rsquo;il est absente, le SI continue son travail. Seules les équipes réalisant des analyses ou souhaitant modifier une configuration sont gênées. Elles résolveront le problème en cours et pourront de nouveau travailler une fois l\u0026rsquo;application de nouveau disponible. service-config : [catégorie 1] [interne] [administration] Sans mise à disposition des configurations, de nouvelles instances de micro-services ne peuvent pas démarrer et leur configuration ne peut pas être rechargée (action depuis le service d\u0026rsquo;administration). service-elastic : [catégorie 1] [profonde] [administration] Sans base de données Elasticsearch, les lignes de log ne peuvent pas être centralisées. Mais les fichiers de log sur cheque serveur ne sont pas perdus pour autant. Donc, dès que Elasticsearch est de nouveau disponible, les FileBeat lui enverront les logs. Mais, par principe, un sreveur ElasticSearch est obligatoirement installé sur plusieurs serveurs différents (plusieurs noeuds) pour assurer l\u0026rsquo;intégrité des données (copie de shard). service-gateway : [catégorie 3] [exposée] [exécution] La Gateway est le point d\u0026rsquo;entrée de toute requête HTTP vers une API du socle. Elle est hautement nécessaire et donc redondée. service-ldap : [catégorie 1] [profonde] [administration] Le LDAP permet l\u0026rsquo;authentification du service d\u0026rsquo;administration et de l\u0026rsquo;application d\u0026rsquo;administration. Il n\u0026rsquo;est pas plus critique que ces deux applications. service-nosql : [catégorie 3] [profonde] [exécution] Sans les configurations (publiques et internes), aucune démarche n\u0026rsquo;est disponible aux usagers. Cette base de données est donc primordiale. service-redis : [catégorie 1] [profonde] [exécution] Ce composant apporte de la sécuritée (anti-DDOS) pour la Gateway. Il n\u0026rsquo;apporte rien aux usagers. Il participe à protéger le SI. service-registry : [catégorie 3] [profonde] [exécution] Sans registre, les différents services et micro-services ne peuvent pas communiquer entre eux. Il est indispensable et à redonder. micro-services : socle-adminpsl : [catégorie 1] [interne] [administration] L\u0026rsquo;application d\u0026rsquo;administration n\u0026rsquo;a pas besoin d\u0026rsquo;être redondée. Si elle est absente, le SI continue son travail. Seules les équipes réalisant des analyses ou souhaitant modifier une configuration sont gênés. Ils résolveront le problème en cours et pourront de nouveau travailler une fois l\u0026rsquo;application disponible. socle-dbbrouillon : [catégorie 2] [interne] [exécution] Sans sauvegarde ou chargement de brouillon, les usagers peuvent toujours renseigner et soumettre des télé-dossiers. socle-dbconfiguration : [catégorie 3] [interne] [exécution] Sans les configurations (publiques et internes), aucune démarche n\u0026rsquo;est disponible aux usagers. socle-dbdocument : [catégorie 3] [interne] [exécution] Sans upload de pièce jointe et stockage de documents générés, aucune soumission n\u0026rsquo;est possible. Cet applicatif est donc indispensable et doit être rendondé. socle-dbnotification : [catégorie 3] [interne] [exécution] Ce composant participe à la soumission d\u0026rsquo;un télé-dossier. Il est donc indispensable. socle-referentiel : [catégorie 2*] [interne] [exécution] Ce composant donne accès à un référentiel. Si une démarche n\u0026rsquo;utilise aucun de ces référentiels, elle peut être parcourue et des télé-dossiers peuvent être soumis. socle-referentielexterne : [catégorie 2*] [interne] [exécution] Ce composant donne accès à un référentiel. Si une démarche n\u0026rsquo;utilise aucun de ces référentiels, elle peut être parcourue et des télé-dossiers peuvent être soumis. socle-securite : [catégorie 3] [interne] [exécution] Ce composant permet toutes les authentifications (OIDC, anonyme et par mot de passe). Sans lui, aucune API ne peut être appelée. socle-soumission : [catégorie 3] [interne] [exécution] Ce composant porte la soumission d\u0026rsquo;un télé-dossier. Il est donc indispensable. socle-transfert : [catégorie 1*] [interne] [administration] Si ce composant est indisponible, les télé-dossiers soumis s\u0026rsquo;accumuleront. Mais, à son redémarrage, les traitements seront réalisés au fur et à mesure sans perte de données. autres : les applications WEB des démarches :[catégorie 3] [exposée] [exécution] Les applications des démarches sont la partie visible du système les applications WEB d\u0026rsquo;administration :[catégorie 1] [interne] [administration] Les applications d\u0026rsquo;administration ne sont pas nécessaires au bon fonctionnement. Elles sont utiles pour la gestion/configuration/administration uniquement. 4.1.2 - Plan de déploiement En reprenant les besoins décrits au chapitre précédent et les intégrant dans un tableau représenant les zones et colonnes réseau :\nColonne ADMIN Colonne EXECUTION Zone exposée service-gateway x3 applications WEB des démarches x3 Zone interne service-admin x1 service-config x1 socle-adminpsl x1 socle-transfert x2 applications WEB d'administration x1 socle-dbbrouillon x3 socle-dbconfiguration x1 socle-dbdocument x3 socle-dbnotification x3 socle-referentiel x2 socle-referentielexterne x2 socle-securite x3 socle-soumission x3 Zone profonde service-elastic x3 service-ldap x1 service-nosql x3 service-redis x1 service-registry x3 A partir de ces besoin et sans disposer des résultats d\u0026rsquo;un tir de performance, il parait logique et suffisant de créer un nombre limiter de machines identiques entre elles (pour simplifier les déploiements) sur le modèle suivant :\nColonne ADMIN Colonne EXECUTION Zone exposée 3 machines Zone interne 2 machines 3 machines Zone profonde 3 machines 3 machines 4.1.3 - Besoins vis-à-vis de l\u0026rsquo;hébergeur/exploitant Le SI semble donc nécessiter 14 machines Unix répondant aux critères suivants\n[toutes] est installé un OS unix récent (distribution au choix de l\u0026rsquo;hébergeur/exploitant) et maintenu à jour par l\u0026rsquo;expoitant [toutes] sont ouverts les flux vers toutes les zones inférieures (la gateway a besoin de l\u0026rsquo;accès au registre) [zone exposée et interne] Internet est accessible en passant par un même dispositif réseau (pour assurer une unique IP publique du SI facilitant ainsi la configuration des filtres par IP des partenaires) [profonde] la capacité de disque est importante et taillée en fonction des tirs de performance réalisés (par défaut 300Go) [toutes] aucun logiciel précis n\u0026rsquo;est à préinstaller sur les machines (Ansible sera utilisé pour installer tous les éléments nécessaires et réaliser les montées de version sauf indication contraire de l\u0026rsquo;hébergeur/exploitant) En plus de ces caractéristiques, la sécurité périphérique du SI est à la charge de l\u0026rsquo;hébergeur/exploitant. Ceci comprend (liste non exhaustive)\nun filtrage de sécurité basé sur les signatures standards d\u0026rsquo;attaque la sécurisation des accès SSH d\u0026rsquo;administration/exploitation \u0026hellip; (à compléter) Les machines sont donc identifiées avec un code XXX_YYY_Z avec\nXXX la colonne réseau, YYY la couche réseau Z l\u0026rsquo;indice de la machine. On obtient ainsi la liste des machines suivantes :\nEXE_EXP_1, EXE_EXP_2, EXE_EXP_3 EXE_INT_1, EXE_INT_2, EXE_INT_3 EXE_PRO_1, EXE_PRO_2, EXE_PRO_3 ADM_INT_1, ADM_INT_2 ADM_PRO_1, ADM_PRO_2, ADM_PRO_3 4.1.4 - Installation avec Ansible La création des machines n\u0026rsquo;est pas dans le périmètre actuel de ce projet. Elles sont identifiées telles que le définit le chapitre précédent.\nLa répartition du déploiement des applicatifs sur les machines est lisible dans le fichier d\u0026rsquo;inventaire\nLes scripts doivent être construits pour installer l\u0026rsquo;ensemble des éléments nécessaires au bon fonctionnement d\u0026rsquo;un applicatif sur un serveur. Ainsi, chaque installation d\u0026rsquo;un applicatif passe, par exemple, par l\u0026rsquo;installation de Java (si Java est déjà installé, Ansible ne fera rien). Avec ce principe, les scripts ne sont pas à refaire si le plan de déploiement change et il est même envisageable d\u0026rsquo;installer rapidement une machine supplémentaire avec seulement un unique applicatif alors que ce dernier est systématiquement installé avec d\u0026rsquo;autres sur les autres machines de l\u0026rsquo;environnement.\nLes scripts/configurations Ansible du projet ias permettent :\npour toutes les machines de paramétrer un groupe et un utilisateur UNIX (www:www) pour les micro-services d\u0026rsquo;installer la bonne version de Java (identique sur toutes les machines - cf version dans la page A faire). de télécharger le binaire applicatif à installer de déposer le binaire dans le répertoire ${repertoirePsl}${nomApplicatif} de déposer la configuration nécessaire dans ce même répertoire de déposer les scripts de démarrage et d\u0026rsquo;arrêt dans ce même répertoire d\u0026rsquo;installer FileBeat dans le répertoire ${repertoireFileBeat} de déposer la configuration propre à FileBeat dans le répertoire ${repertoireFileBeat}conf.d pour les services : full custom pour la plus part 4.1.5 - Commandes à connaître Après exécuter un playbook depuis la machine locale vers la machine WSL :\ndémarrer WLS depuis le menu démarrer de Windows en recherchant ubuntu démarrer WSL, depuis une commande DOS, avec la commande wsl -d UbuntuAnsible sur la machine UbuntuAnsible, exécuter la commande ansible-playbook ansible/05_statuer.yml -i ansible/inventory/local si les actions à réaliser par Ansible nécessite un droit SUDO, exécuter la commande ansible-playbook ansible/01_preparer.yml -i ansible/inventory/local -K --extra-vars \u0026quot;ansible_user=ubuntu\u0026quot; et saisir le mot de passe \u0026ldquo;ubuntu\u0026rdquo; Pour n\u0026rsquo;exécuter un playbook que pour un groupe de machines précis (service/couche/colonne), exécuter ansible-playbook ansible/05_statuer.yml -i ansible/inventory/local --limit machines_service_registry\n"
},
{
	"uri": "http://localhost:1313/documentation/4ops/4.2ansible/",
	"title": "4.2 Ansible",
	"tags": [],
	"description": "",
	"content": "Cette page décrit comment et pourquoi sont organisées les sources du projet IAC\n4.2.1 - Description du projet 4.2.2 - Commandes de base 4.2.1 - Description du projet Ansible permet de créer un répertoire inventory pour y stocker plusieurs sources/fichiers et tous les utiliser avec le paramètre -i. Les fichiers y sont chargés dans l\u0026rsquo;ordre ASCII (source). Ainsi, dans chaque inventaire, sont présents les fichiers :\n01-listeMachines.yml qui fournit, pour chaque code de machine (par exemple EXE_EXP_1), le nom de la machine et son port SSH 02-planDeploiement.yml qui décrit le déploiment des services sur chaque machine 03-groupesReseau.yml qui regroupe les machines par couche, colonne et zone réseau 4.2.2 - Commandes de base Pour démarrer la machine Ansible, exécuter, dans une ligne de commande DOS, wsl -d UbuntuAnsible.\nPour démarrer la machine de test, exécuter, dans une ligne de commande DOS, wsl -d UbuntuTest.\nPour démarrer tous les applicatifs sur la machine WSL, exécuter, depuis la machine UbuntuAnsible, la commande ansible-playbook ansible/04_demarrer.yml -i ansible/inventory/local.\nPour plus de détails sur les commandes possibles, voir le chapitre §4.4.3.\n"
},
{
	"uri": "http://localhost:1313/documentation/4ops/4.3regles/",
	"title": "4.3 Règles",
	"tags": [],
	"description": "",
	"content": "Cette page décrit les régèles et normes de développement dans le projet IAC avec Ansible\n4.3.1 - Conception générale 4.3.2 - A savoir 4.3.3 - Règles à respecter 4.3.4 - Commandes utiles 4.3.1 - Conception générale Ansible est un outil de préparation/rédaction de \u0026ldquo;scripts\u0026rdquo;. Il permet, avec ses modules natifs d\u0026rsquo;exécuter un très grand nombre d\u0026rsquo;actes différents sur un ensemble de machines Unix distantes.\nUn projet Ansible est constitué : de tâches, de rôles et de playbook. Cette organisation peut être utilisée, fonctionnement, de plusieurs manières et est donc assez maléable.\nLe projet ias de la nouvelle PSL s\u0026rsquo;organise ainsi :\nune tâche (task) est une geste unitaire (copier un fichier, générer un fichier depuis un template, créer un répertoire) un rôle (role) est un ensemble de tâches un rôle commun est un ensemble mutualisé de tâches permettant de limiter la duplication dans les véritables rôles un véritable rôle mène à un objectif précis comme préparer/installer/déployer/démarrer/statuer/arrêter un applicatif un scénario (playbooks) rassemble tous les rôles ayant un même objectif mais pour tous les applicatifs Nativement, Ansible permet de limiter l\u0026rsquo;exécution\ndes rôles à un groupe de machines avec le paramètre --limit xxxxx de tout rôle ou tâche avec un ou plusieurs tag Sur ce projet, l\u0026rsquo;usage de tag est limité aux rôles avec le nom d\u0026rsquo;un applicatif.\n4.3.2 - A savoir toutes les variables sont obligatoires et Ansible échoue si une vient à manquer. 4.3.3 - Règles à respecter Sur la conception :\npas de tâche pour mutualiser une unique étape (même complexe et dupliquer plusieurs fois) les tags ne se définissent que sur les rôles et donc dans les playbook chaque applicatif peut être déployé séparément grâce au tags (même si cela nécessite un peu de duplication dans les playbook (cf. 03_deployer) un même playbook exécuté deux fois de suite ne doit déclarer aucun changement (libellé changed) la seconde fois (pas de commande inutile, de redémarrage en trop, \u0026hellip;). Cette règle s\u0026rsquo;applique particulièrement sur l\u0026rsquo;étape 1. Sur la rédaction :\nchaque déclaration de variable pointant sur un répertoire doit se terminer par un \u0026lsquo;/\u0026rsquo;. un commentaire est obligatoire pour chaque tâche Sur les tests :\ntoujours rejouer deux fois consécutives un rôle créé/modifié à la fin d\u0026rsquo;un ensemble de modifications, rejouer absolument tous les rôles : ansible-playbook ansible/99_detruire.yml -i ansible/inventory/local -K --extra-vars \u0026#34;ansible_user=ubuntu\u0026#34; ansible-playbook ansible/01_preparer.yml -i ansible/inventory/local -K --extra-vars \u0026#34;ansible_user=ubuntu\u0026#34; ansible-playbook ansible/02_installer.yml -i ansible/inventory/local ansible-playbook ansible/03_deployer.yml -i ansible/inventory/local ansible-playbook ansible/04_demarrer.yml -i ansible/inventory/local ansible-playbook ansible/05_statuer.yml -i ansible/inventory/local ansible-playbook ansible/06_arreter.yml -i ansible/inventory/local 4.3.4 - Commandes utiles Quelques commandes utiles :\napt et apt-get : # pour lister les paquets installés apt list --installed # pour supprimer tous les paquets désinstallés et leurs dépendances sudo apt autoremove réseau : # pour afficher le nom de la machine hostname # pour les configurations réseau ip a # pour les ports écoutés et processus associés sudo lsof -i -P -n ldap : # lister le contenu du LDAP avec le compte d\u0026#39;administration ldapsearch -H ldap://localhost:389 -D cn=DirectoryManager -w password logs : # pour suivre les modifications dans les logs de l\u0026#39;applicatif service-config tail -f /psl/logs/log_*service-config* Java : # pour lister les versions de Java installées ls -al /usr/lib/jvm/ # pour trouver le CACERT par défaut de l\u0026#39;OS ls /etc/ssl/certs/java/cacerts # pour extraire la version d\u0026#39;un binaire lejar=\u0026#34;/psl/applicatifs/service-config/service-config.jar\u0026#34; fichierPom=`unzip -l ${lejar} | grep pom.properties | sed \u0026#39;s/.*META/META/\u0026#39;` unzip -p ${lejar} $fichierPom | grep version | sed \u0026#39;s/.*=//g\u0026#39; "
},
{
	"uri": "http://localhost:1313/documentation/4ops/4.4exploitation/",
	"title": "4.4 Exploitation",
	"tags": [],
	"description": "",
	"content": "Cette page décrit les tests d\u0026rsquo;une campagne de non-régression complète\n4.4.1 - Introduction 4.4.2 - Prérequis à l\u0026rsquo;installation 4.4.3 - Commandes possibles 4.4.4 - Obtenir les versions des composants déployés 4.4.1 - Introduction Cette page décrit les différentes commandes utiles pour l\u0026rsquo;exploitation de ce SI.\n4.4.2 - Prérequis à l\u0026rsquo;installation Les machines doivent toutes être des machines Ubuntu récentes (2023xx minimum). Un compte disposant des droits SUDO doit exister (par exemple, ubuntu dans le reste de la documentation)\n4.4.3 - Commandes possibles Détruire tout contenu PSL sur toutes les machines : ansible-playbook ansible/99_detruire.yml -i ansible/inventory/local -K --extra-vars \u0026quot;ansible_user=ubuntu\u0026quot;\nCréer tous les éléments de base nécessitant des droits SUDO sur toutes les machines : ansible-playbook ansible/01_preparer.yml -i ansible/inventory/local -K --extra-vars \u0026quot;ansible_user=ubuntu\u0026quot;\nCréer tous les éléments de base nécessitant des droits SUDO sur les machines associées à un applicatif (exemple service-gateway) : ansible-playbook ansible/01_preparer.yml -i ansible/inventory/local -K --extra-vars \u0026quot;ansible_user=ubuntu\u0026quot; --tags service-gateway\nCréer tous les éléments de base nécessitant des droits SUDO sur les machines d\u0026rsquo;une colonne précise (pour arrêter la moitée des machines) : ansible-playbook ansible/01_preparer.yml -i ansible/inventory/local -K --extra-vars \u0026quot;ansible_user=ubuntu\u0026quot; --limit machines_colonne_execution1\nPour tout détruire et tout recréer : ansible-playbook ansible/99_detruire.yml ansible/01_preparer.yml -i ansible/inventory/local -K --extra-vars \u0026quot;ansible_user=ubuntu\u0026quot;\nPour installer les éléments de base et configurations applicatives sur toutes les machines : ansible-playbook ansible/02_installer.yml -i ansible/inventory/local\nPour déployer les applicatifs sur toutes les machines : ansible-playbook ansible/03_deployer.yml -i ansible/inventory/local\nPour démarrer tous les applicatifs (pas apache2 qui nécessite des droits SUDO) sur toutes les machines : ansible-playbook ansible/04_demarrer.yml -i ansible/inventory/local\nPour avoir le statut et la version de les applicatifs sur toutes les machines : ansible-playbook ansible/05_statuer.yml -i ansible/inventory/local\nPour arrêter tous les applicatifs (pas apache2 qui nécessite des droits SUDO) sur toutes les machines : ansible-playbook ansible/06_arreter.yml -i ansible/inventory/local\n4.4.4 - Obtenir les versions des composants déployés Depuis le navigateur, pour les applications WEB, il est possible d\u0026rsquo;obtenir quelques informations de version de chaque livrable depuis le fichier git.json généré durant le build Maven. Ce fichier est disponible depuis l\u0026rsquo;URL mademarche/etatcivil/git.json par exemple. Il contient, par exemple :\n{ \u0026#34;git.branch\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;git.build.time\u0026#34;: \u0026#34;2024-05-16T08:34:27+0200\u0026#34;, \u0026#34;git.build.version\u0026#34;: \u0026#34;0.0.2-SNAPSHOT\u0026#34;, \u0026#34;git.closest.tag.commit.count\u0026#34;: \u0026#34;1121\u0026#34;, \u0026#34;git.closest.tag.name\u0026#34;: \u0026#34;0.0.1-RELEASE\u0026#34;, \u0026#34;git.commit.id\u0026#34;: \u0026#34;b506017a7957f279127140da3b74ef8ba59a81cd\u0026#34; } "
},
{
	"uri": "http://localhost:1313/documentation/5avancement/",
	"title": "5. Avancement",
	"tags": [],
	"description": "",
	"content": "Chapitre 5 Avancement Ce chapitre a vocation à suivre l\u0026rsquo;état des sujets réalisés, en cours et à planifier : 5.1 Organisation 5.2 à faire "
},
{
	"uri": "http://localhost:1313/documentation/5avancement/5.1comment/",
	"title": "5.1 Organisation",
	"tags": [],
	"description": "",
	"content": "A l\u0026rsquo;origine, ce prototype est un défi personnel : est-ce faisable ? Il a été initialisé et développé sur du temps personnel.\nDonc, côté stratégie, les sujets ont été priorisés selon\nleur faisabilité leur difficulté mais aussi en selon l\u0026rsquo;intéret personnel du sujet. "
},
{
	"uri": "http://localhost:1313/documentation/5avancement/5.2quoi/",
	"title": "5.2 à faire",
	"tags": [],
	"description": "",
	"content": "Rappel des étapes/éléments à réaliser par type de sujet :\nfonctionnalité FRONT : doc éventuelle + bibliothèque + framework + impact Back éventuel + TU fonctionnalité BACK : doc + Back + TU ComplexitéPrioritéDescription Maintenances : Maintenance à faire en 07/2024 : Sécurité (1/3) : mettre à jour DependencyTrack depuis §3.34.5.1 (dernière en 04/2024 en 4.10.1) Maintenance à faire en 07/2023 : Sécurité (2/3) : refaire l'audit de sécurité avec DependencyTrack depuis §3.35 (dernière en 04/2024) Maintenance à faire en 07/2024 : Sécurité (3/3) : vérifier les licences des dépendances Java/Maven depuis §3.35 (dernière le 04/2024) Maintenance à faire en 09/2024 : réaliser une montée de version Socle (1/4) : de Java depuis §3.34.3.3 (dernière en 05/2024 et rien de neuf en 06/2024 en JDK-22.0.1 attention à Proguard et GraalVM) Maintenance à faire en 09/2024 : réaliser une montée de version Socle (2/4) : de Maven depuis §3.34.3.5 (dernière en 06/2024 en 3.9.7) Maintenance à faire en 09/2024 : réaliser une montée de version Socle (3/4) : d'Eclipse depuis §3.34.3.2 (dernière en 08/2024 en 2024-06) Maintenance à faire en 09/2024 : réaliser une montée de version Front (1/4) : Node et NPM depuis §3.34.3.4 (dernière en 06/2024 en node-v22.2.0) Maintenance à faire en 09/2024 : réaliser une montée de version de Hugo (dernière en 06/2024 en 0.127.0 cf. §3.31.7) Maintenance à faire en 09/2024 : réaliser une montée de version de la pile Elastic §3.35.4 (dernière en 06/2024 en 8.14.1) Maintenance à faire en 09/2024 : réaliser une montée de version Front (2/4) : Angular globale depuis §3.34.2.1 (dernière en 06/2024 en angular-18.0.2) Maintenance à faire en 09/2024 : réaliser une montée de version Front (3/4) : les autres librairies JS depuis §3.34.2.5 (dernière en 06/2024) Maintenance à faire en 09/2024 : réaliser une montée de version Front (4/4) : la charte DesignSystem depuis §§3.34.2.3(dernière en 04/2024 en 1.11.2) Maintenance à faire en 2025 : réaliser une montée de version de WSL et des images de machine utilisées en local (dernière en 11/2023 en 22.04.2 pour disposer d'openjdk-20 - cf. §3.2.9) Maintenance à faire en 06/2025 : réaliser une montée de version Socle (4/4) : des dépendances Maven pour tout le code (dernière le 03/2025) Date dernière exécution complète de tests : 05/05/2024 : arnaqueinternet (jusqu'à 100 étapes, augmenté à 150 ce jour-là) 05/05/2024 : bibliotheque 05/05/2024 : ddmariage 05/05/2024 : etatcivil 05/05/2024 : jechangedecoordonnees (pb de validation HTML) 05/05/2024 : operationtranquilitevacances 04/09/2023 : fonctionnement du socle démarré depuis Windows avec le script demarrerTout.sh (§3.36.3) 05/09/2023 : fonctionnement du socle démarré depuis WSL avec Ansible (§3.36.4) / / : Revue de la couverture documentaire du framework Angular (cf. http://localhost:1313/documentation/documentationgeneree/framework/compodoc/coverage.html) Date des dernières vérifications régulières de code : 06/05/2024 : recherche du caractère '§' dans la documentation et vérifier chaque lien (sauf dans la page 5.2quoi.md) : libellé formatté en \"§1.2.3\", lien présent, valide et cohérent / / : relecture complète de la documentation (en cours au §1.2.1 au 08/11/2022) / / : vérifier que tous les types de contenu FRONT sont complètement décrits dans le §2.10.2.2 06/05/2024 : recherche de données personnelles dans le code (*.java dans le répetoire 2-code/socle) générant des logs autres que TRACE (regex=(LOGGER|logger)\\.(debug|info|warn|error).*\",.*) (regarder aux paramètres après le message) 06/05/2024 : recherche de données token (une regex _ey.*_) dans le code du _Socle_ (dans les fichiers _*.log;*.java;*.properties;*.sh;*.launch_ mais pas le répertoire .elastic ni dans les logs TRACE, ni dans les logs ACCESS ni les clefs chiffrées commençant par _{cipher}_) 06/05/2024 : recherche de log/throw avec la regex : catch.*[\\S\\s]{2}.*(log|LOG).*[\\S\\s]{2}.*throw (ne pas tenir compte des occurences dûment documentées et justifiées) et règles à documenter pour les logs vs les throw notamment pour les appels externes 06/05/2024 : recherche, dans le code du Socle, de logs avec une concaténation (au lieu d'utiliser {}) avec la regex : LOGGER.*\\+ 21/05/2024 : recherche, dans le code du Socle, de logs, potentiellement actifs en production, contenant des données venant du navigateur de l'usager avec la regex : LOGGER\\.(info|warn|error).*{}. Au besoin, utiliser LogUtils.nettoyerDonneesAvantDeLogguer 06/05/2024 : vérifier la qualité de l'historique GIT 06/05/2024 : vérifier les warnings dans les logs de Maven (\"No artifact found : *:com.github.talbotgui.psl.socle\" et les warning de Shade sur service-nosql sont connus et normaux) 06/05/2024 : vérifier les imports de la classe StringUtils ne venant pas de Spring (utiliser _import.*StringUtils_ dans toutes les classes Java 17/03/2024 : vérifier que tous les paramètres de toutes les APis exposées sont bien validés 23/03/2025 : Compilation du socle avec le profil 'qualimetrie' et rechercher les warnings de Javadoc 0 0OPS : WSL : socle-referentiel fait un OutOfMemory (bloqué par l'interdiction de virtualisation) 0 0OPS : WSL :séparer la conf WSL locale de la conf du poste de dev + ajouter eureka.client.serviceUrl.defaultZone (via la variable) et eureka.instance.hostname dans les scripts de démarrage 0 0OPS : WSL :mettre des variables dans tous les fichier env de prod des applications FRONT et ajouter un sed au déploiement Ansible et un sed dans une nouvelle commande YARN 0 0OPS : bug sur WSL : dans EtatCivil, 404 sur /var/www/html/mademarche/etatcivil/js/dsfr.module.min.js 0 0OPS : bug sur WSL : dans Biblio, 404 sur les /dsfr/favico... 0 0OPS : bug sur WSL : ?? tester les démarches connectées (EtatCivil, biblio-FC et AI-plainte) 0 0OPS : bug sur WSL : service-registry non sécurisé 0 0OPS : https://demo.ansible-semaphore.com/ 0 0OPS : bug sur WSL : Annuler les 3 commandes suivantes exécutées en tant qu'admin dans PowerShell Set-NetFirewallProfile -Profile Private -DisabledInterfaceAliases \"vEthernet (WSL)\" Set-NetFirewallProfile -Profile Public -DisabledInterfaceAliases \"vEthernet (WSL)\" New-NetFirewallRule -DisplayName \"WSL\" -Direction Inbound -InterfaceAlias \"vEthernet (WSL)\" -Action Allow 0 0OPS : la gateway, s'exécutant sur WSL, dans l'UI swagger, affiche un hostname 'localhost' et les APIs ne sont donc pas appelables 0 0OPS : traiter, dans le script SH de stop, la sélection de la bonne instance en fonction du hostname 0 0OPS : ajouter, dans le script SH de statut, l'affichage du hostname+port+idEureka de l'instance 0 0OPS : terminer la documentation d'installation de poste pour IAS 0 0OPS : GPG 0 0OPS : Vault 0 0OPS : lire et appliquer https://www.redhat.com/sysadmin/faster-ansible-playbook-execution 0 0OPS+DOC : dans HUGO, ajouter un lien vers / avec le libellé \"autres version\" qui pointe sur une page /index.html listant toutes les versions 0 0ansible-playbook-grapher KO dans la dernière version de Python3 installée (pas de WSL) 0 0DOC : après installation : VABF : tester toutes les APIs et tous les liens avec WSL UP (pour vérifier les liens vers les applications) (WSL bloqué) 0 0DOC : migrer vers BRUNO : attendre le https://github.com/usebruno/bruno/issues/1003 pour mettre en place l'authentification OIDC et compléter le chapitre \"3.24.3 - Les requêtes HTTP\" 0 0MAVEN : Montée de version Tika-3.x, unboundid-ldapsdk-7.x, jcommander-2.x 0 0FRONT : retirer le plus possible Material des démarches et n'utiliser que des composants qui n'existe pas dans la DSFR (et documenter le §3.26.3 0 0FRONT : retirer le plus possible Material de l'application d'administration et n'utiliser que des composants qui n'existe pas dans la DSFR (et documenter le §3.26.3 0 0FRONT : retirer le plus possible Material de l'application d'édition et n'utiliser que des composants qui n'existe pas dans la DSFR (et documenter le §3.26.3 0 0FRONT : regarder à https://angular.dev/guide/ssr 0 0FRONT : bug au clic sur ANNULER dans la popup de sauvegarde de brouillon non connecté 0 0FRONT : refaire la modale de sauvegarde du brouillon avec une modale DSFR (https://www.systeme-de-design.gouv.fr/elements-d-interface/composants/modale) et retirer la dernière trace de Material 0 0FRONT : retirer le dernier fileReplacement du fichier angular.json sur le modèle du fichier de environnement.json 0 0FRONT : monter la version de html-validate pour faire passer les tests E2E de DDMARIAGE (bug à la validation de la page des PJ quand plus d'un input FILE est affiché 0 0FRONT : regarder à https://angular.fr/pipes/pure 0 0FRONT : remettre en place la couverture de code dans l'application Angular (quand ce sera possible - ko en 07/2024) 0 0MAVEN : monter la version des dépendances Maven avec https://docs.renovatebot.com/ 0 0E2E : traiter les TODO et ajouter des contrôles sur les libellés, le facultatif, ... et les composants affichables 0 0FRONT : ajouter la date, l'heure et la date+heure sous différents formats dans les données disponibles dans les templates 0 0E2E : I18n dans les tests E2E (check sélecteur au début puis, à chaque page, changer de langue pour vérifier les libellés) 0 0E2E : paramètre langue dans les tests E2E (check sélecteur au début puis, à chaque page, changer de langue pour vérifier les libellés) 0 0Revoir la gestion des erreurs dans les clients FEIGN (https://www.baeldung.com/java-feign-client-exception-handling) pour ne pas avoir systématiquement une 500 (prendre le cas d'une erreur de validation de donnée) 0 0DOC : rejouer tous les tests, en vérifier la pertinence et/ou ajouter des contrôles 0 0DependencyTrack : analyser les problèmes de licence remontés 0 0DependencyTrack : analyser les vulnérabilités remontées 0 0DependencyTrack : faire fonctionner les policy concernant les versions de dépendance 0 0PREZ : créer un chapitre \"formation\" dans la documentation et y reprendre la première présentation et créer une seconde PREZ (dans le HTML et pas en PPTx) 0 0DOC : finir la description des tests du chapitre 3.36.2 0 0DOC : finir la description des tests du chapitre 3.36.4 0 0DOC : faire en sorte que les appels REST depuis l'IHM de swagger-ui utilise l'url (host:port) de la gateway et non celui de l'applicatif 0 0DDMariage : gérer les démarches hybrides et les potentielles connexions d'usager 0 0DDMariage : implémenter le référentiel COMEDEC dans le référentiel géographique 0 0Ajouter des mécaniques pour désactiver/inhiber/retarder des traitements quand des systèmes externes sont indisponibles ou bug =\u003e avec procédure pour activer/contourner/revenirEnArriere 0 0operationtranquilitevacances : lien \"besoin d'aide\" en bas de démarche 0 0operationtranquilitevacances : personnalisation des messages d'erreur par validation et par champs 0 0operationtranquilitevacances : ajouter la validation dateDebut"
},
{
	"uri": "http://localhost:1313/documentation/6glossaire/",
	"title": "6. Glossaire",
	"tags": [],
	"description": "",
	"content": "Pour communiquer aisément, faut-il encore utiliser chaque mot à bon escient :\ndémarche (point de vue du SI) une démarche est une application WEB publique (exposée sur Internet) permettant aux usager de saisir des données dans l\u0026rsquo;objectif de créer une demande. Synonyme : application (point de vue des usagers/testeurs) réaliser une démarche est la somme des actions nécessaires pour créer et compléter une demande dans une application WEB publique nommée démarche dans la définition précédente. Synonyme : création d\u0026rsquo;un télé-dossier (point de vue des partenaires) une démarche reçue est l\u0026rsquo;ensemble des documents et données saisies par l\u0026rsquo;usager. Synonyme : télé-dossier télé-dossier ensemble des documents et données saisis/fournis par l\u0026rsquo;usager à travers une application de démarche pièce-jointe une pièce-jointe est un des deux types de documents présents dans un télé-dossier. document généré un document généré est un fichier créé automatiquement à la soumission d\u0026rsquo;un télé-dossier, par le socle, à partir d\u0026rsquo;un modèle/template et des données saisies par l\u0026rsquo;usager. soumission la soumission est l\u0026rsquo;action réalisée au clic d\u0026rsquo;un usager sur le bouton soumettre ma demande. A cet instant, sont créés des documents qui, associés aux pièces jointes, formeront le télé-dossier. "
},
{
	"uri": "http://localhost:1313/documentation/0licence/",
	"title": "0. License",
	"tags": [],
	"description": "",
	"content": "Summary This program is offered under a commercial and under the AGPL license. For commercial licensing, contact me at talbotgui@gmail.com.\nFor AGPL licensing, see below.\nAGPL licensing: This program is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License for more details.\nAGPL license is available under this line and https://www.gnu.org/licenses/#AGPL\nCOMMERCIAL LICENSE For commercial licensing, contact me at talbotgui@gmail.com.\nAGPL LICENSE GNU AFFERO GENERAL PUBLIC LICENSE Version 3, 19 November 2007 Copyright (C) 2007 Free Software Foundation, Inc. https://fsf.org/ Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\nPreamble The GNU Affero General Public License is a free, copyleft license for software and other kinds of works, specifically designed to ensure cooperation with the community in the case of network server software.\nThe licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, our General Public Licenses are intended to guarantee your freedom to share and change all versions of a program\u0026ndash;to make sure it remains free software for all its users.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.\nDevelopers that use our General Public Licenses protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License which gives you legal permission to copy, distribute and/or modify the software.\nA secondary benefit of defending all users\u0026rsquo; freedom is that improvements made in alternate versions of the program, if they receive widespread use, become available for other developers to incorporate. Many developers of free software are heartened and encouraged by the resulting cooperation. However, in the case of software used on network servers, this result may fail to come about. The GNU General Public License permits making a modified version and letting the public access it on a server without ever releasing its source code to the public.\nThe GNU Affero General Public License is designed specifically to ensure that, in such cases, the modified source code becomes available to the community. It requires the operator of a network server to provide the source code of the modified version running there to the users of that server. Therefore, public use of a modified version, on a publicly accessible server, gives the public access to the source code of the modified version.\nAn older license, called the Affero General Public License and published by Affero, was designed to accomplish similar goals. This is a different license, not a version of the Affero GPL, but Affero has released a new version of the Affero GPL which permits relicensing under this license.\nThe precise terms and conditions for copying, distribution and modification follow.\nTERMS AND CONDITIONS Definitions. \u0026ldquo;This License\u0026rdquo; refers to version 3 of the GNU Affero General Public License.\n\u0026ldquo;Copyright\u0026rdquo; also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.\n\u0026ldquo;The Program\u0026rdquo; refers to any copyrightable work licensed under this License. Each licensee is addressed as \u0026ldquo;you\u0026rdquo;. \u0026ldquo;Licensees\u0026rdquo; and \u0026ldquo;recipients\u0026rdquo; may be individuals or organizations.\nTo \u0026ldquo;modify\u0026rdquo; a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy. The resulting work is called a \u0026ldquo;modified version\u0026rdquo; of the earlier work or a work \u0026ldquo;based on\u0026rdquo; the earlier work.\nA \u0026ldquo;covered work\u0026rdquo; means either the unmodified Program or a work based on the Program.\nTo \u0026ldquo;propagate\u0026rdquo; a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy. Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well.\nTo \u0026ldquo;convey\u0026rdquo; a work means any kind of propagation that enables other parties to make or receive copies. Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.\nAn interactive user interface displays \u0026ldquo;Appropriate Legal Notices\u0026rdquo; to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License. If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.\nSource Code. The \u0026ldquo;source code\u0026rdquo; for a work means the preferred form of the work for making modifications to it. \u0026ldquo;Object code\u0026rdquo; means any non-source form of a work.\nA \u0026ldquo;Standard Interface\u0026rdquo; means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.\nThe \u0026ldquo;System Libraries\u0026rdquo; of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form. A \u0026ldquo;Major Component\u0026rdquo;, in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.\nThe \u0026ldquo;Corresponding Source\u0026rdquo; for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work\u0026rsquo;s System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.\nThe Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.\nThe Corresponding Source for a work in source code form is that same work.\nBasic Permissions. All rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.\nYou may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright. Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you.\nConveying under any other circumstances is permitted solely under the conditions stated below. Sublicensing is not allowed; section 10 makes it unnecessary.\nProtecting Users\u0026rsquo; Legal Rights From Anti-Circumvention Law. No covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures.\nWhen you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work\u0026rsquo;s users, your or third parties\u0026rsquo; legal rights to forbid circumvention of technological measures.\nConveying Verbatim Copies. You may convey verbatim copies of the Program\u0026rsquo;s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program.\nYou may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee.\nConveying Modified Source Versions. You may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions:\na) The work must carry prominent notices stating that you modified it, and giving a relevant date. b) The work must carry prominent notices stating that it is released under this License and any conditions added under section 7. This requirement modifies the requirement in section 4 to \u0026quot;keep intact all notices\u0026quot;. c) You must license the entire work, as a whole, under this License to anyone who comes into possession of a copy. This License will therefore apply, along with any applicable section 7 additional terms, to the whole of the work, and all its parts, regardless of how they are packaged. This License gives no permission to license the work in any other way, but it does not invalidate such permission if you have separately received it. d) If the work has interactive user interfaces, each must display Appropriate Legal Notices; however, if the Program has interactive interfaces that do not display Appropriate Legal Notices, your work need not make them do so. A compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an \u0026ldquo;aggregate\u0026rdquo; if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation\u0026rsquo;s users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate.\nConveying Non-Source Forms. You may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:\na) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by the Corresponding Source fixed on a durable physical medium customarily used for software interchange. b) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by a written offer, valid for at least three years and valid for as long as you offer spare parts or customer support for that product model, to give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge. c) Convey individual copies of the object code with a copy of the written offer to provide the Corresponding Source. This alternative is allowed only occasionally and noncommercially, and only if you received the object code with such an offer, in accord with subsection 6b. d) Convey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge. You need not require recipients to copy the Corresponding Source along with the object code. If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements. e) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d. A separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.\nA \u0026ldquo;User Product\u0026rdquo; is either (1) a \u0026ldquo;consumer product\u0026rdquo;, which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, \u0026ldquo;normally used\u0026rdquo; refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\n\u0026ldquo;Installation Information\u0026rdquo; for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.\nIf you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).\nThe requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.\nCorresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.\nAdditional Terms. \u0026ldquo;Additional permissions\u0026rdquo; are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.\nWhen you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it. (Additional permissions may be written to require their own removal in certain cases when you modify the work.) You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission.\nNotwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms:\na) Disclaiming warranty or limiting liability differently from the terms of sections 15 and 16 of this License; or b) Requiring preservation of specified reasonable legal notices or author attributions in that material or in the Appropriate Legal Notices displayed by works containing it; or c) Prohibiting misrepresentation of the origin of that material, or requiring that modified versions of such material be marked in reasonable ways as different from the original version; or d) Limiting the use for publicity purposes of names of licensors or authors of the material; or e) Declining to grant rights under trademark law for use of some trade names, trademarks, or service marks; or f) Requiring indemnification of licensors and authors of that material by anyone who conveys the material (or modified versions of it) with contractual assumptions of liability to the recipient, for any liability that these contractual assumptions directly impose on those licensors and authors. All other non-permissive additional terms are considered \u0026ldquo;further restrictions\u0026rdquo; within the meaning of section 10. If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term. If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.\nIf you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.\nAdditional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.\nTermination. You may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).\nHowever, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.\nMoreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.\nTermination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.\nAcceptance Not Required for Having Copies. You are not required to accept this License in order to receive or run a copy of the Program. Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance. However, nothing other than this License grants you permission to propagate or modify any covered work. These actions infringe copyright if you do not accept this License. Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so.\nAutomatic Licensing of Downstream Recipients. Each time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License. You are not responsible for enforcing compliance by third parties with this License.\nAn \u0026ldquo;entity transaction\u0026rdquo; is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations. If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party\u0026rsquo;s predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts.\nYou may not impose any further restrictions on the exercise of the rights granted or affirmed under this License. For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it.\nPatents. A \u0026ldquo;contributor\u0026rdquo; is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based. The work thus licensed is called the contributor\u0026rsquo;s \u0026ldquo;contributor version\u0026rdquo;.\nA contributor\u0026rsquo;s \u0026ldquo;essential patent claims\u0026rdquo; are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version. For purposes of this definition, \u0026ldquo;control\u0026rdquo; includes the right to grant patent sublicenses in a manner consistent with the requirements of this License.\nEach contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor\u0026rsquo;s essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version.\nIn the following three paragraphs, a \u0026ldquo;patent license\u0026rdquo; is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement). To \u0026ldquo;grant\u0026rdquo; such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party.\nIf you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients. \u0026ldquo;Knowingly relying\u0026rdquo; means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient\u0026rsquo;s use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid.\nIf, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it.\nA patent license is \u0026ldquo;discriminatory\u0026rdquo; if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License. You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007.\nNothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law.\nNo Surrender of Others\u0026rsquo; Freedom. If conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all. For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program.\nRemote Network Interaction; Use with the GNU General Public License. Notwithstanding any other provision of this License, if you modify the Program, your modified version must prominently offer all users interacting with it remotely through a computer network (if your version supports such interaction) an opportunity to receive the Corresponding Source of your version by providing access to the Corresponding Source from a network server at no charge, through some standard or customary means of facilitating copying of software. This Corresponding Source shall include the Corresponding Source for any work covered by version 3 of the GNU General Public License that is incorporated pursuant to the following paragraph.\nNotwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU General Public License into a single combined work, and to convey the resulting work. The terms of this License will continue to apply to the part which is the covered work, but the work with which it is combined will remain governed by version 3 of the GNU General Public License.\nRevised Versions of this License. The Free Software Foundation may publish revised and/or new versions of the GNU Affero General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies that a certain numbered version of the GNU Affero General Public License \u0026ldquo;or any later version\u0026rdquo; applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of the GNU Affero General Public License, you may choose any version ever published by the Free Software Foundation.\nIf the Program specifies that a proxy can decide which future versions of the GNU Affero General Public License can be used, that proxy\u0026rsquo;s public statement of acceptance of a version permanently authorizes you to choose that version for the Program.\nLater license versions may give you additional or different permissions. However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version.\nDisclaimer of Warranty. THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \u0026ldquo;AS IS\u0026rdquo; WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\nLimitation of Liability. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\nInterpretation of Sections 15 and 16. If the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee.\nEND OF TERMS AND CONDITIONS How to Apply These Terms to Your New Programs If you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively state the exclusion of warranty; and each file should have at least the \u0026ldquo;copyright\u0026rdquo; line and a pointer to where the full notice is found.\n\u0026lt;one line to give the program's name and a brief idea of what it does.\u0026gt; Copyright (C) \u0026lt;year\u0026gt; \u0026lt;name of author\u0026gt; This program is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License for more details. You should have received a copy of the GNU Affero General Public License along with this program. If not, see \u0026lt;https://www.gnu.org/licenses/\u0026gt;. Also add information on how to contact you by electronic and paper mail.\nIf your software can interact with users remotely through a computer network, you should also make sure that it provides a way for users to get its source. For example, if your program is a web application, its interface could display a \u0026ldquo;Source\u0026rdquo; link that leads users to an archive of the code. There are many ways you could offer source, and different solutions will be better for different programs; see section 13 for the specific requirements.\nYou should also get your employer (if you work as a programmer) or school, if any, to sign a \u0026ldquo;copyright disclaimer\u0026rdquo; for the program, if necessary. For more information on this, and how to apply and follow the GNU AGPL, see https://www.gnu.org/licenses/.\n"
},
{
	"uri": "http://localhost:1313/documentation/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/documentation/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]